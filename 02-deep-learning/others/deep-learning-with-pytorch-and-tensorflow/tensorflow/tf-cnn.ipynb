{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from utils import tile_raster_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_data = mnist.input_data.read_data_sets('./datasets/mnist/', one_hot=True, seed=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classify MNIST using Simple Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 784 # input is 28 width x 28 height matrix\n",
    "num_labels = 10 # output is 10 digit numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Interactive Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, num_features]) # None indicates batch size\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10], dtype=tf.float32, name='weights'))\n",
    "b = tf.Variable(tf.zeros([10], dtype=tf.float32, name='bias'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "softmax_op = tf.nn.softmax(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_op = tf.reduce_mean(-tf.reduce_sum(y * tf.log(softmax_op), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train The Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "correct_prediction_op = tf.equal(tf.argmax(softmax_op, 1), tf.argmax(y, 1))\n",
    "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction_op, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init_op) # run the init_op using an interactive session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Training accuracy: 0.9219\n",
      "Epoch: 200, Training accuracy: 0.8438\n",
      "Epoch: 300, Training accuracy: 0.8750\n",
      "Epoch: 400, Training accuracy: 0.8438\n",
      "Epoch: 500, Training accuracy: 0.8594\n",
      "Epoch: 600, Training accuracy: 0.8594\n",
      "Epoch: 700, Training accuracy: 0.9062\n",
      "Epoch: 800, Training accuracy: 0.8906\n",
      "Epoch: 900, Training accuracy: 0.9219\n",
      "Epoch: 1000, Training accuracy: 0.8906\n"
     ]
    }
   ],
   "source": [
    "for i_epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    train_batch = mnist_data.train.next_batch(batch_size)\n",
    "    if i_epoch % 100 == 0:\n",
    "        train_accuracy = accuracy_op.eval(feed_dict={X: train_batch[0], y: train_batch[1]})\n",
    "        print(f'Epoch: {i_epoch}, Training accuracy: {train_accuracy:.4f}')\n",
    "    \n",
    "    optimizer_op.run(feed_dict={X: train_batch[0], y: train_batch[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final accuracy for the simple perceptron model is: 91.31%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_op.eval(feed_dict={X: mnist_data.test.images, y: mnist_data.test.labels}) * 100\n",
    "print(f'The final accuracy for the simple perceptron model is: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classify MNIST using Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = 28\n",
    "height = 28\n",
    "flatten = width * height\n",
    "num_channels = 1\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Interactive Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, flatten])\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_image = tf.reshape(X, [-1, width, height, num_channels]) # -1 indicates batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = tf.Variable(tf.truncated_normal([5, 5, 1, 32], stddev=0.1, name='weights_conv1')) # 5x5 filter size\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[32], name='bias_conv1')) # need 32 biases for 32 outputs\n",
    "\n",
    "conv1_layer = tf.nn.conv2d(X_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1\n",
    "conv1_layer = tf.nn.relu(conv1_layer)\n",
    "\n",
    "conv1_map = tf.nn.max_pool(conv1_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=0.1, name='weights_conv2')) # 5x5 filter size\n",
    "b_conv2 = tf.Variable(tf.constant(0.1, shape=[64], name='bias_conv2')) # need 64 biases for 64 outputs\n",
    "\n",
    "conv2_layer = tf.nn.conv2d(conv1_map, W_conv2, strides=[1, 1, 1, 1], padding='SAME') + b_conv2\n",
    "conv2_layer = tf.nn.relu(conv2_layer)\n",
    "\n",
    "conv2_map = tf.nn.max_pool(conv2_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully Connected Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flattening last convolution layer output\n",
    "flatten_matrix = tf.reshape(conv2_map, [-1, 7 * 7 * 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = tf.Variable(tf.truncated_normal([7 * 7 * 64, 1024], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1, shape=[1024])) # need 1024 biases for 1024 outputs\n",
    "\n",
    "fc1_layer = tf.matmul(flatten_matrix, W_fc1) + b_fc1\n",
    "fc1_layer = tf.nn.relu(fc1_layer)\n",
    "\n",
    "# dropout layer for reducing overfitting\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "fc1_layer = tf.nn.dropout(fc1_layer, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully Connected Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = tf.Variable(tf.truncated_normal([1024, num_labels], stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.constant(0.1, shape=[num_labels]))\n",
    "\n",
    "fc2_layer = tf.matmul(fc1_layer, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = tf.nn.softmax(fc2_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_op = tf.reduce_mean(-tf.reduce_sum(y * tf.log(outputs), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer_op = tf.train.AdamOptimizer(learning_rate).minimize(loss_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train The Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init_op) # run the init_op using an interactive session\n",
    "\n",
    "correct_prediction_op = tf.equal(tf.argmax(outputs, 1), tf.argmax(y, 1))\n",
    "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction_op, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Training accuracy: 0.8125\n",
      "Epoch: 200, Training accuracy: 0.9062\n",
      "Epoch: 300, Training accuracy: 0.8906\n",
      "Epoch: 400, Training accuracy: 0.9688\n",
      "Epoch: 500, Training accuracy: 0.9062\n",
      "Epoch: 600, Training accuracy: 0.9844\n",
      "Epoch: 700, Training accuracy: 0.9688\n",
      "Epoch: 800, Training accuracy: 0.9531\n",
      "Epoch: 900, Training accuracy: 0.9688\n",
      "Epoch: 1000, Training accuracy: 0.9844\n"
     ]
    }
   ],
   "source": [
    "for i_epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    train_batch = mnist_data.train.next_batch(batch_size)\n",
    "    if i_epoch % 100 == 0:\n",
    "        train_accuracy = accuracy_op.eval(feed_dict={X: train_batch[0], y: train_batch[1], keep_prob: 1.0})\n",
    "        print(f'Epoch: {i_epoch}, Training accuracy: {train_accuracy:.4f}')\n",
    "    \n",
    "    optimizer_op.run(feed_dict={X: train_batch[0], y: train_batch[1], keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate in batches to avoid out-of-memory issues\n",
    "num_batches = mnist_data.test.images.shape[0] // batch_size\n",
    "cummulative_accuarcy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final accuracy for the CNN model is: 96.52%\n"
     ]
    }
   ],
   "source": [
    "for index in range(num_batches):\n",
    "    \n",
    "    test_batch = mnist_data.test.next_batch(batch_size)\n",
    "    cummulative_accuarcy += accuracy_op.eval(feed_dict={X: test_batch[0], y: test_batch[1], keep_prob: 1.0})\n",
    "\n",
    "print(f'The final accuracy for the CNN model is: {(cummulative_accuarcy/ num_batches)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
