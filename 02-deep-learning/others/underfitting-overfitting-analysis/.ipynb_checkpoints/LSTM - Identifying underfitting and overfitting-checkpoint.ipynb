{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train():\n",
    "    seq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "    seq = array(seq)\n",
    "    X, y = seq[:, 0], seq[:, 1]\n",
    "    X = X.reshape(len(X), 1, 1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_validation():\n",
    "    seq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "    seq = array(seq)\n",
    "    X, y = seq[:, 0], seq[:, 1]\n",
    "    X = X.reshape(len(X), 1, 1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting (less epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 285ms/step - loss: 0.1013 - val_loss: 0.5952\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1002 - val_loss: 0.5916\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0991 - val_loss: 0.5880\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0980 - val_loss: 0.5845\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0970 - val_loss: 0.5809\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0959 - val_loss: 0.5774\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0948 - val_loss: 0.5738\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0938 - val_loss: 0.5703\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0927 - val_loss: 0.5668\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0917 - val_loss: 0.5633\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.5598\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0896 - val_loss: 0.5563\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.5528\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.5493\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0865 - val_loss: 0.5459\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0855 - val_loss: 0.5424\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0845 - val_loss: 0.5389\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0835 - val_loss: 0.5354\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0825 - val_loss: 0.5320\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0816 - val_loss: 0.5286\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.5251\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.5217\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.5183\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0777 - val_loss: 0.5149\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.5115\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.5081\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.5047\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.5013\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.4979\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0720 - val_loss: 0.4945\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.4911\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0702 - val_loss: 0.4878\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.4844\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.4810\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.4777\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.4743\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0657 - val_loss: 0.4709\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.4676\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.4642\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0630 - val_loss: 0.4609\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.4575\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0613 - val_loss: 0.4542\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.4508\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.4474\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 0.4441\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.4408\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0571 - val_loss: 0.4374\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0563 - val_loss: 0.4341\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.4308\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.4275\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.4241\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.4208\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.4175\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.4142\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.4109\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.4076\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.4043\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0483 - val_loss: 0.4010\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0476 - val_loss: 0.3977\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0468 - val_loss: 0.3944\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0461 - val_loss: 0.3912\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.3879\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.3846\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.3814\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.3781\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0425 - val_loss: 0.3749\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 893us/step - loss: 0.0418 - val_loss: 0.3716\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.3684\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.3652\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.3620\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.3588\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0384 - val_loss: 0.3555\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0377 - val_loss: 0.3523\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0371 - val_loss: 0.3492\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.3460\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.3428\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0352 - val_loss: 0.3397\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0346 - val_loss: 0.3365\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0340 - val_loss: 0.3334\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.3303\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0328 - val_loss: 0.3272\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0322 - val_loss: 0.3241\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0316 - val_loss: 0.3210\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.3179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0305 - val_loss: 0.3149\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0299 - val_loss: 0.3118\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0294 - val_loss: 0.3088\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.3058\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0283 - val_loss: 0.3028\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.2998\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0273 - val_loss: 0.2969\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0268 - val_loss: 0.2939\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0263 - val_loss: 0.2910\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0258 - val_loss: 0.2881\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.2852\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0249 - val_loss: 0.2824\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.2795\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0240 - val_loss: 0.2767\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.2739\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.2711\n"
     ]
    }
   ],
   "source": [
    "model_underfitting = Sequential()\n",
    "model_underfitting.add(LSTM(10, input_shape=(1,1)))\n",
    "model_underfitting.add(Dense(1, activation='linear'))\n",
    "\n",
    "model_underfitting.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "X, y = get_train()\n",
    "val_X, val_y = get_validation()\n",
    "history_underfitting = model_underfitting.fit(X, y, epochs=100, validation_data=(val_X, val_y), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18168b5fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and validation loss\n",
    "pyplot.plot(history_underfitting.history['loss'])\n",
    "pyplot.plot(history_underfitting.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting (insufficient memory cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.1278 - val_loss: 0.7713\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1236 - val_loss: 0.7601\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1196 - val_loss: 0.7493\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1157 - val_loss: 0.7387\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1120 - val_loss: 0.7284\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1084 - val_loss: 0.7184\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1050 - val_loss: 0.7087\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1017 - val_loss: 0.6992\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0985 - val_loss: 0.6900\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0955 - val_loss: 0.6811\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0926 - val_loss: 0.6724\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0898 - val_loss: 0.6639\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0872 - val_loss: 0.6556\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0846 - val_loss: 0.6476\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0822 - val_loss: 0.6398\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0798 - val_loss: 0.6322\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0775 - val_loss: 0.6248\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0754 - val_loss: 0.6176\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.6106\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.6038\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0694 - val_loss: 0.5971\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.5907\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0658 - val_loss: 0.5843\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0641 - val_loss: 0.5782\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0625 - val_loss: 0.5722\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.5664\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.5607\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.5552\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0566 - val_loss: 0.5498\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0553 - val_loss: 0.5445\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.5394\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.5344\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.5296\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.5248\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.5202\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0485 - val_loss: 0.5157\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0475 - val_loss: 0.5113\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.5070\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0457 - val_loss: 0.5028\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0448 - val_loss: 0.4987\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0440 - val_loss: 0.4948\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0432 - val_loss: 0.4909\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0424 - val_loss: 0.4871\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.4834\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.4798\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.4763\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.4729\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0390 - val_loss: 0.4695\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.4662\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0378 - val_loss: 0.4631\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0373 - val_loss: 0.4599\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0368 - val_loss: 0.4569\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.4539\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.4511\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 964us/step - loss: 0.0353 - val_loss: 0.4482\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0348 - val_loss: 0.4455\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0344 - val_loss: 0.4428\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0340 - val_loss: 0.4402\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0336 - val_loss: 0.4376\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0332 - val_loss: 0.4351\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0329 - val_loss: 0.4326\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0325 - val_loss: 0.4302\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0322 - val_loss: 0.4279\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0319 - val_loss: 0.4256\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0316 - val_loss: 0.4234\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.4212\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0310 - val_loss: 0.4191\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.4170\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0304 - val_loss: 0.4150\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0302 - val_loss: 0.4130\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0300 - val_loss: 0.4111\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.4092\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0295 - val_loss: 0.4073\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0293 - val_loss: 0.4055\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0291 - val_loss: 0.4037\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0289 - val_loss: 0.4020\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0287 - val_loss: 0.4003\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.3987\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0284 - val_loss: 0.3971\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0282 - val_loss: 0.3955\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0280 - val_loss: 0.3940\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.3924\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.3910\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.3895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.3881\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0273 - val_loss: 0.3868\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.3854\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.3841\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.3828\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.3815\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0268 - val_loss: 0.3803\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.3791\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.3779\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0265 - val_loss: 0.3768\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0264 - val_loss: 0.3757\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0263 - val_loss: 0.3746\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.3735\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0261 - val_loss: 0.3724\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.3714\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0260 - val_loss: 0.3704\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0259 - val_loss: 0.3694\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0258 - val_loss: 0.3684\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0258 - val_loss: 0.3675\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0257 - val_loss: 0.3666\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 977us/step - loss: 0.0257 - val_loss: 0.3657\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0256 - val_loss: 0.3648\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0256 - val_loss: 0.3639\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0255 - val_loss: 0.3631\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0254 - val_loss: 0.3622\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.3614\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0254 - val_loss: 0.3606\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0253 - val_loss: 0.3598\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0253 - val_loss: 0.3591\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.3583\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.3576\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0251 - val_loss: 0.3569\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0251 - val_loss: 0.3562\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0251 - val_loss: 0.3555\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0250 - val_loss: 0.3549\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0250 - val_loss: 0.3542\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0250 - val_loss: 0.3536\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0249 - val_loss: 0.3529\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0249 - val_loss: 0.3523\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0249 - val_loss: 0.3517\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0249 - val_loss: 0.3511\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.3506\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0248 - val_loss: 0.3500\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.3494\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0248 - val_loss: 0.3489\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.3484\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.3479\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.3473\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.3468\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.3464\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.3459\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0246 - val_loss: 0.3454\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0246 - val_loss: 0.3450\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0246 - val_loss: 0.3445\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0246 - val_loss: 0.3441\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0246 - val_loss: 0.3436\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0246 - val_loss: 0.3432\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0245 - val_loss: 0.3428\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0245 - val_loss: 0.3424\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.3420\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0245 - val_loss: 0.3416\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0245 - val_loss: 0.3413\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.3409\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0245 - val_loss: 0.3405\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0245 - val_loss: 0.3402\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0245 - val_loss: 0.3398\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.3395\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.3391\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.3388\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.3385\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.3382\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.3379\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.3376\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.3373\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.3370\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.3367\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.3364\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.3361\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.3359\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3356\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3354\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3351\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3346\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3344\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.3341\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.3339\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.3337\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3335\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3333\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3331\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3328\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.3326\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3324\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3323\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3321\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.3319\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3317\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3315\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3313\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3312\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3310\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3308\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3307\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3305\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.3303\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3302\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3300\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3299\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3298\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3296\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3295\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3293\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3292\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3291\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 817us/step - loss: 0.0242 - val_loss: 0.3289\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3288\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3287\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3286\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3284\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3283\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3282\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.3281\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3280\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3279\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3278\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3277\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.3276\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3275\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.3274\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3273\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3272\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3271\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3270\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3269\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3268\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3267\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3266\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3265\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3265\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3264\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3263\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3262\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3261\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 955us/step - loss: 0.0242 - val_loss: 0.3261\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3260\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3259\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3259\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3258\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3257\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3256\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3256\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3255\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3254\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3254\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3253\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3253\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3252\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3251\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3251\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3250\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3250\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3249\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3249\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3248\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3247\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3246\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3246\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3245\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3245\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3244\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3244\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3244\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3243\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3243\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3242\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3242\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3241\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3241\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3240\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3240\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3240\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3239\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3239\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3238\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3238\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3238\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3237\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3237\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3237\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3236\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3236\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3235\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3235\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3235\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3234\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3234\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3234\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3233\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3233\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3233\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3233\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3232\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3232\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3232\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3231\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3231\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3231\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3231\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3230\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3230\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3230\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.3229\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3229\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3229\n"
     ]
    }
   ],
   "source": [
    "# set LSTM unit to 1 and optimizer to sgd\n",
    "model_underfitting2 = Sequential()\n",
    "model_underfitting2.add(LSTM(1, input_shape=(1,1)))\n",
    "model_underfitting2.add(Dense(1, activation='linear'))\n",
    "\n",
    "model_underfitting2.compile(loss='mse', optimizer='sgd')\n",
    "\n",
    "X, y = get_train()\n",
    "val_X, val_y = get_validation()\n",
    "history_underfitting2 = model_underfitting2.fit(X, y, epochs=300, validation_data=(val_X, val_y), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181749ecf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and validation loss\n",
    "pyplot.plot(history_underfitting2.history['loss'])\n",
    "pyplot.plot(history_underfitting2.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/1200\n",
      "5/5 [==============================] - 2s 417ms/step - loss: 0.1064 - val_loss: 0.6253\n",
      "Epoch 2/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1051 - val_loss: 0.6216\n",
      "Epoch 3/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1040 - val_loss: 0.6172\n",
      "Epoch 4/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1027 - val_loss: 0.6129\n",
      "Epoch 5/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1015 - val_loss: 0.6088\n",
      "Epoch 6/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1003 - val_loss: 0.6045\n",
      "Epoch 7/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0990 - val_loss: 0.6002\n",
      "Epoch 8/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0978 - val_loss: 0.5959\n",
      "Epoch 9/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0966 - val_loss: 0.5917\n",
      "Epoch 10/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0954 - val_loss: 0.5874\n",
      "Epoch 11/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0942 - val_loss: 0.5832\n",
      "Epoch 12/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0930 - val_loss: 0.5790\n",
      "Epoch 13/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0918 - val_loss: 0.5748\n",
      "Epoch 14/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.5706\n",
      "Epoch 15/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0894 - val_loss: 0.5664\n",
      "Epoch 16/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0883 - val_loss: 0.5623\n",
      "Epoch 17/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.5582\n",
      "Epoch 18/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.5541\n",
      "Epoch 19/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.5499\n",
      "Epoch 20/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0837 - val_loss: 0.5458\n",
      "Epoch 21/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0826 - val_loss: 0.5418\n",
      "Epoch 22/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0815 - val_loss: 0.5377\n",
      "Epoch 23/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.5337\n",
      "Epoch 24/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.5297\n",
      "Epoch 25/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.5257\n",
      "Epoch 26/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.5217\n",
      "Epoch 27/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0761 - val_loss: 0.5177\n",
      "Epoch 28/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.5137\n",
      "Epoch 29/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.5098\n",
      "Epoch 30/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.5059\n",
      "Epoch 31/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.5020\n",
      "Epoch 32/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.4981\n",
      "Epoch 33/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.4942\n",
      "Epoch 34/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.4903\n",
      "Epoch 35/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.4865\n",
      "Epoch 36/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.4826\n",
      "Epoch 37/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0660 - val_loss: 0.4788\n",
      "Epoch 38/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.4750\n",
      "Epoch 39/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.4712\n",
      "Epoch 40/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.4674\n",
      "Epoch 41/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0622 - val_loss: 0.4637\n",
      "Epoch 42/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0612 - val_loss: 0.4600\n",
      "Epoch 43/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0603 - val_loss: 0.4562\n",
      "Epoch 44/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.4525\n",
      "Epoch 45/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.4488\n",
      "Epoch 46/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.4452\n",
      "Epoch 47/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.4415\n",
      "Epoch 48/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.4378\n",
      "Epoch 49/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.4342\n",
      "Epoch 50/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.4306\n",
      "Epoch 51/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0533 - val_loss: 0.4270\n",
      "Epoch 52/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 0.4234\n",
      "Epoch 53/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.4198\n",
      "Epoch 54/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.4163\n",
      "Epoch 55/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.4128\n",
      "Epoch 56/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.4093\n",
      "Epoch 57/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.4058\n",
      "Epoch 58/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0477 - val_loss: 0.4023\n",
      "Epoch 59/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.3988\n",
      "Epoch 60/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.3954\n",
      "Epoch 61/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0454 - val_loss: 0.3920\n",
      "Epoch 62/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0446 - val_loss: 0.3886\n",
      "Epoch 63/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0439 - val_loss: 0.3852\n",
      "Epoch 64/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.3818\n",
      "Epoch 65/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0425 - val_loss: 0.3784\n",
      "Epoch 66/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.3751\n",
      "Epoch 67/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.3718\n",
      "Epoch 68/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.3685\n",
      "Epoch 69/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.3652\n",
      "Epoch 70/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0390 - val_loss: 0.3620\n",
      "Epoch 71/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0384 - val_loss: 0.3587\n",
      "Epoch 72/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.3555\n",
      "Epoch 73/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.3523\n",
      "Epoch 74/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.3491\n",
      "Epoch 75/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.3459\n",
      "Epoch 76/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0352 - val_loss: 0.3428\n",
      "Epoch 77/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0346 - val_loss: 0.3396\n",
      "Epoch 78/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0340 - val_loss: 0.3365\n",
      "Epoch 79/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.3334\n",
      "Epoch 80/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0329 - val_loss: 0.3304\n",
      "Epoch 81/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0323 - val_loss: 0.3273\n",
      "Epoch 82/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0317 - val_loss: 0.3243\n",
      "Epoch 83/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0312 - val_loss: 0.3212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0306 - val_loss: 0.3183\n",
      "Epoch 85/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.3153\n",
      "Epoch 86/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.3123\n",
      "Epoch 87/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0291 - val_loss: 0.3094\n",
      "Epoch 88/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0286 - val_loss: 0.3065\n",
      "Epoch 89/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0281 - val_loss: 0.3036\n",
      "Epoch 90/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.3008\n",
      "Epoch 91/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.2979\n",
      "Epoch 92/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0266 - val_loss: 0.2951\n",
      "Epoch 93/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.2923\n",
      "Epoch 94/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0257 - val_loss: 0.2895\n",
      "Epoch 95/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0253 - val_loss: 0.2868\n",
      "Epoch 96/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0249 - val_loss: 0.2840\n",
      "Epoch 97/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.2813\n",
      "Epoch 98/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0240 - val_loss: 0.2787\n",
      "Epoch 99/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0236 - val_loss: 0.2760\n",
      "Epoch 100/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.2734\n",
      "Epoch 101/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.2707\n",
      "Epoch 102/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.2681\n",
      "Epoch 103/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.2656\n",
      "Epoch 104/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.2630\n",
      "Epoch 105/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.2605\n",
      "Epoch 106/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.2580\n",
      "Epoch 107/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.2556\n",
      "Epoch 108/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.2531\n",
      "Epoch 109/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.2507\n",
      "Epoch 110/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.2483\n",
      "Epoch 111/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.2460\n",
      "Epoch 112/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.2436\n",
      "Epoch 113/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.2413\n",
      "Epoch 114/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.2390\n",
      "Epoch 115/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.2368\n",
      "Epoch 116/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.2345\n",
      "Epoch 117/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.2323\n",
      "Epoch 118/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.2301\n",
      "Epoch 119/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.2280\n",
      "Epoch 120/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.2258\n",
      "Epoch 121/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.2237\n",
      "Epoch 122/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.2216\n",
      "Epoch 123/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.2196\n",
      "Epoch 124/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.2176\n",
      "Epoch 125/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.2156\n",
      "Epoch 126/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.2136\n",
      "Epoch 127/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.2116\n",
      "Epoch 128/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.2097\n",
      "Epoch 129/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.2078\n",
      "Epoch 130/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.2059\n",
      "Epoch 131/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.2041\n",
      "Epoch 132/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.2022\n",
      "Epoch 133/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.2004\n",
      "Epoch 134/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.1987\n",
      "Epoch 135/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.1969\n",
      "Epoch 136/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1952\n",
      "Epoch 137/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.1935\n",
      "Epoch 138/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.1918\n",
      "Epoch 139/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.1902\n",
      "Epoch 140/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.1886\n",
      "Epoch 141/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1870\n",
      "Epoch 142/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1854\n",
      "Epoch 143/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1839\n",
      "Epoch 144/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.1823\n",
      "Epoch 145/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.1808\n",
      "Epoch 146/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.1794\n",
      "Epoch 147/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1779\n",
      "Epoch 148/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.1765\n",
      "Epoch 149/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1751\n",
      "Epoch 150/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1737\n",
      "Epoch 151/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.1724\n",
      "Epoch 152/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1710\n",
      "Epoch 153/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1697\n",
      "Epoch 154/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1684\n",
      "Epoch 155/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1672\n",
      "Epoch 156/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1659\n",
      "Epoch 157/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1647\n",
      "Epoch 158/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.1635\n",
      "Epoch 159/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1623\n",
      "Epoch 160/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1612\n",
      "Epoch 161/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1600\n",
      "Epoch 162/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1589\n",
      "Epoch 163/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1578\n",
      "Epoch 164/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1567\n",
      "Epoch 165/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.1557\n",
      "Epoch 166/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.1546\n",
      "Epoch 167/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.1536\n",
      "Epoch 168/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1526\n",
      "Epoch 169/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1516\n",
      "Epoch 170/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1507\n",
      "Epoch 171/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1497\n",
      "Epoch 172/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1488\n",
      "Epoch 173/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.1479\n",
      "Epoch 174/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1470\n",
      "Epoch 175/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1461\n",
      "Epoch 176/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1453\n",
      "Epoch 177/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1444\n",
      "Epoch 178/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1436\n",
      "Epoch 179/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1428\n",
      "Epoch 180/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1420\n",
      "Epoch 181/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1412\n",
      "Epoch 182/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1405\n",
      "Epoch 183/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1397\n",
      "Epoch 184/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1390\n",
      "Epoch 185/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1382\n",
      "Epoch 186/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1375\n",
      "Epoch 187/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1368\n",
      "Epoch 188/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1361\n",
      "Epoch 189/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1355\n",
      "Epoch 190/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1348\n",
      "Epoch 191/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1341\n",
      "Epoch 192/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.1335\n",
      "Epoch 193/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1329\n",
      "Epoch 194/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.1323\n",
      "Epoch 195/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1317\n",
      "Epoch 196/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1311\n",
      "Epoch 197/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1305\n",
      "Epoch 198/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1299\n",
      "Epoch 199/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1293\n",
      "Epoch 200/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1288\n",
      "Epoch 201/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1282\n",
      "Epoch 202/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1277\n",
      "Epoch 203/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1271\n",
      "Epoch 204/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1266\n",
      "Epoch 205/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1261\n",
      "Epoch 206/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1256\n",
      "Epoch 207/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.1251\n",
      "Epoch 208/1200\n",
      "5/5 [==============================] - 0s 933us/step - loss: 0.0097 - val_loss: 0.1246\n",
      "Epoch 209/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1241\n",
      "Epoch 210/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1236\n",
      "Epoch 211/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1231\n",
      "Epoch 212/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1226\n",
      "Epoch 213/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1222\n",
      "Epoch 214/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1217\n",
      "Epoch 215/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1213\n",
      "Epoch 216/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1208\n",
      "Epoch 217/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1204\n",
      "Epoch 218/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1199\n",
      "Epoch 219/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1195\n",
      "Epoch 220/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1191\n",
      "Epoch 221/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1186\n",
      "Epoch 222/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1182\n",
      "Epoch 223/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1178\n",
      "Epoch 224/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1174\n",
      "Epoch 225/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1170\n",
      "Epoch 226/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1166\n",
      "Epoch 227/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1162\n",
      "Epoch 228/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1158\n",
      "Epoch 229/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1154\n",
      "Epoch 230/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1150\n",
      "Epoch 231/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1146\n",
      "Epoch 232/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1142\n",
      "Epoch 233/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1138\n",
      "Epoch 234/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1134\n",
      "Epoch 235/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1131\n",
      "Epoch 236/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.1127\n",
      "Epoch 237/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.1123\n",
      "Epoch 238/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1119\n",
      "Epoch 239/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1116\n",
      "Epoch 240/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1112\n",
      "Epoch 241/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.1108\n",
      "Epoch 242/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1105\n",
      "Epoch 243/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1101\n",
      "Epoch 244/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1097\n",
      "Epoch 245/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1094\n",
      "Epoch 246/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1090\n",
      "Epoch 247/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1083\n",
      "Epoch 249/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1080\n",
      "Epoch 250/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1076\n",
      "Epoch 251/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1072\n",
      "Epoch 252/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1069\n",
      "Epoch 253/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1065\n",
      "Epoch 254/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1062\n",
      "Epoch 255/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1058\n",
      "Epoch 256/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1055\n",
      "Epoch 257/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1051\n",
      "Epoch 258/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1048\n",
      "Epoch 259/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1044\n",
      "Epoch 260/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1041\n",
      "Epoch 261/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1038\n",
      "Epoch 262/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1034\n",
      "Epoch 263/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1031\n",
      "Epoch 264/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1027\n",
      "Epoch 265/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.1024\n",
      "Epoch 266/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.1020\n",
      "Epoch 267/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.1017\n",
      "Epoch 268/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.1013\n",
      "Epoch 269/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.1010\n",
      "Epoch 270/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.1007\n",
      "Epoch 271/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.1003\n",
      "Epoch 272/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.1000\n",
      "Epoch 273/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0996\n",
      "Epoch 274/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0993\n",
      "Epoch 275/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0989\n",
      "Epoch 276/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0986\n",
      "Epoch 277/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0983\n",
      "Epoch 278/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0979\n",
      "Epoch 279/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0976\n",
      "Epoch 280/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0972\n",
      "Epoch 281/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0969\n",
      "Epoch 282/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0966\n",
      "Epoch 283/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0962\n",
      "Epoch 284/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0959\n",
      "Epoch 285/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0955\n",
      "Epoch 286/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0952\n",
      "Epoch 287/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0949\n",
      "Epoch 288/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0945\n",
      "Epoch 289/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0942\n",
      "Epoch 290/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0938\n",
      "Epoch 291/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0935\n",
      "Epoch 292/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0932\n",
      "Epoch 293/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0928\n",
      "Epoch 294/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0925\n",
      "Epoch 295/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0921\n",
      "Epoch 296/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0918\n",
      "Epoch 297/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0915\n",
      "Epoch 298/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0911\n",
      "Epoch 299/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0908\n",
      "Epoch 300/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0904\n",
      "Epoch 301/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0901\n",
      "Epoch 302/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0898\n",
      "Epoch 303/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0894\n",
      "Epoch 304/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0891\n",
      "Epoch 305/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0888\n",
      "Epoch 306/1200\n",
      "5/5 [==============================] - 0s 919us/step - loss: 0.0073 - val_loss: 0.0884\n",
      "Epoch 307/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0881\n",
      "Epoch 308/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0877\n",
      "Epoch 309/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0874\n",
      "Epoch 310/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0871\n",
      "Epoch 311/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0867\n",
      "Epoch 312/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0864\n",
      "Epoch 313/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0861\n",
      "Epoch 314/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0857\n",
      "Epoch 315/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0854\n",
      "Epoch 316/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0850\n",
      "Epoch 317/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0847\n",
      "Epoch 318/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0844\n",
      "Epoch 319/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0840\n",
      "Epoch 320/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0837\n",
      "Epoch 321/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0834\n",
      "Epoch 322/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0830\n",
      "Epoch 323/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0827\n",
      "Epoch 324/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0823\n",
      "Epoch 325/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0820\n",
      "Epoch 326/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0817\n",
      "Epoch 327/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0813\n",
      "Epoch 328/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0810\n",
      "Epoch 329/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0803\n",
      "Epoch 331/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0800\n",
      "Epoch 332/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0797\n",
      "Epoch 333/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0793\n",
      "Epoch 334/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0790\n",
      "Epoch 335/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0787\n",
      "Epoch 336/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0783\n",
      "Epoch 337/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0780\n",
      "Epoch 338/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0777\n",
      "Epoch 339/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0773\n",
      "Epoch 340/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0770\n",
      "Epoch 341/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0767\n",
      "Epoch 342/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0763\n",
      "Epoch 343/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0760\n",
      "Epoch 344/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0757\n",
      "Epoch 345/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0753\n",
      "Epoch 346/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0750\n",
      "Epoch 347/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0747\n",
      "Epoch 348/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0743\n",
      "Epoch 349/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0740\n",
      "Epoch 350/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0737\n",
      "Epoch 351/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0733\n",
      "Epoch 352/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0730\n",
      "Epoch 353/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0727\n",
      "Epoch 354/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0723\n",
      "Epoch 355/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0720\n",
      "Epoch 356/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0717\n",
      "Epoch 357/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0714\n",
      "Epoch 358/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0710\n",
      "Epoch 359/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0707\n",
      "Epoch 360/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0704\n",
      "Epoch 361/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0700\n",
      "Epoch 362/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0697\n",
      "Epoch 363/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0694\n",
      "Epoch 364/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0691\n",
      "Epoch 365/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0687\n",
      "Epoch 366/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0684\n",
      "Epoch 367/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0681\n",
      "Epoch 368/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0678\n",
      "Epoch 369/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0674\n",
      "Epoch 370/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0671\n",
      "Epoch 371/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0668\n",
      "Epoch 372/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0665\n",
      "Epoch 373/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0661\n",
      "Epoch 374/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0658\n",
      "Epoch 375/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0655\n",
      "Epoch 376/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0652\n",
      "Epoch 377/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0648\n",
      "Epoch 378/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0645\n",
      "Epoch 379/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0642\n",
      "Epoch 380/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0639\n",
      "Epoch 381/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0635\n",
      "Epoch 382/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0632\n",
      "Epoch 383/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0629\n",
      "Epoch 384/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0626\n",
      "Epoch 385/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0623\n",
      "Epoch 386/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0620\n",
      "Epoch 387/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0616\n",
      "Epoch 388/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0613\n",
      "Epoch 389/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0610\n",
      "Epoch 390/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0607\n",
      "Epoch 391/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0604\n",
      "Epoch 392/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0600\n",
      "Epoch 393/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0597\n",
      "Epoch 394/1200\n",
      "5/5 [==============================] - 0s 974us/step - loss: 0.0052 - val_loss: 0.0594\n",
      "Epoch 395/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0591\n",
      "Epoch 396/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0588\n",
      "Epoch 397/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0585\n",
      "Epoch 398/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0582\n",
      "Epoch 399/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0578\n",
      "Epoch 400/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0575\n",
      "Epoch 401/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0572\n",
      "Epoch 402/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0569\n",
      "Epoch 403/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0566\n",
      "Epoch 404/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0563\n",
      "Epoch 405/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0560\n",
      "Epoch 406/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0557\n",
      "Epoch 407/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0554\n",
      "Epoch 408/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0550\n",
      "Epoch 409/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0547\n",
      "Epoch 410/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0544\n",
      "Epoch 411/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0538\n",
      "Epoch 413/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0535\n",
      "Epoch 414/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0532\n",
      "Epoch 415/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0529\n",
      "Epoch 416/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0526\n",
      "Epoch 417/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0523\n",
      "Epoch 418/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0520\n",
      "Epoch 419/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0517\n",
      "Epoch 420/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0514\n",
      "Epoch 421/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0511\n",
      "Epoch 422/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0508\n",
      "Epoch 423/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0505\n",
      "Epoch 424/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0502\n",
      "Epoch 425/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0499\n",
      "Epoch 426/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0496\n",
      "Epoch 427/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0493\n",
      "Epoch 428/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0490\n",
      "Epoch 429/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0487\n",
      "Epoch 430/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0484\n",
      "Epoch 431/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0481\n",
      "Epoch 432/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0478\n",
      "Epoch 433/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0475\n",
      "Epoch 434/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0472\n",
      "Epoch 435/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0469\n",
      "Epoch 436/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0466\n",
      "Epoch 437/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0463\n",
      "Epoch 438/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0461\n",
      "Epoch 439/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0458\n",
      "Epoch 440/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0455\n",
      "Epoch 441/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0452\n",
      "Epoch 442/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0449\n",
      "Epoch 443/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0446\n",
      "Epoch 444/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0443\n",
      "Epoch 445/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0440\n",
      "Epoch 446/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0437\n",
      "Epoch 447/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0435\n",
      "Epoch 448/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0432\n",
      "Epoch 449/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0429\n",
      "Epoch 450/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0426\n",
      "Epoch 451/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0423\n",
      "Epoch 452/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0420\n",
      "Epoch 453/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0418\n",
      "Epoch 454/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0415\n",
      "Epoch 455/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0412\n",
      "Epoch 456/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0409\n",
      "Epoch 457/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0407\n",
      "Epoch 458/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0404\n",
      "Epoch 459/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0401\n",
      "Epoch 460/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0398\n",
      "Epoch 461/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0396\n",
      "Epoch 462/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0393\n",
      "Epoch 463/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0390\n",
      "Epoch 464/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0387\n",
      "Epoch 465/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0385\n",
      "Epoch 466/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0382\n",
      "Epoch 467/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0379\n",
      "Epoch 468/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0376\n",
      "Epoch 469/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0374\n",
      "Epoch 470/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0371\n",
      "Epoch 471/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0368\n",
      "Epoch 472/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0366\n",
      "Epoch 473/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0363\n",
      "Epoch 474/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0361\n",
      "Epoch 475/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0358\n",
      "Epoch 476/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0355\n",
      "Epoch 477/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0353\n",
      "Epoch 478/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0350\n",
      "Epoch 479/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0347\n",
      "Epoch 480/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0345\n",
      "Epoch 481/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0342\n",
      "Epoch 482/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0340\n",
      "Epoch 483/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0337\n",
      "Epoch 484/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0335\n",
      "Epoch 485/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0332\n",
      "Epoch 486/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0329\n",
      "Epoch 487/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0327\n",
      "Epoch 488/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0324\n",
      "Epoch 489/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0322\n",
      "Epoch 490/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0319\n",
      "Epoch 491/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0317\n",
      "Epoch 492/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0314\n",
      "Epoch 493/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0309\n",
      "Epoch 495/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0307\n",
      "Epoch 496/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0305\n",
      "Epoch 497/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0302\n",
      "Epoch 498/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0300\n",
      "Epoch 499/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0297\n",
      "Epoch 500/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0295\n",
      "Epoch 501/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0292\n",
      "Epoch 502/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0290\n",
      "Epoch 503/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0288\n",
      "Epoch 504/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0285\n",
      "Epoch 505/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0283\n",
      "Epoch 506/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0280\n",
      "Epoch 507/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0278\n",
      "Epoch 508/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0276\n",
      "Epoch 509/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0273\n",
      "Epoch 510/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0271\n",
      "Epoch 511/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0269\n",
      "Epoch 512/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0267\n",
      "Epoch 513/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0264\n",
      "Epoch 514/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0262\n",
      "Epoch 515/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0260\n",
      "Epoch 516/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0257\n",
      "Epoch 517/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0255\n",
      "Epoch 518/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0253\n",
      "Epoch 519/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0251\n",
      "Epoch 520/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0248\n",
      "Epoch 521/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0246\n",
      "Epoch 522/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0244\n",
      "Epoch 523/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0242\n",
      "Epoch 524/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0240\n",
      "Epoch 525/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0238\n",
      "Epoch 526/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0235\n",
      "Epoch 527/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0233\n",
      "Epoch 528/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0231\n",
      "Epoch 529/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0229\n",
      "Epoch 530/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0227\n",
      "Epoch 531/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0225\n",
      "Epoch 532/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0223\n",
      "Epoch 533/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0221\n",
      "Epoch 534/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0218\n",
      "Epoch 535/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0216\n",
      "Epoch 536/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0214\n",
      "Epoch 537/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0212\n",
      "Epoch 538/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0210\n",
      "Epoch 539/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0208\n",
      "Epoch 540/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0206\n",
      "Epoch 541/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0204\n",
      "Epoch 542/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0202\n",
      "Epoch 543/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0200\n",
      "Epoch 544/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0198\n",
      "Epoch 545/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0196\n",
      "Epoch 546/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0194\n",
      "Epoch 547/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0192\n",
      "Epoch 548/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0190\n",
      "Epoch 549/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0188\n",
      "Epoch 550/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0187\n",
      "Epoch 551/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0185\n",
      "Epoch 552/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0183\n",
      "Epoch 553/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0181\n",
      "Epoch 554/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0179\n",
      "Epoch 555/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0177\n",
      "Epoch 556/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0175\n",
      "Epoch 557/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0174\n",
      "Epoch 558/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0172\n",
      "Epoch 559/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0170\n",
      "Epoch 560/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0168\n",
      "Epoch 561/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0166\n",
      "Epoch 562/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0164\n",
      "Epoch 563/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0163\n",
      "Epoch 564/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0161\n",
      "Epoch 565/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0159\n",
      "Epoch 566/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0157\n",
      "Epoch 567/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0156\n",
      "Epoch 568/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0154\n",
      "Epoch 569/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0152\n",
      "Epoch 570/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0151\n",
      "Epoch 571/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0149\n",
      "Epoch 572/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0147\n",
      "Epoch 573/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0146\n",
      "Epoch 574/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0144\n",
      "Epoch 575/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 576/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0141\n",
      "Epoch 577/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0139\n",
      "Epoch 578/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0137\n",
      "Epoch 579/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0136\n",
      "Epoch 580/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0134\n",
      "Epoch 581/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0133\n",
      "Epoch 582/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0131\n",
      "Epoch 583/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0130\n",
      "Epoch 584/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0128\n",
      "Epoch 585/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0127\n",
      "Epoch 586/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 587/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0124\n",
      "Epoch 588/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0122\n",
      "Epoch 589/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0121\n",
      "Epoch 590/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0119\n",
      "Epoch 591/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0118\n",
      "Epoch 592/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0116\n",
      "Epoch 593/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0115\n",
      "Epoch 594/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0113\n",
      "Epoch 595/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0112\n",
      "Epoch 596/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0110\n",
      "Epoch 597/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0109\n",
      "Epoch 598/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0108\n",
      "Epoch 599/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0106\n",
      "Epoch 600/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0105\n",
      "Epoch 601/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0104\n",
      "Epoch 602/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0102\n",
      "Epoch 603/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0101\n",
      "Epoch 604/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0100\n",
      "Epoch 605/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0098\n",
      "Epoch 606/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0097\n",
      "Epoch 607/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0096\n",
      "Epoch 608/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0094\n",
      "Epoch 609/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0093\n",
      "Epoch 610/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0092\n",
      "Epoch 611/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0091\n",
      "Epoch 612/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0089\n",
      "Epoch 613/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0088\n",
      "Epoch 614/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0087\n",
      "Epoch 615/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0086\n",
      "Epoch 616/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0085\n",
      "Epoch 617/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0083\n",
      "Epoch 618/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0082\n",
      "Epoch 619/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0081\n",
      "Epoch 620/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0080\n",
      "Epoch 621/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0079\n",
      "Epoch 622/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0078\n",
      "Epoch 623/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0076\n",
      "Epoch 624/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0075\n",
      "Epoch 625/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0074\n",
      "Epoch 626/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0073\n",
      "Epoch 627/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0072\n",
      "Epoch 628/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.9008e-04 - val_loss: 0.0071\n",
      "Epoch 629/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.7993e-04 - val_loss: 0.0070\n",
      "Epoch 630/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.6985e-04 - val_loss: 0.0069\n",
      "Epoch 631/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.5984e-04 - val_loss: 0.0068\n",
      "Epoch 632/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.4991e-04 - val_loss: 0.0067\n",
      "Epoch 633/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.4005e-04 - val_loss: 0.0066\n",
      "Epoch 634/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.3027e-04 - val_loss: 0.0065\n",
      "Epoch 635/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.2055e-04 - val_loss: 0.0064\n",
      "Epoch 636/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.1091e-04 - val_loss: 0.0063\n",
      "Epoch 637/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.0134e-04 - val_loss: 0.0062\n",
      "Epoch 638/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.9184e-04 - val_loss: 0.0061\n",
      "Epoch 639/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.8242e-04 - val_loss: 0.0060\n",
      "Epoch 640/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.7306e-04 - val_loss: 0.0059\n",
      "Epoch 641/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.6378e-04 - val_loss: 0.0058\n",
      "Epoch 642/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.5457e-04 - val_loss: 0.0057\n",
      "Epoch 643/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.4543e-04 - val_loss: 0.0056\n",
      "Epoch 644/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.3636e-04 - val_loss: 0.0055\n",
      "Epoch 645/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.2737e-04 - val_loss: 0.0054\n",
      "Epoch 646/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.1844e-04 - val_loss: 0.0053\n",
      "Epoch 647/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.0959e-04 - val_loss: 0.0053\n",
      "Epoch 648/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.0080e-04 - val_loss: 0.0052\n",
      "Epoch 649/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.9208e-04 - val_loss: 0.0051\n",
      "Epoch 650/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.8344e-04 - val_loss: 0.0050\n",
      "Epoch 651/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.7486e-04 - val_loss: 0.0049\n",
      "Epoch 652/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.6636e-04 - val_loss: 0.0048\n",
      "Epoch 653/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.5791e-04 - val_loss: 0.0047\n",
      "Epoch 654/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.4955e-04 - val_loss: 0.0047\n",
      "Epoch 655/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.4125e-04 - val_loss: 0.0046\n",
      "Epoch 656/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.3302e-04 - val_loss: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 657/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.2485e-04 - val_loss: 0.0044\n",
      "Epoch 658/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.1676e-04 - val_loss: 0.0043\n",
      "Epoch 659/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.0873e-04 - val_loss: 0.0043\n",
      "Epoch 660/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.0077e-04 - val_loss: 0.0042\n",
      "Epoch 661/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.9288e-04 - val_loss: 0.0041\n",
      "Epoch 662/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.8506e-04 - val_loss: 0.0040\n",
      "Epoch 663/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.7730e-04 - val_loss: 0.0040\n",
      "Epoch 664/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.6961e-04 - val_loss: 0.0039\n",
      "Epoch 665/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.6198e-04 - val_loss: 0.0038\n",
      "Epoch 666/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.5442e-04 - val_loss: 0.0038\n",
      "Epoch 667/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.4693e-04 - val_loss: 0.0037\n",
      "Epoch 668/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.3950e-04 - val_loss: 0.0036\n",
      "Epoch 669/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.3214e-04 - val_loss: 0.0035\n",
      "Epoch 670/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.2484e-04 - val_loss: 0.0035\n",
      "Epoch 671/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.1761e-04 - val_loss: 0.0034\n",
      "Epoch 672/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.1044e-04 - val_loss: 0.0033\n",
      "Epoch 673/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.0334e-04 - val_loss: 0.0033\n",
      "Epoch 674/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.9630e-04 - val_loss: 0.0032\n",
      "Epoch 675/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.8932e-04 - val_loss: 0.0032\n",
      "Epoch 676/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.8241e-04 - val_loss: 0.0031\n",
      "Epoch 677/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.7556e-04 - val_loss: 0.0030\n",
      "Epoch 678/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.6877e-04 - val_loss: 0.0030\n",
      "Epoch 679/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.6205e-04 - val_loss: 0.0029\n",
      "Epoch 680/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.5539e-04 - val_loss: 0.0029\n",
      "Epoch 681/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.4879e-04 - val_loss: 0.0028\n",
      "Epoch 682/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.4225e-04 - val_loss: 0.0027\n",
      "Epoch 683/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.3577e-04 - val_loss: 0.0027\n",
      "Epoch 684/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.2936e-04 - val_loss: 0.0026\n",
      "Epoch 685/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.2300e-04 - val_loss: 0.0026\n",
      "Epoch 686/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.1671e-04 - val_loss: 0.0025\n",
      "Epoch 687/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.1047e-04 - val_loss: 0.0025\n",
      "Epoch 688/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.0430e-04 - val_loss: 0.0024\n",
      "Epoch 689/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.9818e-04 - val_loss: 0.0024\n",
      "Epoch 690/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.9213e-04 - val_loss: 0.0023\n",
      "Epoch 691/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.8613e-04 - val_loss: 0.0023\n",
      "Epoch 692/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.8019e-04 - val_loss: 0.0022\n",
      "Epoch 693/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.7431e-04 - val_loss: 0.0022\n",
      "Epoch 694/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.6848e-04 - val_loss: 0.0021\n",
      "Epoch 695/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.6272e-04 - val_loss: 0.0021\n",
      "Epoch 696/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.5701e-04 - val_loss: 0.0020\n",
      "Epoch 697/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.5136e-04 - val_loss: 0.0020\n",
      "Epoch 698/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.4576e-04 - val_loss: 0.0019\n",
      "Epoch 699/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.4023e-04 - val_loss: 0.0019\n",
      "Epoch 700/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.3475e-04 - val_loss: 0.0018\n",
      "Epoch 701/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.2932e-04 - val_loss: 0.0018\n",
      "Epoch 702/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.2395e-04 - val_loss: 0.0017\n",
      "Epoch 703/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.1863e-04 - val_loss: 0.0017\n",
      "Epoch 704/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.1337e-04 - val_loss: 0.0017\n",
      "Epoch 705/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.0816e-04 - val_loss: 0.0016\n",
      "Epoch 706/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.0301e-04 - val_loss: 0.0016\n",
      "Epoch 707/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.9791e-04 - val_loss: 0.0015\n",
      "Epoch 708/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.9287e-04 - val_loss: 0.0015\n",
      "Epoch 709/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.8787e-04 - val_loss: 0.0015\n",
      "Epoch 710/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.8293e-04 - val_loss: 0.0014\n",
      "Epoch 711/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.7805e-04 - val_loss: 0.0014\n",
      "Epoch 712/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.7321e-04 - val_loss: 0.0014\n",
      "Epoch 713/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.6842e-04 - val_loss: 0.0013\n",
      "Epoch 714/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.6369e-04 - val_loss: 0.0013\n",
      "Epoch 715/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.5901e-04 - val_loss: 0.0013\n",
      "Epoch 716/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.5437e-04 - val_loss: 0.0012\n",
      "Epoch 717/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.4979e-04 - val_loss: 0.0012\n",
      "Epoch 718/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.4526e-04 - val_loss: 0.0012\n",
      "Epoch 719/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.4078e-04 - val_loss: 0.0011\n",
      "Epoch 720/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.3635e-04 - val_loss: 0.0011\n",
      "Epoch 721/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.3196e-04 - val_loss: 0.0011\n",
      "Epoch 722/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.2763e-04 - val_loss: 0.0010\n",
      "Epoch 723/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.2334e-04 - val_loss: 9.9813e-04\n",
      "Epoch 724/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.1910e-04 - val_loss: 9.6915e-04\n",
      "Epoch 725/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.1490e-04 - val_loss: 9.4073e-04\n",
      "Epoch 726/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.1076e-04 - val_loss: 9.1285e-04\n",
      "Epoch 727/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.0666e-04 - val_loss: 8.8553e-04\n",
      "Epoch 728/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.0260e-04 - val_loss: 8.5875e-04\n",
      "Epoch 729/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.9860e-04 - val_loss: 8.3251e-04\n",
      "Epoch 730/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.9464e-04 - val_loss: 8.0681e-04\n",
      "Epoch 731/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.9072e-04 - val_loss: 7.8163e-04\n",
      "Epoch 732/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.8685e-04 - val_loss: 7.5696e-04\n",
      "Epoch 733/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.8302e-04 - val_loss: 7.3282e-04\n",
      "Epoch 734/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.7924e-04 - val_loss: 7.0919e-04\n",
      "Epoch 735/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.7550e-04 - val_loss: 6.8606e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 736/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.7181e-04 - val_loss: 6.6342e-04\n",
      "Epoch 737/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.6815e-04 - val_loss: 6.4128e-04\n",
      "Epoch 738/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.6454e-04 - val_loss: 6.1963e-04\n",
      "Epoch 739/1200\n",
      "5/5 [==============================] - 0s 943us/step - loss: 2.6098e-04 - val_loss: 5.9846e-04\n",
      "Epoch 740/1200\n",
      "5/5 [==============================] - 0s 946us/step - loss: 2.5745e-04 - val_loss: 5.7777e-04\n",
      "Epoch 741/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.5397e-04 - val_loss: 5.5755e-04\n",
      "Epoch 742/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.5053e-04 - val_loss: 5.3779e-04\n",
      "Epoch 743/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.4713e-04 - val_loss: 5.1850e-04\n",
      "Epoch 744/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.4377e-04 - val_loss: 4.9967e-04\n",
      "Epoch 745/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.4045e-04 - val_loss: 4.8128e-04\n",
      "Epoch 746/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.3717e-04 - val_loss: 4.6333e-04\n",
      "Epoch 747/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.3393e-04 - val_loss: 4.4584e-04\n",
      "Epoch 748/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.3073e-04 - val_loss: 4.2877e-04\n",
      "Epoch 749/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2757e-04 - val_loss: 4.1214e-04\n",
      "Epoch 750/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.2445e-04 - val_loss: 3.9593e-04\n",
      "Epoch 751/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2137e-04 - val_loss: 3.8014e-04\n",
      "Epoch 752/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1832e-04 - val_loss: 3.6477e-04\n",
      "Epoch 753/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1531e-04 - val_loss: 3.4980e-04\n",
      "Epoch 754/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1234e-04 - val_loss: 3.3524e-04\n",
      "Epoch 755/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0941e-04 - val_loss: 3.2107e-04\n",
      "Epoch 756/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0651e-04 - val_loss: 3.0730e-04\n",
      "Epoch 757/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0365e-04 - val_loss: 2.9392e-04\n",
      "Epoch 758/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0083e-04 - val_loss: 2.8092e-04\n",
      "Epoch 759/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9804e-04 - val_loss: 2.6830e-04\n",
      "Epoch 760/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9528e-04 - val_loss: 2.5606e-04\n",
      "Epoch 761/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9257e-04 - val_loss: 2.4418e-04\n",
      "Epoch 762/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8988e-04 - val_loss: 2.3267e-04\n",
      "Epoch 763/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.8723e-04 - val_loss: 2.2152e-04\n",
      "Epoch 764/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.8462e-04 - val_loss: 2.1072e-04\n",
      "Epoch 765/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8203e-04 - val_loss: 2.0027e-04\n",
      "Epoch 766/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7949e-04 - val_loss: 1.9017e-04\n",
      "Epoch 767/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7697e-04 - val_loss: 1.8040e-04\n",
      "Epoch 768/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7449e-04 - val_loss: 1.7098e-04\n",
      "Epoch 769/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7204e-04 - val_loss: 1.6188e-04\n",
      "Epoch 770/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6962e-04 - val_loss: 1.5310e-04\n",
      "Epoch 771/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6723e-04 - val_loss: 1.4465e-04\n",
      "Epoch 772/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6487e-04 - val_loss: 1.3652e-04\n",
      "Epoch 773/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6255e-04 - val_loss: 1.2870e-04\n",
      "Epoch 774/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6026e-04 - val_loss: 1.2118e-04\n",
      "Epoch 775/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5799e-04 - val_loss: 1.1397e-04\n",
      "Epoch 776/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5576e-04 - val_loss: 1.0705e-04\n",
      "Epoch 777/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5356e-04 - val_loss: 1.0043e-04\n",
      "Epoch 778/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5138e-04 - val_loss: 9.4102e-05\n",
      "Epoch 779/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4924e-04 - val_loss: 8.8057e-05\n",
      "Epoch 780/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4712e-04 - val_loss: 8.2290e-05\n",
      "Epoch 781/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4504e-04 - val_loss: 7.6802e-05\n",
      "Epoch 782/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4298e-04 - val_loss: 7.1586e-05\n",
      "Epoch 783/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4095e-04 - val_loss: 6.6639e-05\n",
      "Epoch 784/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3894e-04 - val_loss: 6.1955e-05\n",
      "Epoch 785/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3697e-04 - val_loss: 5.7529e-05\n",
      "Epoch 786/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3502e-04 - val_loss: 5.3358e-05\n",
      "Epoch 787/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3310e-04 - val_loss: 4.9440e-05\n",
      "Epoch 788/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3120e-04 - val_loss: 4.5768e-05\n",
      "Epoch 789/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2933e-04 - val_loss: 4.2340e-05\n",
      "Epoch 790/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2749e-04 - val_loss: 3.9151e-05\n",
      "Epoch 791/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2568e-04 - val_loss: 3.6196e-05\n",
      "Epoch 792/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2388e-04 - val_loss: 3.3474e-05\n",
      "Epoch 793/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2212e-04 - val_loss: 3.0977e-05\n",
      "Epoch 794/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2038e-04 - val_loss: 2.8704e-05\n",
      "Epoch 795/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1866e-04 - val_loss: 2.6649e-05\n",
      "Epoch 796/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1697e-04 - val_loss: 2.4811e-05\n",
      "Epoch 797/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1530e-04 - val_loss: 2.3184e-05\n",
      "Epoch 798/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1365e-04 - val_loss: 2.1765e-05\n",
      "Epoch 799/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1203e-04 - val_loss: 2.0550e-05\n",
      "Epoch 800/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1043e-04 - val_loss: 1.9535e-05\n",
      "Epoch 801/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0886e-04 - val_loss: 1.8717e-05\n",
      "Epoch 802/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0731e-04 - val_loss: 1.8092e-05\n",
      "Epoch 803/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0577e-04 - val_loss: 1.7657e-05\n",
      "Epoch 804/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0427e-04 - val_loss: 1.7408e-05\n",
      "Epoch 805/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0278e-04 - val_loss: 1.7341e-05\n",
      "Epoch 806/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0132e-04 - val_loss: 1.7452e-05\n",
      "Epoch 807/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.9873e-05 - val_loss: 1.7740e-05\n",
      "Epoch 808/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.8450e-05 - val_loss: 1.8200e-05\n",
      "Epoch 809/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.7049e-05 - val_loss: 1.8828e-05\n",
      "Epoch 810/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.5668e-05 - val_loss: 1.9622e-05\n",
      "Epoch 811/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.4308e-05 - val_loss: 2.0578e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 812/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.2967e-05 - val_loss: 2.1692e-05\n",
      "Epoch 813/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.1647e-05 - val_loss: 2.2962e-05\n",
      "Epoch 814/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.0346e-05 - val_loss: 2.4385e-05\n",
      "Epoch 815/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.9064e-05 - val_loss: 2.5956e-05\n",
      "Epoch 816/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.7802e-05 - val_loss: 2.7673e-05\n",
      "Epoch 817/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.6558e-05 - val_loss: 2.9534e-05\n",
      "Epoch 818/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.5333e-05 - val_loss: 3.1535e-05\n",
      "Epoch 819/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.4126e-05 - val_loss: 3.3672e-05\n",
      "Epoch 820/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.2938e-05 - val_loss: 3.5943e-05\n",
      "Epoch 821/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.1768e-05 - val_loss: 3.8344e-05\n",
      "Epoch 822/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.0615e-05 - val_loss: 4.0874e-05\n",
      "Epoch 823/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.9480e-05 - val_loss: 4.3529e-05\n",
      "Epoch 824/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.8362e-05 - val_loss: 4.6307e-05\n",
      "Epoch 825/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.7261e-05 - val_loss: 4.9204e-05\n",
      "Epoch 826/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.6177e-05 - val_loss: 5.2216e-05\n",
      "Epoch 827/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.5109e-05 - val_loss: 5.5342e-05\n",
      "Epoch 828/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.4059e-05 - val_loss: 5.8580e-05\n",
      "Epoch 829/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.3024e-05 - val_loss: 6.1925e-05\n",
      "Epoch 830/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.2006e-05 - val_loss: 6.5377e-05\n",
      "Epoch 831/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.1003e-05 - val_loss: 6.8931e-05\n",
      "Epoch 832/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.0016e-05 - val_loss: 7.2585e-05\n",
      "Epoch 833/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.9044e-05 - val_loss: 7.6338e-05\n",
      "Epoch 834/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.8087e-05 - val_loss: 8.0186e-05\n",
      "Epoch 835/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.7145e-05 - val_loss: 8.4127e-05\n",
      "Epoch 836/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.6218e-05 - val_loss: 8.8160e-05\n",
      "Epoch 837/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.5305e-05 - val_loss: 9.2280e-05\n",
      "Epoch 838/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.4407e-05 - val_loss: 9.6486e-05\n",
      "Epoch 839/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.3524e-05 - val_loss: 1.0077e-04\n",
      "Epoch 840/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.2654e-05 - val_loss: 1.0514e-04\n",
      "Epoch 841/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.1798e-05 - val_loss: 1.0959e-04\n",
      "Epoch 842/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.0955e-05 - val_loss: 1.1411e-04\n",
      "Epoch 843/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.0126e-05 - val_loss: 1.1871e-04\n",
      "Epoch 844/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.9310e-05 - val_loss: 1.2338e-04\n",
      "Epoch 845/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.8508e-05 - val_loss: 1.2812e-04\n",
      "Epoch 846/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.7718e-05 - val_loss: 1.3293e-04\n",
      "Epoch 847/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.6940e-05 - val_loss: 1.3780e-04\n",
      "Epoch 848/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.6176e-05 - val_loss: 1.4273e-04\n",
      "Epoch 849/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.5424e-05 - val_loss: 1.4773e-04\n",
      "Epoch 850/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.4684e-05 - val_loss: 1.5278e-04\n",
      "Epoch 851/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.3955e-05 - val_loss: 1.5790e-04\n",
      "Epoch 852/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.3239e-05 - val_loss: 1.6307e-04\n",
      "Epoch 853/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.2535e-05 - val_loss: 1.6829e-04\n",
      "Epoch 854/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.1842e-05 - val_loss: 1.7356e-04\n",
      "Epoch 855/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.1160e-05 - val_loss: 1.7888e-04\n",
      "Epoch 856/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.0490e-05 - val_loss: 1.8425e-04\n",
      "Epoch 857/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.9830e-05 - val_loss: 1.8967e-04\n",
      "Epoch 858/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.9181e-05 - val_loss: 1.9512e-04\n",
      "Epoch 859/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.8544e-05 - val_loss: 2.0063e-04\n",
      "Epoch 860/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.7916e-05 - val_loss: 2.0617e-04\n",
      "Epoch 861/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.7299e-05 - val_loss: 2.1175e-04\n",
      "Epoch 862/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.6693e-05 - val_loss: 2.1737e-04\n",
      "Epoch 863/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.6096e-05 - val_loss: 2.2302e-04\n",
      "Epoch 864/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.5509e-05 - val_loss: 2.2871e-04\n",
      "Epoch 865/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.4932e-05 - val_loss: 2.3443e-04\n",
      "Epoch 866/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.4365e-05 - val_loss: 2.4018e-04\n",
      "Epoch 867/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.3807e-05 - val_loss: 2.4596e-04\n",
      "Epoch 868/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.3259e-05 - val_loss: 2.5177e-04\n",
      "Epoch 869/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.2720e-05 - val_loss: 2.5760e-04\n",
      "Epoch 870/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.2190e-05 - val_loss: 2.6346e-04\n",
      "Epoch 871/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.1669e-05 - val_loss: 2.6935e-04\n",
      "Epoch 872/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.1157e-05 - val_loss: 2.7525e-04\n",
      "Epoch 873/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.0654e-05 - val_loss: 2.8117e-04\n",
      "Epoch 874/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.0159e-05 - val_loss: 2.8712e-04\n",
      "Epoch 875/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.9672e-05 - val_loss: 2.9308e-04\n",
      "Epoch 876/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.9194e-05 - val_loss: 2.9905e-04\n",
      "Epoch 877/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.8724e-05 - val_loss: 3.0505e-04\n",
      "Epoch 878/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.8262e-05 - val_loss: 3.1105e-04\n",
      "Epoch 879/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.7808e-05 - val_loss: 3.1707e-04\n",
      "Epoch 880/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.7362e-05 - val_loss: 3.2310e-04\n",
      "Epoch 881/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.6923e-05 - val_loss: 3.2914e-04\n",
      "Epoch 882/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.6492e-05 - val_loss: 3.3519e-04\n",
      "Epoch 883/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.6069e-05 - val_loss: 3.4125e-04\n",
      "Epoch 884/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.5653e-05 - val_loss: 3.4731e-04\n",
      "Epoch 885/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.5244e-05 - val_loss: 3.5338e-04\n",
      "Epoch 886/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.4842e-05 - val_loss: 3.5946e-04\n",
      "Epoch 887/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.4448e-05 - val_loss: 3.6553e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 888/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.4060e-05 - val_loss: 3.7161e-04\n",
      "Epoch 889/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.3679e-05 - val_loss: 3.7769e-04\n",
      "Epoch 890/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.3305e-05 - val_loss: 3.8377e-04\n",
      "Epoch 891/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.2937e-05 - val_loss: 3.8985e-04\n",
      "Epoch 892/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.2576e-05 - val_loss: 3.9592e-04\n",
      "Epoch 893/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.2221e-05 - val_loss: 4.0200e-04\n",
      "Epoch 894/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.1872e-05 - val_loss: 4.0807e-04\n",
      "Epoch 895/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.1530e-05 - val_loss: 4.1414e-04\n",
      "Epoch 896/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.1193e-05 - val_loss: 4.2020e-04\n",
      "Epoch 897/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.0863e-05 - val_loss: 4.2626e-04\n",
      "Epoch 898/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.0538e-05 - val_loss: 4.3231e-04\n",
      "Epoch 899/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.0220e-05 - val_loss: 4.3835e-04\n",
      "Epoch 900/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.9907e-05 - val_loss: 4.4438e-04\n",
      "Epoch 901/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.9599e-05 - val_loss: 4.5041e-04\n",
      "Epoch 902/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.9297e-05 - val_loss: 4.5642e-04\n",
      "Epoch 903/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.9001e-05 - val_loss: 4.6242e-04\n",
      "Epoch 904/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.8709e-05 - val_loss: 4.6841e-04\n",
      "Epoch 905/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.8423e-05 - val_loss: 4.7439e-04\n",
      "Epoch 906/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.8142e-05 - val_loss: 4.8035e-04\n",
      "Epoch 907/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.7867e-05 - val_loss: 4.8630e-04\n",
      "Epoch 908/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.7596e-05 - val_loss: 4.9224e-04\n",
      "Epoch 909/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.7330e-05 - val_loss: 4.9816e-04\n",
      "Epoch 910/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.7069e-05 - val_loss: 5.0406e-04\n",
      "Epoch 911/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.6813e-05 - val_loss: 5.0995e-04\n",
      "Epoch 912/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.6561e-05 - val_loss: 5.1582e-04\n",
      "Epoch 913/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.6314e-05 - val_loss: 5.2168e-04\n",
      "Epoch 914/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.6072e-05 - val_loss: 5.2751e-04\n",
      "Epoch 915/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.5834e-05 - val_loss: 5.3333e-04\n",
      "Epoch 916/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.5600e-05 - val_loss: 5.3913e-04\n",
      "Epoch 917/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.5371e-05 - val_loss: 5.4490e-04\n",
      "Epoch 918/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.5145e-05 - val_loss: 5.5066e-04\n",
      "Epoch 919/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.4924e-05 - val_loss: 5.5640e-04\n",
      "Epoch 920/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.4708e-05 - val_loss: 5.6211e-04\n",
      "Epoch 921/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.4495e-05 - val_loss: 5.6781e-04\n",
      "Epoch 922/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.4286e-05 - val_loss: 5.7348e-04\n",
      "Epoch 923/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.4080e-05 - val_loss: 5.7912e-04\n",
      "Epoch 924/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.3879e-05 - val_loss: 5.8475e-04\n",
      "Epoch 925/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.3681e-05 - val_loss: 5.9035e-04\n",
      "Epoch 926/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.3487e-05 - val_loss: 5.9593e-04\n",
      "Epoch 927/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.3297e-05 - val_loss: 6.0148e-04\n",
      "Epoch 928/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.3110e-05 - val_loss: 6.0701e-04\n",
      "Epoch 929/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.2927e-05 - val_loss: 6.1251e-04\n",
      "Epoch 930/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2747e-05 - val_loss: 6.1799e-04\n",
      "Epoch 931/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2571e-05 - val_loss: 6.2344e-04\n",
      "Epoch 932/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2398e-05 - val_loss: 6.2886e-04\n",
      "Epoch 933/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.2228e-05 - val_loss: 6.3426e-04\n",
      "Epoch 934/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2061e-05 - val_loss: 6.3964e-04\n",
      "Epoch 935/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1897e-05 - val_loss: 6.4498e-04\n",
      "Epoch 936/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1737e-05 - val_loss: 6.5030e-04\n",
      "Epoch 937/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.1579e-05 - val_loss: 6.5559e-04\n",
      "Epoch 938/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1425e-05 - val_loss: 6.6086e-04\n",
      "Epoch 939/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1273e-05 - val_loss: 6.6609e-04\n",
      "Epoch 940/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1125e-05 - val_loss: 6.7130e-04\n",
      "Epoch 941/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0979e-05 - val_loss: 6.7648e-04\n",
      "Epoch 942/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0836e-05 - val_loss: 6.8162e-04\n",
      "Epoch 943/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0695e-05 - val_loss: 6.8674e-04\n",
      "Epoch 944/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0558e-05 - val_loss: 6.9183e-04\n",
      "Epoch 945/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0423e-05 - val_loss: 6.9689e-04\n",
      "Epoch 946/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0290e-05 - val_loss: 7.0192e-04\n",
      "Epoch 947/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0160e-05 - val_loss: 7.0692e-04\n",
      "Epoch 948/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0033e-05 - val_loss: 7.1189e-04\n",
      "Epoch 949/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9908e-05 - val_loss: 7.1684e-04\n",
      "Epoch 950/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9785e-05 - val_loss: 7.2174e-04\n",
      "Epoch 951/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9665e-05 - val_loss: 7.2662e-04\n",
      "Epoch 952/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9547e-05 - val_loss: 7.3148e-04\n",
      "Epoch 953/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9431e-05 - val_loss: 7.3629e-04\n",
      "Epoch 954/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9318e-05 - val_loss: 7.4108e-04\n",
      "Epoch 955/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9206e-05 - val_loss: 7.4584e-04\n",
      "Epoch 956/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9097e-05 - val_loss: 7.5056e-04\n",
      "Epoch 957/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8990e-05 - val_loss: 7.5526e-04\n",
      "Epoch 958/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8885e-05 - val_loss: 7.5992e-04\n",
      "Epoch 959/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.8783e-05 - val_loss: 7.6455e-04\n",
      "Epoch 960/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.8682e-05 - val_loss: 7.6915e-04\n",
      "Epoch 961/1200\n",
      "5/5 [==============================] - 0s 918us/step - loss: 1.8583e-05 - val_loss: 7.7372e-04\n",
      "Epoch 962/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8486e-05 - val_loss: 7.7825e-04\n",
      "Epoch 963/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8391e-05 - val_loss: 7.8276e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 964/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.8297e-05 - val_loss: 7.8723e-04\n",
      "Epoch 965/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8206e-05 - val_loss: 7.9167e-04\n",
      "Epoch 966/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8116e-05 - val_loss: 7.9608e-04\n",
      "Epoch 967/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8028e-05 - val_loss: 8.0046e-04\n",
      "Epoch 968/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7942e-05 - val_loss: 8.0481e-04\n",
      "Epoch 969/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7858e-05 - val_loss: 8.0912e-04\n",
      "Epoch 970/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7775e-05 - val_loss: 8.1340e-04\n",
      "Epoch 971/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7694e-05 - val_loss: 8.1765e-04\n",
      "Epoch 972/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7614e-05 - val_loss: 8.2188e-04\n",
      "Epoch 973/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7536e-05 - val_loss: 8.2606e-04\n",
      "Epoch 974/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7460e-05 - val_loss: 8.3022e-04\n",
      "Epoch 975/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7385e-05 - val_loss: 8.3434e-04\n",
      "Epoch 976/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7311e-05 - val_loss: 8.3843e-04\n",
      "Epoch 977/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7239e-05 - val_loss: 8.4249e-04\n",
      "Epoch 978/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7168e-05 - val_loss: 8.4652e-04\n",
      "Epoch 979/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7099e-05 - val_loss: 8.5052e-04\n",
      "Epoch 980/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7031e-05 - val_loss: 8.5449e-04\n",
      "Epoch 981/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6965e-05 - val_loss: 8.5842e-04\n",
      "Epoch 982/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6900e-05 - val_loss: 8.6232e-04\n",
      "Epoch 983/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6836e-05 - val_loss: 8.6618e-04\n",
      "Epoch 984/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.6773e-05 - val_loss: 8.7002e-04\n",
      "Epoch 985/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6712e-05 - val_loss: 8.7383e-04\n",
      "Epoch 986/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6651e-05 - val_loss: 8.7761e-04\n",
      "Epoch 987/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6593e-05 - val_loss: 8.8135e-04\n",
      "Epoch 988/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6535e-05 - val_loss: 8.8506e-04\n",
      "Epoch 989/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6478e-05 - val_loss: 8.8874e-04\n",
      "Epoch 990/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6422e-05 - val_loss: 8.9239e-04\n",
      "Epoch 991/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6368e-05 - val_loss: 8.9601e-04\n",
      "Epoch 992/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6315e-05 - val_loss: 8.9960e-04\n",
      "Epoch 993/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6262e-05 - val_loss: 9.0315e-04\n",
      "Epoch 994/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6211e-05 - val_loss: 9.0668e-04\n",
      "Epoch 995/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6161e-05 - val_loss: 9.1017e-04\n",
      "Epoch 996/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6112e-05 - val_loss: 9.1364e-04\n",
      "Epoch 997/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6064e-05 - val_loss: 9.1707e-04\n",
      "Epoch 998/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6016e-05 - val_loss: 9.2048e-04\n",
      "Epoch 999/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5970e-05 - val_loss: 9.2385e-04\n",
      "Epoch 1000/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5925e-05 - val_loss: 9.2719e-04\n",
      "Epoch 1001/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5880e-05 - val_loss: 9.3051e-04\n",
      "Epoch 1002/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5837e-05 - val_loss: 9.3379e-04\n",
      "Epoch 1003/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5794e-05 - val_loss: 9.3704e-04\n",
      "Epoch 1004/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5752e-05 - val_loss: 9.4026e-04\n",
      "Epoch 1005/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5711e-05 - val_loss: 9.4346e-04\n",
      "Epoch 1006/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5671e-05 - val_loss: 9.4663e-04\n",
      "Epoch 1007/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5631e-05 - val_loss: 9.4976e-04\n",
      "Epoch 1008/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5593e-05 - val_loss: 9.5286e-04\n",
      "Epoch 1009/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5555e-05 - val_loss: 9.5594e-04\n",
      "Epoch 1010/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5518e-05 - val_loss: 9.5899e-04\n",
      "Epoch 1011/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5481e-05 - val_loss: 9.6201e-04\n",
      "Epoch 1012/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5446e-05 - val_loss: 9.6500e-04\n",
      "Epoch 1013/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5411e-05 - val_loss: 9.6796e-04\n",
      "Epoch 1014/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5377e-05 - val_loss: 9.7089e-04\n",
      "Epoch 1015/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5343e-05 - val_loss: 9.7380e-04\n",
      "Epoch 1016/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5310e-05 - val_loss: 9.7667e-04\n",
      "Epoch 1017/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5278e-05 - val_loss: 9.7952e-04\n",
      "Epoch 1018/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5247e-05 - val_loss: 9.8234e-04\n",
      "Epoch 1019/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5216e-05 - val_loss: 9.8513e-04\n",
      "Epoch 1020/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5185e-05 - val_loss: 9.8790e-04\n",
      "Epoch 1021/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5156e-05 - val_loss: 9.9063e-04\n",
      "Epoch 1022/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5127e-05 - val_loss: 9.9335e-04\n",
      "Epoch 1023/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5098e-05 - val_loss: 9.9603e-04\n",
      "Epoch 1024/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5070e-05 - val_loss: 9.9868e-04\n",
      "Epoch 1025/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5043e-05 - val_loss: 0.0010\n",
      "Epoch 1026/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5016e-05 - val_loss: 0.0010\n",
      "Epoch 1027/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4990e-05 - val_loss: 0.0010\n",
      "Epoch 1028/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4964e-05 - val_loss: 0.0010\n",
      "Epoch 1029/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4939e-05 - val_loss: 0.0010\n",
      "Epoch 1030/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4914e-05 - val_loss: 0.0010\n",
      "Epoch 1031/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4890e-05 - val_loss: 0.0010\n",
      "Epoch 1032/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4866e-05 - val_loss: 0.0010\n",
      "Epoch 1033/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4843e-05 - val_loss: 0.0010\n",
      "Epoch 1034/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4820e-05 - val_loss: 0.0010\n",
      "Epoch 1035/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4798e-05 - val_loss: 0.0010\n",
      "Epoch 1036/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4776e-05 - val_loss: 0.0010\n",
      "Epoch 1037/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4754e-05 - val_loss: 0.0010\n",
      "Epoch 1038/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4733e-05 - val_loss: 0.0010\n",
      "Epoch 1039/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4713e-05 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1040/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4693e-05 - val_loss: 0.0010\n",
      "Epoch 1041/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4673e-05 - val_loss: 0.0010\n",
      "Epoch 1042/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4653e-05 - val_loss: 0.0010\n",
      "Epoch 1043/1200\n",
      "5/5 [==============================] - 0s 957us/step - loss: 1.4634e-05 - val_loss: 0.0010\n",
      "Epoch 1044/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4615e-05 - val_loss: 0.0010\n",
      "Epoch 1045/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4597e-05 - val_loss: 0.0010\n",
      "Epoch 1046/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4579e-05 - val_loss: 0.0011\n",
      "Epoch 1047/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4562e-05 - val_loss: 0.0011\n",
      "Epoch 1048/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4544e-05 - val_loss: 0.0011\n",
      "Epoch 1049/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4527e-05 - val_loss: 0.0011\n",
      "Epoch 1050/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4511e-05 - val_loss: 0.0011\n",
      "Epoch 1051/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4495e-05 - val_loss: 0.0011\n",
      "Epoch 1052/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4479e-05 - val_loss: 0.0011\n",
      "Epoch 1053/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4463e-05 - val_loss: 0.0011\n",
      "Epoch 1054/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4448e-05 - val_loss: 0.0011\n",
      "Epoch 1055/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4433e-05 - val_loss: 0.0011\n",
      "Epoch 1056/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4418e-05 - val_loss: 0.0011\n",
      "Epoch 1057/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4403e-05 - val_loss: 0.0011\n",
      "Epoch 1058/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4389e-05 - val_loss: 0.0011\n",
      "Epoch 1059/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4375e-05 - val_loss: 0.0011\n",
      "Epoch 1060/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4362e-05 - val_loss: 0.0011\n",
      "Epoch 1061/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4348e-05 - val_loss: 0.0011\n",
      "Epoch 1062/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4335e-05 - val_loss: 0.0011\n",
      "Epoch 1063/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4322e-05 - val_loss: 0.0011\n",
      "Epoch 1064/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4310e-05 - val_loss: 0.0011\n",
      "Epoch 1065/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4297e-05 - val_loss: 0.0011\n",
      "Epoch 1066/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4285e-05 - val_loss: 0.0011\n",
      "Epoch 1067/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4273e-05 - val_loss: 0.0011\n",
      "Epoch 1068/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4262e-05 - val_loss: 0.0011\n",
      "Epoch 1069/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4250e-05 - val_loss: 0.0011\n",
      "Epoch 1070/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4239e-05 - val_loss: 0.0011\n",
      "Epoch 1071/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4228e-05 - val_loss: 0.0011\n",
      "Epoch 1072/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4217e-05 - val_loss: 0.0011\n",
      "Epoch 1073/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4206e-05 - val_loss: 0.0011\n",
      "Epoch 1074/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4196e-05 - val_loss: 0.0011\n",
      "Epoch 1075/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4185e-05 - val_loss: 0.0011\n",
      "Epoch 1076/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4175e-05 - val_loss: 0.0011\n",
      "Epoch 1077/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4166e-05 - val_loss: 0.0011\n",
      "Epoch 1078/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4156e-05 - val_loss: 0.0011\n",
      "Epoch 1079/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4146e-05 - val_loss: 0.0011\n",
      "Epoch 1080/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4137e-05 - val_loss: 0.0011\n",
      "Epoch 1081/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4128e-05 - val_loss: 0.0011\n",
      "Epoch 1082/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4119e-05 - val_loss: 0.0011\n",
      "Epoch 1083/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4110e-05 - val_loss: 0.0011\n",
      "Epoch 1084/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4101e-05 - val_loss: 0.0011\n",
      "Epoch 1085/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4093e-05 - val_loss: 0.0011\n",
      "Epoch 1086/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4084e-05 - val_loss: 0.0011\n",
      "Epoch 1087/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4076e-05 - val_loss: 0.0011\n",
      "Epoch 1088/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4068e-05 - val_loss: 0.0011\n",
      "Epoch 1089/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4060e-05 - val_loss: 0.0011\n",
      "Epoch 1090/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4052e-05 - val_loss: 0.0011\n",
      "Epoch 1091/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4044e-05 - val_loss: 0.0011\n",
      "Epoch 1092/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4037e-05 - val_loss: 0.0011\n",
      "Epoch 1093/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4029e-05 - val_loss: 0.0011\n",
      "Epoch 1094/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4022e-05 - val_loss: 0.0011\n",
      "Epoch 1095/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4015e-05 - val_loss: 0.0011\n",
      "Epoch 1096/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4007e-05 - val_loss: 0.0011\n",
      "Epoch 1097/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4000e-05 - val_loss: 0.0011\n",
      "Epoch 1098/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3994e-05 - val_loss: 0.0011\n",
      "Epoch 1099/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3987e-05 - val_loss: 0.0011\n",
      "Epoch 1100/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3980e-05 - val_loss: 0.0011\n",
      "Epoch 1101/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3974e-05 - val_loss: 0.0011\n",
      "Epoch 1102/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3967e-05 - val_loss: 0.0011\n",
      "Epoch 1103/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3961e-05 - val_loss: 0.0011\n",
      "Epoch 1104/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3955e-05 - val_loss: 0.0011\n",
      "Epoch 1105/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3949e-05 - val_loss: 0.0011\n",
      "Epoch 1106/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3943e-05 - val_loss: 0.0011\n",
      "Epoch 1107/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3937e-05 - val_loss: 0.0011\n",
      "Epoch 1108/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3931e-05 - val_loss: 0.0011\n",
      "Epoch 1109/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3925e-05 - val_loss: 0.0011\n",
      "Epoch 1110/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3919e-05 - val_loss: 0.0011\n",
      "Epoch 1111/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3914e-05 - val_loss: 0.0011\n",
      "Epoch 1112/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3908e-05 - val_loss: 0.0011\n",
      "Epoch 1113/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3903e-05 - val_loss: 0.0011\n",
      "Epoch 1114/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3898e-05 - val_loss: 0.0011\n",
      "Epoch 1115/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3892e-05 - val_loss: 0.0011\n",
      "Epoch 1116/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3887e-05 - val_loss: 0.0011\n",
      "Epoch 1117/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3882e-05 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1118/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3877e-05 - val_loss: 0.0011\n",
      "Epoch 1119/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3872e-05 - val_loss: 0.0012\n",
      "Epoch 1120/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3867e-05 - val_loss: 0.0012\n",
      "Epoch 1121/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3862e-05 - val_loss: 0.0012\n",
      "Epoch 1122/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3858e-05 - val_loss: 0.0012\n",
      "Epoch 1123/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3853e-05 - val_loss: 0.0012\n",
      "Epoch 1124/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3848e-05 - val_loss: 0.0012\n",
      "Epoch 1125/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3844e-05 - val_loss: 0.0012\n",
      "Epoch 1126/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3839e-05 - val_loss: 0.0012\n",
      "Epoch 1127/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3835e-05 - val_loss: 0.0012\n",
      "Epoch 1128/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3830e-05 - val_loss: 0.0012\n",
      "Epoch 1129/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3826e-05 - val_loss: 0.0012\n",
      "Epoch 1130/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3822e-05 - val_loss: 0.0012\n",
      "Epoch 1131/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3817e-05 - val_loss: 0.0012\n",
      "Epoch 1132/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3813e-05 - val_loss: 0.0012\n",
      "Epoch 1133/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3809e-05 - val_loss: 0.0012\n",
      "Epoch 1134/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3805e-05 - val_loss: 0.0012\n",
      "Epoch 1135/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3801e-05 - val_loss: 0.0012\n",
      "Epoch 1136/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3797e-05 - val_loss: 0.0012\n",
      "Epoch 1137/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3793e-05 - val_loss: 0.0012\n",
      "Epoch 1138/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3789e-05 - val_loss: 0.0012\n",
      "Epoch 1139/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3785e-05 - val_loss: 0.0012\n",
      "Epoch 1140/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3781e-05 - val_loss: 0.0012\n",
      "Epoch 1141/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3778e-05 - val_loss: 0.0012\n",
      "Epoch 1142/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3774e-05 - val_loss: 0.0012\n",
      "Epoch 1143/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3770e-05 - val_loss: 0.0012\n",
      "Epoch 1144/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3767e-05 - val_loss: 0.0012\n",
      "Epoch 1145/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3763e-05 - val_loss: 0.0012\n",
      "Epoch 1146/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3759e-05 - val_loss: 0.0012\n",
      "Epoch 1147/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3756e-05 - val_loss: 0.0012\n",
      "Epoch 1148/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3752e-05 - val_loss: 0.0012\n",
      "Epoch 1149/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3749e-05 - val_loss: 0.0012\n",
      "Epoch 1150/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3745e-05 - val_loss: 0.0012\n",
      "Epoch 1151/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3742e-05 - val_loss: 0.0012\n",
      "Epoch 1152/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3739e-05 - val_loss: 0.0012\n",
      "Epoch 1153/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3735e-05 - val_loss: 0.0012\n",
      "Epoch 1154/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3732e-05 - val_loss: 0.0012\n",
      "Epoch 1155/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3729e-05 - val_loss: 0.0012\n",
      "Epoch 1156/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3725e-05 - val_loss: 0.0012\n",
      "Epoch 1157/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3722e-05 - val_loss: 0.0012\n",
      "Epoch 1158/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3719e-05 - val_loss: 0.0012\n",
      "Epoch 1159/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3716e-05 - val_loss: 0.0012\n",
      "Epoch 1160/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3713e-05 - val_loss: 0.0012\n",
      "Epoch 1161/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3709e-05 - val_loss: 0.0012\n",
      "Epoch 1162/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3706e-05 - val_loss: 0.0012\n",
      "Epoch 1163/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3703e-05 - val_loss: 0.0012\n",
      "Epoch 1164/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3700e-05 - val_loss: 0.0012\n",
      "Epoch 1165/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3697e-05 - val_loss: 0.0012\n",
      "Epoch 1166/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3694e-05 - val_loss: 0.0012\n",
      "Epoch 1167/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3691e-05 - val_loss: 0.0012\n",
      "Epoch 1168/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3688e-05 - val_loss: 0.0012\n",
      "Epoch 1169/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3685e-05 - val_loss: 0.0012\n",
      "Epoch 1170/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3682e-05 - val_loss: 0.0012\n",
      "Epoch 1171/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3679e-05 - val_loss: 0.0012\n",
      "Epoch 1172/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3677e-05 - val_loss: 0.0012\n",
      "Epoch 1173/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3674e-05 - val_loss: 0.0012\n",
      "Epoch 1174/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3671e-05 - val_loss: 0.0012\n",
      "Epoch 1175/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3668e-05 - val_loss: 0.0012\n",
      "Epoch 1176/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3665e-05 - val_loss: 0.0012\n",
      "Epoch 1177/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3662e-05 - val_loss: 0.0012\n",
      "Epoch 1178/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3660e-05 - val_loss: 0.0012\n",
      "Epoch 1179/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3657e-05 - val_loss: 0.0012\n",
      "Epoch 1180/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3654e-05 - val_loss: 0.0012\n",
      "Epoch 1181/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3651e-05 - val_loss: 0.0012\n",
      "Epoch 1182/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3649e-05 - val_loss: 0.0012\n",
      "Epoch 1183/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3646e-05 - val_loss: 0.0012\n",
      "Epoch 1184/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3643e-05 - val_loss: 0.0012\n",
      "Epoch 1185/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3641e-05 - val_loss: 0.0012\n",
      "Epoch 1186/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3638e-05 - val_loss: 0.0012\n",
      "Epoch 1187/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3635e-05 - val_loss: 0.0012\n",
      "Epoch 1188/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3633e-05 - val_loss: 0.0012\n",
      "Epoch 1189/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3630e-05 - val_loss: 0.0012\n",
      "Epoch 1190/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3627e-05 - val_loss: 0.0012\n",
      "Epoch 1191/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3625e-05 - val_loss: 0.0012\n",
      "Epoch 1192/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3622e-05 - val_loss: 0.0012\n",
      "Epoch 1193/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3620e-05 - val_loss: 0.0012\n",
      "Epoch 1194/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3617e-05 - val_loss: 0.0012\n",
      "Epoch 1195/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3614e-05 - val_loss: 0.0012\n",
      "Epoch 1196/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3612e-05 - val_loss: 0.0012\n",
      "Epoch 1197/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3609e-05 - val_loss: 0.0012\n",
      "Epoch 1198/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3607e-05 - val_loss: 0.0012\n",
      "Epoch 1199/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3604e-05 - val_loss: 0.0012\n",
      "Epoch 1200/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3602e-05 - val_loss: 0.0012\n"
     ]
    }
   ],
   "source": [
    "# set epochs to 1200\n",
    "model_overfitting = Sequential()\n",
    "model_overfitting.add(LSTM(10, input_shape=(1,1)))\n",
    "model_overfitting.add(Dense(1, activation='linear'))\n",
    "\n",
    "model_overfitting.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "X, y = get_train()\n",
    "val_X, val_y = get_validation()\n",
    "history_overfitting = model_overfitting.fit(X, y, epochs=1200, validation_data=(val_X, val_y), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRERaRYlERERaRYlERERaRYlERERa5f8HZzkzjGO4ug8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181bad66a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history_overfitting.history['loss'][500:])\n",
    "pyplot.plot(history_overfitting.history['val_loss'][500:])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Champion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/650\n",
      "5/5 [==============================] - 2s 457ms/step - loss: 0.1169 - val_loss: 0.7030\n",
      "Epoch 2/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1155 - val_loss: 0.6980\n",
      "Epoch 3/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1140 - val_loss: 0.6931\n",
      "Epoch 4/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1126 - val_loss: 0.6882\n",
      "Epoch 5/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1112 - val_loss: 0.6833\n",
      "Epoch 6/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1098 - val_loss: 0.6784\n",
      "Epoch 7/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1084 - val_loss: 0.6736\n",
      "Epoch 8/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1070 - val_loss: 0.6688\n",
      "Epoch 9/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1057 - val_loss: 0.6640\n",
      "Epoch 10/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1043 - val_loss: 0.6592\n",
      "Epoch 11/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1030 - val_loss: 0.6545\n",
      "Epoch 12/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1016 - val_loss: 0.6498\n",
      "Epoch 13/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1003 - val_loss: 0.6451\n",
      "Epoch 14/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0990 - val_loss: 0.6404\n",
      "Epoch 15/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0977 - val_loss: 0.6358\n",
      "Epoch 16/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0965 - val_loss: 0.6312\n",
      "Epoch 17/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.6266\n",
      "Epoch 18/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.6220\n",
      "Epoch 19/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0927 - val_loss: 0.6175\n",
      "Epoch 20/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0915 - val_loss: 0.6130\n",
      "Epoch 21/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0902 - val_loss: 0.6085\n",
      "Epoch 22/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0890 - val_loss: 0.6041\n",
      "Epoch 23/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0878 - val_loss: 0.5996\n",
      "Epoch 24/650\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.5953\n",
      "Epoch 25/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0855 - val_loss: 0.5909\n",
      "Epoch 26/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0843 - val_loss: 0.5866\n",
      "Epoch 27/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0832 - val_loss: 0.5823\n",
      "Epoch 28/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0821 - val_loss: 0.5780\n",
      "Epoch 29/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.5738\n",
      "Epoch 30/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.5696\n",
      "Epoch 31/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.5654\n",
      "Epoch 32/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0777 - val_loss: 0.5613\n",
      "Epoch 33/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.5571\n",
      "Epoch 34/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.5530\n",
      "Epoch 35/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.5490\n",
      "Epoch 36/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.5449\n",
      "Epoch 37/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.5409\n",
      "Epoch 38/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.5369\n",
      "Epoch 39/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.5330\n",
      "Epoch 40/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.5290\n",
      "Epoch 41/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0685 - val_loss: 0.5251\n",
      "Epoch 42/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0675 - val_loss: 0.5212\n",
      "Epoch 43/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.5173\n",
      "Epoch 44/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.5135\n",
      "Epoch 45/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.5097\n",
      "Epoch 46/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0638 - val_loss: 0.5059\n",
      "Epoch 47/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0629 - val_loss: 0.5021\n",
      "Epoch 48/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.4984\n",
      "Epoch 49/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.4947\n",
      "Epoch 50/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0602 - val_loss: 0.4909\n",
      "Epoch 51/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.4873\n",
      "Epoch 52/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.4836\n",
      "Epoch 53/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.4800\n",
      "Epoch 54/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0568 - val_loss: 0.4764\n",
      "Epoch 55/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.4728\n",
      "Epoch 56/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0551 - val_loss: 0.4692\n",
      "Epoch 57/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.4657\n",
      "Epoch 58/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.4622\n",
      "Epoch 59/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0527 - val_loss: 0.4587\n",
      "Epoch 60/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.4552\n",
      "Epoch 61/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0512 - val_loss: 0.4517\n",
      "Epoch 62/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.4483\n",
      "Epoch 63/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.4449\n",
      "Epoch 64/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0489 - val_loss: 0.4414\n",
      "Epoch 65/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0482 - val_loss: 0.4381\n",
      "Epoch 66/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0474 - val_loss: 0.4347\n",
      "Epoch 67/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.4314\n",
      "Epoch 68/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0460 - val_loss: 0.4280\n",
      "Epoch 69/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0453 - val_loss: 0.4247\n",
      "Epoch 70/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0446 - val_loss: 0.4215\n",
      "Epoch 71/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.4182\n",
      "Epoch 72/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0433 - val_loss: 0.4150\n",
      "Epoch 73/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0426 - val_loss: 0.4117\n",
      "Epoch 74/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.4085\n",
      "Epoch 75/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.4053\n",
      "Epoch 76/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.4022\n",
      "Epoch 77/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.3990\n",
      "Epoch 78/650\n",
      "5/5 [==============================] - 0s 939us/step - loss: 0.0395 - val_loss: 0.3959\n",
      "Epoch 79/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0389 - val_loss: 0.3928\n",
      "Epoch 80/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.3897\n",
      "Epoch 81/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0377 - val_loss: 0.3867\n",
      "Epoch 82/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0371 - val_loss: 0.3836\n",
      "Epoch 83/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0365 - val_loss: 0.3806\n",
      "Epoch 84/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.3776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.3746\n",
      "Epoch 86/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0349 - val_loss: 0.3716\n",
      "Epoch 87/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0343 - val_loss: 0.3687\n",
      "Epoch 88/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0338 - val_loss: 0.3657\n",
      "Epoch 89/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0333 - val_loss: 0.3628\n",
      "Epoch 90/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.3599\n",
      "Epoch 91/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0323 - val_loss: 0.3570\n",
      "Epoch 92/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0318 - val_loss: 0.3542\n",
      "Epoch 93/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.3514\n",
      "Epoch 94/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.3486\n",
      "Epoch 95/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0304 - val_loss: 0.3458\n",
      "Epoch 96/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.3430\n",
      "Epoch 97/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.3402\n",
      "Epoch 98/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0290 - val_loss: 0.3375\n",
      "Epoch 99/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.3348\n",
      "Epoch 100/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.3321\n",
      "Epoch 101/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0277 - val_loss: 0.3294\n",
      "Epoch 102/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0273 - val_loss: 0.3268\n",
      "Epoch 103/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0269 - val_loss: 0.3242\n",
      "Epoch 104/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0265 - val_loss: 0.3216\n",
      "Epoch 105/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.3190\n",
      "Epoch 106/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0258 - val_loss: 0.3164\n",
      "Epoch 107/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0254 - val_loss: 0.3139\n",
      "Epoch 108/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0251 - val_loss: 0.3114\n",
      "Epoch 109/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.3089\n",
      "Epoch 110/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.3064\n",
      "Epoch 111/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0240 - val_loss: 0.3039\n",
      "Epoch 112/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.3015\n",
      "Epoch 113/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.2991\n",
      "Epoch 114/650\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0230 - val_loss: 0.2967\n",
      "Epoch 115/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.2943\n",
      "Epoch 116/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0224 - val_loss: 0.2920\n",
      "Epoch 117/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.2896\n",
      "Epoch 118/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0218 - val_loss: 0.2873\n",
      "Epoch 119/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0216 - val_loss: 0.2851\n",
      "Epoch 120/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.2828\n",
      "Epoch 121/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.2806\n",
      "Epoch 122/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0208 - val_loss: 0.2784\n",
      "Epoch 123/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.2762\n",
      "Epoch 124/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.2740\n",
      "Epoch 125/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.2719\n",
      "Epoch 126/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.2697\n",
      "Epoch 127/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.2676\n",
      "Epoch 128/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.2656\n",
      "Epoch 129/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.2635\n",
      "Epoch 130/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.2615\n",
      "Epoch 131/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.2595\n",
      "Epoch 132/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.2575\n",
      "Epoch 133/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.2556\n",
      "Epoch 134/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.2536\n",
      "Epoch 135/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.2517\n",
      "Epoch 136/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.2498\n",
      "Epoch 137/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.2480\n",
      "Epoch 138/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.2461\n",
      "Epoch 139/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.2443\n",
      "Epoch 140/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.2425\n",
      "Epoch 141/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.2407\n",
      "Epoch 142/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.2390\n",
      "Epoch 143/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.2372\n",
      "Epoch 144/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.2355\n",
      "Epoch 145/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.2338\n",
      "Epoch 146/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.2322\n",
      "Epoch 147/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.2305\n",
      "Epoch 148/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.2289\n",
      "Epoch 149/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.2273\n",
      "Epoch 150/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.2258\n",
      "Epoch 151/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.2242\n",
      "Epoch 152/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.2227\n",
      "Epoch 153/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.2212\n",
      "Epoch 154/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.2197\n",
      "Epoch 155/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.2183\n",
      "Epoch 156/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.2168\n",
      "Epoch 157/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.2154\n",
      "Epoch 158/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.2140\n",
      "Epoch 159/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.2126\n",
      "Epoch 160/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.2113\n",
      "Epoch 161/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.2099\n",
      "Epoch 162/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.2086\n",
      "Epoch 163/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.2073\n",
      "Epoch 164/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.2061\n",
      "Epoch 165/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.2048\n",
      "Epoch 166/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.2036\n",
      "Epoch 167/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.2024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.2012\n",
      "Epoch 169/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.2000\n",
      "Epoch 170/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.1988\n",
      "Epoch 171/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.1977\n",
      "Epoch 172/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.1966\n",
      "Epoch 173/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.1955\n",
      "Epoch 174/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1944\n",
      "Epoch 175/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1933\n",
      "Epoch 176/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1923\n",
      "Epoch 177/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.1913\n",
      "Epoch 178/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.1902\n",
      "Epoch 179/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1892\n",
      "Epoch 180/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1883\n",
      "Epoch 181/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1873\n",
      "Epoch 182/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.1864\n",
      "Epoch 183/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.1854\n",
      "Epoch 184/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.1845\n",
      "Epoch 185/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.1836\n",
      "Epoch 186/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.1827\n",
      "Epoch 187/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1819\n",
      "Epoch 188/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1810\n",
      "Epoch 189/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.1802\n",
      "Epoch 190/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1793\n",
      "Epoch 191/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1785\n",
      "Epoch 192/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1777\n",
      "Epoch 193/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.1769\n",
      "Epoch 194/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.1761\n",
      "Epoch 195/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1754\n",
      "Epoch 196/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1746\n",
      "Epoch 197/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.1739\n",
      "Epoch 198/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1732\n",
      "Epoch 199/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1724\n",
      "Epoch 200/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1717\n",
      "Epoch 201/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.1710\n",
      "Epoch 202/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.1704\n",
      "Epoch 203/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.1697\n",
      "Epoch 204/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.1690\n",
      "Epoch 205/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.1684\n",
      "Epoch 206/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.1677\n",
      "Epoch 207/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.1671\n",
      "Epoch 208/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1665\n",
      "Epoch 209/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1658\n",
      "Epoch 210/650\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.1652\n",
      "Epoch 211/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1646\n",
      "Epoch 212/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.1640\n",
      "Epoch 213/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.1635\n",
      "Epoch 214/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1629\n",
      "Epoch 215/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1623\n",
      "Epoch 216/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1617\n",
      "Epoch 217/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1612\n",
      "Epoch 218/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1606\n",
      "Epoch 219/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1601\n",
      "Epoch 220/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1596\n",
      "Epoch 221/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1590\n",
      "Epoch 222/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1585\n",
      "Epoch 223/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.1580\n",
      "Epoch 224/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.1575\n",
      "Epoch 225/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1570\n",
      "Epoch 226/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1565\n",
      "Epoch 227/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1560\n",
      "Epoch 228/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1555\n",
      "Epoch 229/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1550\n",
      "Epoch 230/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1545\n",
      "Epoch 231/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1540\n",
      "Epoch 232/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1535\n",
      "Epoch 233/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.1531\n",
      "Epoch 234/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1526\n",
      "Epoch 235/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1521\n",
      "Epoch 236/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1517\n",
      "Epoch 237/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.1512\n",
      "Epoch 238/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1508\n",
      "Epoch 239/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.1503\n",
      "Epoch 240/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1499\n",
      "Epoch 241/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1494\n",
      "Epoch 242/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.1490\n",
      "Epoch 243/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1485\n",
      "Epoch 244/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1481\n",
      "Epoch 245/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1477\n",
      "Epoch 246/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1472\n",
      "Epoch 247/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1468\n",
      "Epoch 248/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1464\n",
      "Epoch 249/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1459\n",
      "Epoch 250/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1451\n",
      "Epoch 252/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1447\n",
      "Epoch 253/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1443\n",
      "Epoch 254/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1438\n",
      "Epoch 255/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1434\n",
      "Epoch 256/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1430\n",
      "Epoch 257/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1426\n",
      "Epoch 258/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1422\n",
      "Epoch 259/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.1418\n",
      "Epoch 260/650\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.1414\n",
      "Epoch 261/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1410\n",
      "Epoch 262/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.1405\n",
      "Epoch 263/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1401\n",
      "Epoch 264/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1397\n",
      "Epoch 265/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1393\n",
      "Epoch 266/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1389\n",
      "Epoch 267/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1385\n",
      "Epoch 268/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1381\n",
      "Epoch 269/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1377\n",
      "Epoch 270/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.1373\n",
      "Epoch 271/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.1369\n",
      "Epoch 272/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1365\n",
      "Epoch 273/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1361\n",
      "Epoch 274/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1357\n",
      "Epoch 275/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1353\n",
      "Epoch 276/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1349\n",
      "Epoch 277/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1345\n",
      "Epoch 278/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1341\n",
      "Epoch 279/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1337\n",
      "Epoch 280/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1333\n",
      "Epoch 281/650\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.1329\n",
      "Epoch 282/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1325\n",
      "Epoch 283/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1321\n",
      "Epoch 284/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1318\n",
      "Epoch 285/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1314\n",
      "Epoch 286/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1310\n",
      "Epoch 287/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1306\n",
      "Epoch 288/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1302\n",
      "Epoch 289/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1298\n",
      "Epoch 290/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1294\n",
      "Epoch 291/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1290\n",
      "Epoch 292/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1286\n",
      "Epoch 293/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1282\n",
      "Epoch 294/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1278\n",
      "Epoch 295/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.1274\n",
      "Epoch 296/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.1270\n",
      "Epoch 297/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.1266\n",
      "Epoch 298/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1262\n",
      "Epoch 299/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1258\n",
      "Epoch 300/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1255\n",
      "Epoch 301/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1251\n",
      "Epoch 302/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1247\n",
      "Epoch 303/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1243\n",
      "Epoch 304/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1239\n",
      "Epoch 305/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.1235\n",
      "Epoch 306/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.1231\n",
      "Epoch 307/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1227\n",
      "Epoch 308/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1223\n",
      "Epoch 309/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1219\n",
      "Epoch 310/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1215\n",
      "Epoch 311/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1211\n",
      "Epoch 312/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1207\n",
      "Epoch 313/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1203\n",
      "Epoch 314/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1200\n",
      "Epoch 315/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1196\n",
      "Epoch 316/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1192\n",
      "Epoch 317/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1188\n",
      "Epoch 318/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1184\n",
      "Epoch 319/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1180\n",
      "Epoch 320/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1176\n",
      "Epoch 321/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1172\n",
      "Epoch 322/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1168\n",
      "Epoch 323/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1164\n",
      "Epoch 324/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1160\n",
      "Epoch 325/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1156\n",
      "Epoch 326/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1152\n",
      "Epoch 327/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1148\n",
      "Epoch 328/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1145\n",
      "Epoch 329/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1141\n",
      "Epoch 330/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1137\n",
      "Epoch 331/650\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.1133\n",
      "Epoch 332/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1129\n",
      "Epoch 333/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.1121\n",
      "Epoch 335/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.1117\n",
      "Epoch 336/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1113\n",
      "Epoch 337/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1109\n",
      "Epoch 338/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1105\n",
      "Epoch 339/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.1101\n",
      "Epoch 340/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1097\n",
      "Epoch 341/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1094\n",
      "Epoch 342/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1090\n",
      "Epoch 343/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.1086\n",
      "Epoch 344/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.1082\n",
      "Epoch 345/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.1078\n",
      "Epoch 346/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1074\n",
      "Epoch 347/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.1070\n",
      "Epoch 348/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1066\n",
      "Epoch 349/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1062\n",
      "Epoch 350/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1058\n",
      "Epoch 351/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1054\n",
      "Epoch 352/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1050\n",
      "Epoch 353/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1046\n",
      "Epoch 354/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1043\n",
      "Epoch 355/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1039\n",
      "Epoch 356/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1035\n",
      "Epoch 357/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1031\n",
      "Epoch 358/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1027\n",
      "Epoch 359/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1023\n",
      "Epoch 360/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.1019\n",
      "Epoch 361/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.1015\n",
      "Epoch 362/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.1011\n",
      "Epoch 363/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.1007\n",
      "Epoch 364/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.1003\n",
      "Epoch 365/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.1000\n",
      "Epoch 366/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0996\n",
      "Epoch 367/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0992\n",
      "Epoch 368/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0988\n",
      "Epoch 369/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0984\n",
      "Epoch 370/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0980\n",
      "Epoch 371/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0976\n",
      "Epoch 372/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0972\n",
      "Epoch 373/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0968\n",
      "Epoch 374/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0964\n",
      "Epoch 375/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0960\n",
      "Epoch 376/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0957\n",
      "Epoch 377/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0953\n",
      "Epoch 378/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0949\n",
      "Epoch 379/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0945\n",
      "Epoch 380/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0941\n",
      "Epoch 381/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0937\n",
      "Epoch 382/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0933\n",
      "Epoch 383/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0929\n",
      "Epoch 384/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0925\n",
      "Epoch 385/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0922\n",
      "Epoch 386/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0918\n",
      "Epoch 387/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0914\n",
      "Epoch 388/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0910\n",
      "Epoch 389/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0906\n",
      "Epoch 390/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0902\n",
      "Epoch 391/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0898\n",
      "Epoch 392/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0894\n",
      "Epoch 393/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0890\n",
      "Epoch 394/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0887\n",
      "Epoch 395/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0883\n",
      "Epoch 396/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0879\n",
      "Epoch 397/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0875\n",
      "Epoch 398/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0871\n",
      "Epoch 399/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0867\n",
      "Epoch 400/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0863\n",
      "Epoch 401/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0860\n",
      "Epoch 402/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0856\n",
      "Epoch 403/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0852\n",
      "Epoch 404/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0848\n",
      "Epoch 405/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0844\n",
      "Epoch 406/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0840\n",
      "Epoch 407/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0836\n",
      "Epoch 408/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0833\n",
      "Epoch 409/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0829\n",
      "Epoch 410/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0825\n",
      "Epoch 411/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0821\n",
      "Epoch 412/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0817\n",
      "Epoch 413/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0813\n",
      "Epoch 414/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0810\n",
      "Epoch 415/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0806\n",
      "Epoch 416/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0798\n",
      "Epoch 418/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0794\n",
      "Epoch 419/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0790\n",
      "Epoch 420/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0787\n",
      "Epoch 421/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0783\n",
      "Epoch 422/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0779\n",
      "Epoch 423/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0775\n",
      "Epoch 424/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0771\n",
      "Epoch 425/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0767\n",
      "Epoch 426/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0764\n",
      "Epoch 427/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0760\n",
      "Epoch 428/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0756\n",
      "Epoch 429/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0752\n",
      "Epoch 430/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0748\n",
      "Epoch 431/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0745\n",
      "Epoch 432/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0741\n",
      "Epoch 433/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0737\n",
      "Epoch 434/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0733\n",
      "Epoch 435/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0729\n",
      "Epoch 436/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0726\n",
      "Epoch 437/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0722\n",
      "Epoch 438/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0718\n",
      "Epoch 439/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0714\n",
      "Epoch 440/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0711\n",
      "Epoch 441/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0707\n",
      "Epoch 442/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0703\n",
      "Epoch 443/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0699\n",
      "Epoch 444/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0696\n",
      "Epoch 445/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0692\n",
      "Epoch 446/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0688\n",
      "Epoch 447/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0684\n",
      "Epoch 448/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0681\n",
      "Epoch 449/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0677\n",
      "Epoch 450/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0673\n",
      "Epoch 451/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0669\n",
      "Epoch 452/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0666\n",
      "Epoch 453/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0662\n",
      "Epoch 454/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0658\n",
      "Epoch 455/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0655\n",
      "Epoch 456/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0651\n",
      "Epoch 457/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0647\n",
      "Epoch 458/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0643\n",
      "Epoch 459/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0640\n",
      "Epoch 460/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0636\n",
      "Epoch 461/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0632\n",
      "Epoch 462/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0629\n",
      "Epoch 463/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0625\n",
      "Epoch 464/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0621\n",
      "Epoch 465/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0618\n",
      "Epoch 466/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0614\n",
      "Epoch 467/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0610\n",
      "Epoch 468/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0607\n",
      "Epoch 469/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0603\n",
      "Epoch 470/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0599\n",
      "Epoch 471/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0596\n",
      "Epoch 472/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0592\n",
      "Epoch 473/650\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0588\n",
      "Epoch 474/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0585\n",
      "Epoch 475/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0581\n",
      "Epoch 476/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0577\n",
      "Epoch 477/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0574\n",
      "Epoch 478/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0570\n",
      "Epoch 479/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0567\n",
      "Epoch 480/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0563\n",
      "Epoch 481/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0559\n",
      "Epoch 482/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0556\n",
      "Epoch 483/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0552\n",
      "Epoch 484/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0549\n",
      "Epoch 485/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0545\n",
      "Epoch 486/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0542\n",
      "Epoch 487/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0538\n",
      "Epoch 488/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0534\n",
      "Epoch 489/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0531\n",
      "Epoch 490/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0527\n",
      "Epoch 491/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0524\n",
      "Epoch 492/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0520\n",
      "Epoch 493/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0517\n",
      "Epoch 494/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0513\n",
      "Epoch 495/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0510\n",
      "Epoch 496/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0506\n",
      "Epoch 497/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0503\n",
      "Epoch 498/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0499\n",
      "Epoch 499/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0492\n",
      "Epoch 501/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0489\n",
      "Epoch 502/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0485\n",
      "Epoch 503/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0482\n",
      "Epoch 504/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0478\n",
      "Epoch 505/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0475\n",
      "Epoch 506/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0471\n",
      "Epoch 507/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0468\n",
      "Epoch 508/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0465\n",
      "Epoch 509/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0461\n",
      "Epoch 510/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0458\n",
      "Epoch 511/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0454\n",
      "Epoch 512/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0451\n",
      "Epoch 513/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0447\n",
      "Epoch 514/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0444\n",
      "Epoch 515/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0441\n",
      "Epoch 516/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0437\n",
      "Epoch 517/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0434\n",
      "Epoch 518/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0431\n",
      "Epoch 519/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0427\n",
      "Epoch 520/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0424\n",
      "Epoch 521/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0421\n",
      "Epoch 522/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0417\n",
      "Epoch 523/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0414\n",
      "Epoch 524/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0411\n",
      "Epoch 525/650\n",
      "5/5 [==============================] - 0s 965us/step - loss: 0.0039 - val_loss: 0.0407\n",
      "Epoch 526/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0404\n",
      "Epoch 527/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0401\n",
      "Epoch 528/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0398\n",
      "Epoch 529/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0394\n",
      "Epoch 530/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0391\n",
      "Epoch 531/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0388\n",
      "Epoch 532/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0385\n",
      "Epoch 533/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0381\n",
      "Epoch 534/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0378\n",
      "Epoch 535/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0375\n",
      "Epoch 536/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0372\n",
      "Epoch 537/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0368\n",
      "Epoch 538/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0365\n",
      "Epoch 539/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0362\n",
      "Epoch 540/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0359\n",
      "Epoch 541/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0356\n",
      "Epoch 542/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0353\n",
      "Epoch 543/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0350\n",
      "Epoch 544/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0346\n",
      "Epoch 545/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0343\n",
      "Epoch 546/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0340\n",
      "Epoch 547/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0337\n",
      "Epoch 548/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0334\n",
      "Epoch 549/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0331\n",
      "Epoch 550/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0328\n",
      "Epoch 551/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0325\n",
      "Epoch 552/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0322\n",
      "Epoch 553/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0319\n",
      "Epoch 554/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0316\n",
      "Epoch 555/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0313\n",
      "Epoch 556/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0310\n",
      "Epoch 557/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0307\n",
      "Epoch 558/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0304\n",
      "Epoch 559/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0301\n",
      "Epoch 560/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0298\n",
      "Epoch 561/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0295\n",
      "Epoch 562/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0292\n",
      "Epoch 563/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0289\n",
      "Epoch 564/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0286\n",
      "Epoch 565/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0283\n",
      "Epoch 566/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0280\n",
      "Epoch 567/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0277\n",
      "Epoch 568/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0275\n",
      "Epoch 569/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0272\n",
      "Epoch 570/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0269\n",
      "Epoch 571/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0266\n",
      "Epoch 572/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0263\n",
      "Epoch 573/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0261\n",
      "Epoch 574/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0258\n",
      "Epoch 575/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0255\n",
      "Epoch 576/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0252\n",
      "Epoch 577/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0249\n",
      "Epoch 578/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0247\n",
      "Epoch 579/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0244\n",
      "Epoch 580/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0241\n",
      "Epoch 581/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0239\n",
      "Epoch 582/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 583/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0233\n",
      "Epoch 584/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0231\n",
      "Epoch 585/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0228\n",
      "Epoch 586/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0225\n",
      "Epoch 587/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0223\n",
      "Epoch 588/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0220\n",
      "Epoch 589/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0218\n",
      "Epoch 590/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0215\n",
      "Epoch 591/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0212\n",
      "Epoch 592/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0210\n",
      "Epoch 593/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0207\n",
      "Epoch 594/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0205\n",
      "Epoch 595/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0202\n",
      "Epoch 596/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0200\n",
      "Epoch 597/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0197\n",
      "Epoch 598/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0195\n",
      "Epoch 599/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0192\n",
      "Epoch 600/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0190\n",
      "Epoch 601/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0188\n",
      "Epoch 602/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0185\n",
      "Epoch 603/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0183\n",
      "Epoch 604/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0180\n",
      "Epoch 605/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0178\n",
      "Epoch 606/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0176\n",
      "Epoch 607/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0173\n",
      "Epoch 608/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0171\n",
      "Epoch 609/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0169\n",
      "Epoch 610/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0166\n",
      "Epoch 611/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0164\n",
      "Epoch 612/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0162\n",
      "Epoch 613/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0160\n",
      "Epoch 614/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0158\n",
      "Epoch 615/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0155\n",
      "Epoch 616/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0153\n",
      "Epoch 617/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0151\n",
      "Epoch 618/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0149\n",
      "Epoch 619/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0147\n",
      "Epoch 620/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0145\n",
      "Epoch 621/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0142\n",
      "Epoch 622/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0140\n",
      "Epoch 623/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0138\n",
      "Epoch 624/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0136\n",
      "Epoch 625/650\n",
      "5/5 [==============================] - 0s 952us/step - loss: 0.0017 - val_loss: 0.0134\n",
      "Epoch 626/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0132\n",
      "Epoch 627/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0130\n",
      "Epoch 628/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0128\n",
      "Epoch 629/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0126\n",
      "Epoch 630/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0124\n",
      "Epoch 631/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0122\n",
      "Epoch 632/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0120\n",
      "Epoch 633/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0118\n",
      "Epoch 634/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0117\n",
      "Epoch 635/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0115\n",
      "Epoch 636/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0113\n",
      "Epoch 637/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0111\n",
      "Epoch 638/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0109\n",
      "Epoch 639/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0107\n",
      "Epoch 640/650\n",
      "5/5 [==============================] - 0s 952us/step - loss: 0.0014 - val_loss: 0.0105\n",
      "Epoch 641/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0104\n",
      "Epoch 642/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0102\n",
      "Epoch 643/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0100\n",
      "Epoch 644/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0098\n",
      "Epoch 645/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0097\n",
      "Epoch 646/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0095\n",
      "Epoch 647/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0093\n",
      "Epoch 648/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0092\n",
      "Epoch 649/650\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0090\n",
      "Epoch 650/650\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0088\n"
     ]
    }
   ],
   "source": [
    "# set epochs to 600\n",
    "model_fitting = Sequential()\n",
    "model_fitting.add(LSTM(10, input_shape=(1,1)))\n",
    "model_fitting.add(Dense(1, activation='linear'))\n",
    "\n",
    "model_fitting.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "X, y = get_train()\n",
    "val_X, val_y = get_val()\n",
    "history_fitting = model_fitting.fit(X, y, epochs=650, validation_data=(val_X, val_y), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTCULBWOMMZX+P649u1jJM1SuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181ba80588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history_fitting.history['loss'])\n",
    "pyplot.plot(history_fitting.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect data across multiple repeats\n",
    "train = DataFrame()\n",
    "val = DataFrame()\n",
    "for i in range(5):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(10, input_shape=(1,1)))\n",
    "\tmodel.add(Dense(1, activation='linear'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\tX,y = get_train()\n",
    "\tvalX, valY = get_val()\n",
    "\t# fit model\n",
    "\thistory = model.fit(X, y, epochs=300, validation_data=(valX, valY), shuffle=False)\n",
    "\t# story history\n",
    "\ttrain[str(i)] = history.history['loss']\n",
    "\tval[str(i)] = history.history['val_loss']\n",
    "\n",
    "# plot train and validation loss across multiple runs\n",
    "pyplot.plot(train, color='blue', label='train')\n",
    "pyplot.plot(val, color='orange', label='validation')\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
