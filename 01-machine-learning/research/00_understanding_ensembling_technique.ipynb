{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Technique "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Max Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = tree.DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3 = LogisticRegression()\n",
    "\n",
    "model1.fit(x_train,y_train)\n",
    "model2.fit(x_train,y_train)\n",
    "model3.fit(x_train,y_train)\n",
    "\n",
    "pred1 = model1.predict(x_test)\n",
    "pred2 = model2.predict(x_test)\n",
    "pred3 = model3.predict(x_test)\n",
    "\n",
    "final_pred = np.array([])\n",
    "\n",
    "for i in range(0,len(x_test)):\n",
    "    final_pred = np.append(final_pred, mode([pred1[i], pred2[i], pred3[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "model1 = LogisticRegression(random_state=1)\n",
    "model2 = tree.DecisionTreeClassifier(random_state=1)\n",
    "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2)], voting='hard')\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = tree.DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3 = LogisticRegression()\n",
    "\n",
    "model1.fit(x_train,y_train)\n",
    "model2.fit(x_train,y_train)\n",
    "model3.fit(x_train,y_train)\n",
    "\n",
    "pred1 = model1.predict_proba(x_test)\n",
    "pred2 = model2.predict_proba(x_test)\n",
    "pred3 = model3.predict_proba(x_test)\n",
    "\n",
    "finalpred = (pred1+pred2+pred3)/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Weighted Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = tree.DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3 = LogisticRegression()\n",
    "\n",
    "model1.fit(x_train,y_train)\n",
    "model2.fit(x_train,y_train)\n",
    "model3.fit(x_train,y_train)\n",
    "\n",
    "pred1 = model1.predict_proba(x_test)\n",
    "pred2 = model2.predict_proba(x_test)\n",
    "pred3 = model3.predict_proba(x_test)\n",
    "\n",
    "finalpred = (pred1*0.3+pred2*0.3+pred3*0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have covered the basic ensemble techniques, letâ€™s move on to understanding the advanced techniques:\n",
    "1. Stacking\n",
    "2. Blending\n",
    "3. Bagging\n",
    "4. Boosting\n",
    "\n",
    "For more detail, please refer to this site: https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
