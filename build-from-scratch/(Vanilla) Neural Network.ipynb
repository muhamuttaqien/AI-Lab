{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Sunday Oct 28, 2018\\n@author: Muh. Angga Muttaqien, AI/ Data Scientist in GRID Inc. Japan\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Sunday Oct 28, 2018\n",
    "@author: Muh. Angga Muttaqien, AI/ Data Scientist in GRID Inc. Japan\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training example, each column is a feature X1, X2 adn X3\n",
    "X = np.array(([0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]), dtype=float)\n",
    "y = np.array(([0], [1], [1], [0]), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define supporting functions\n",
    "\n",
    "# activation function\n",
    "def sigmoid(t):\n",
    "    return 1/(1+np.exp(-t))\n",
    "\n",
    "# derivative of sigmoid\n",
    "def sigmoid_derivative(p):\n",
    "    return p * (1 - p)\n",
    "\n",
    "# calculate loss function\n",
    "def calculate_loss_function(y):\n",
    "    return np.mean(np.square(y - NN.feedforward()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NN class definition\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        self.input = x\n",
    "        self.weights1 = np.random.rand(self.input.shape[1], 4) # considering we have 4 nodes in the hidden layer\n",
    "        self.weights2 = np.random.rand(4, 1) # we have 1 node as output layer (binary classification problem)\n",
    "        self.y = y\n",
    "        self.output = np.zeros(y.shape)\n",
    "        \n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.layer2 = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "        \n",
    "        return self.layer2\n",
    "    \n",
    "    def backprop(self):\n",
    "        d_weights2 = np.dot(self.layer1.T, 2*(self.y - self.output) * sigmoid_derivative(self.output))\n",
    "        d_weights1 = np.dot(self.input.T, np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1))\n",
    " \n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        self.output = self.feedforward()\n",
    "        self.backprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN = NeuralNetwork(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For iteration # 0\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.7125527 ]\n",
      " [0.74591895]\n",
      " [0.74105219]\n",
      " [0.7653895 ]]\n",
      "Loss: \n",
      "0.30629089595413606\n",
      "\n",
      "\n",
      "For iteration # 100\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.40326553]\n",
      " [0.55481511]\n",
      " [0.52563748]\n",
      " [0.55604338]]\n",
      "Loss: \n",
      "0.22375417796739588\n",
      "\n",
      "\n",
      "For iteration # 200\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.14263348]\n",
      " [0.74514261]\n",
      " [0.73157188]\n",
      " [0.33612078]]\n",
      "Loss: \n",
      "0.06758185920151827\n",
      "\n",
      "\n",
      "For iteration # 300\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.06861735]\n",
      " [0.89371942]\n",
      " [0.87655611]\n",
      " [0.1366166 ]]\n",
      "Loss: \n",
      "0.012476597819952685\n",
      "\n",
      "\n",
      "For iteration # 400\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.04618899]\n",
      " [0.93482944]\n",
      " [0.91828523]\n",
      " [0.0857413 ]]\n",
      "Loss: \n",
      "0.005102374510237498\n",
      "\n",
      "\n",
      "For iteration # 500\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.03635886]\n",
      " [0.95135339]\n",
      " [0.93713883]\n",
      " [0.06433184]]\n",
      "Loss: \n",
      "0.002944642986683701\n",
      "\n",
      "\n",
      "For iteration # 600\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.03076309]\n",
      " [0.96019952]\n",
      " [0.94784341]\n",
      " [0.05261675]]\n",
      "Loss: \n",
      "0.0020048194629540416\n",
      "\n",
      "\n",
      "For iteration # 700\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.02708584]\n",
      " [0.9657717 ]\n",
      " [0.95479957]\n",
      " [0.04516622]]\n",
      "Loss: \n",
      "0.001497071463770292\n",
      "\n",
      "\n",
      "For iteration # 800\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.02444914]\n",
      " [0.96964506]\n",
      " [0.95972561]\n",
      " [0.03996481]]\n",
      "Loss: \n",
      "0.0011845988195426538\n",
      "\n",
      "\n",
      "For iteration # 900\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.02244573]\n",
      " [0.97251843]\n",
      " [0.96342429]\n",
      " [0.03609931]]\n",
      "Loss: \n",
      "0.0009749975907215943\n",
      "\n",
      "\n",
      "For iteration # 1000\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.0208596 ]\n",
      " [0.97474992]\n",
      " [0.96632085]\n",
      " [0.03309583]]\n",
      "Loss: \n",
      "0.0008255770657108446\n",
      "\n",
      "\n",
      "For iteration # 1100\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.0195648 ]\n",
      " [0.97654271]\n",
      " [0.9686621 ]\n",
      " [0.03068334]]\n",
      "Loss: \n",
      "0.0007141393663280895\n",
      "\n",
      "\n",
      "For iteration # 1200\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.01848256]\n",
      " [0.97802106]\n",
      " [0.97060153]\n",
      " [0.0286952 ]]\n",
      "Loss: \n",
      "0.0006280908119483989\n",
      "\n",
      "\n",
      "For iteration # 1300\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.01756082]\n",
      " [0.97926553]\n",
      " [0.97223988]\n",
      " [0.02702303]]\n",
      "Loss: \n",
      "0.0005597922615065535\n",
      "\n",
      "\n",
      "For iteration # 1400\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.01676371]\n",
      " [0.98033075]\n",
      " [0.97364617]\n",
      " [0.0255931 ]]\n",
      "Loss: \n",
      "0.0005043581246926721\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# execute this cell to train the NN\n",
    "for i in range(1500): # trains the NN 1500 times (epochs)\n",
    "    if i % 100 == 0:\n",
    "        print(\"For iteration # \" + str(i) + \"\\n\")\n",
    "        print(\"Input: \\n\" + str(X))\n",
    "        print(\"Actual Output: \\n\" + str(y))\n",
    "        print(\"Predicted Output: \\n\" + str(NN.feedforward()))\n",
    "        print(\"Loss: \\n\" + str(calculate_loss_function(y)))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    NN.train(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
