{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(512) # standard normal distribution with mean 0 and std 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.028838863596320152\n",
      "Std: 0.9946354627609253\n"
     ]
    }
   ],
   "source": [
    "print('Mean:',x.mean().item())\n",
    "print('Std:',x.std().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploding Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(512)\n",
    "\n",
    "for i in range(100):\n",
    "    a = torch.randn(512, 512)\n",
    "    x = a @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: nan\n",
      "Std: nan\n"
     ]
    }
   ],
   "source": [
    "print('Mean:',x.mean().item())\n",
    "print('Std:',x.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(512)\n",
    "\n",
    "for i in range(100):\n",
    "    a = torch.randn(512, 512)\n",
    "    x = a @ x\n",
    "    \n",
    "    if torch.isnan(x.std()): break\n",
    "        \n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanishing Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(512)\n",
    "\n",
    "for i in range(100):\n",
    "    a = torch.randn(512, 512) * 0.01\n",
    "    x = a @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.0\n",
      "Std: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Mean:',x.mean().item())\n",
    "print('Std:',x.std().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights Multiplication in Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_layers = 10000\n",
    "n_inputs = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(n_inputs)\n",
    "\n",
    "mean, variance = 0., 0.\n",
    "for i in range(n_layers):\n",
    "    a = torch.randn(n_inputs, n_inputs)\n",
    "    y = a @ x\n",
    "    mean += y.mean().item() \n",
    "    variance += y.pow(2).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.007916836410108954\n",
      "Std: 22.787822588706245\n"
     ]
    }
   ],
   "source": [
    "print('Mean:',mean/ n_layers)\n",
    "print('Std:',math.sqrt(variance/n_layers)) # STD will explode in this hypothetical network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.627416997969522"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(n_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Multiplication w/ Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_layers = 10000\n",
    "n_inputs = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(n_inputs)\n",
    "\n",
    "mean, variance = 0., 0.\n",
    "for i in range(n_layers):\n",
    "    a = torch.randn(n_inputs, n_inputs) * math.sqrt(1./512)\n",
    "    y = a @ x\n",
    "    mean += y.mean().item() \n",
    "    variance += y.pow(2).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.0002587269434472546\n",
      "Std: 0.9993272300424068\n"
     ]
    }
   ],
   "source": [
    "print('Mean:',mean/ n_layers)\n",
    "print('Std:',math.sqrt(variance/n_layers)) # STD will be 1 in this hypothetical network with weight init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    a = torch.randn(n_inputs, n_inputs) * math.sqrt(1./512)\n",
    "    x = a @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.01688116043806076\n",
      "Std: 0.7799294590950012\n"
     ]
    }
   ],
   "source": [
    "print('Mean:',x.mean().item())\n",
    "print('Std:',x.std().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Multiplication w/ Weight Initialization + Tanh Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# non-linear activation function approximately describing real-world phenomena\n",
    "def tanh(x): return torch.tanh(x)\n",
    "x = torch.randn(n_inputs)\n",
    "\n",
    "for i in range(100):\n",
    "    a = torch.randn(n_inputs, n_inputs) * math.sqrt(1./512)\n",
    "    x = tanh(a @ x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.0011068356689065695\n",
      "Std: 0.09315230697393417\n"
     ]
    }
   ],
   "source": [
    "print('Mean:',x.mean().item())\n",
    "print('Std:',x.std().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Weight Init - BAD!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standard_init(m, h): return torch.Tensor(m, h).uniform_(-1, 1) * math.sqrt(1./512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_layers = 100\n",
    "n_inputs = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tanh(x): return torch.tanh(x)\n",
    "x = torch.randn(n_inputs)\n",
    "\n",
    "for i in range(100):\n",
    "    a = standard_init(n_inputs, n_inputs)\n",
    "    x = tanh(a @ x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 6.148139943250872e-16\n",
      "Std: 9.401696196399494e-16\n"
     ]
    }
   ],
   "source": [
    "print('Mean:',x.mean().item())\n",
    "print('Std:',x.std().item()) # the std of layers' activations will cause almost completely vanishing gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/standard_init.png' width=75% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TanH - [Xavier](https://arxiv.org/pdf/1502.01852.pdf) Weight Init - GOOD!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/xavier_formula.png' width=75% />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for symmetric, non-linear activations\n",
    "def xavier_init(m, h): return torch.Tensor(m, h).uniform_(-1, 1) * math.sqrt(6./ (m+h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_layers = 100\n",
    "n_inputs = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tanh(x): return torch.tanh(x)\n",
    "x = torch.randn(n_inputs)\n",
    "\n",
    "for i in range(n_layers):\n",
    "    a = xavier_init(n_inputs, n_inputs)\n",
    "    x = tanh(a @ x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.0012303171679377556\n",
      "Std: 0.048384666442871094\n"
     ]
    }
   ],
   "source": [
    "print('Mean:',x.mean().item())\n",
    "print('Std:',x.std().item()) # the std of layers’ activations around 1 will avoid gradients exploding or vanishing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/xavier_init.png' width=75% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU - Xavier Weight Init - BAD!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_layers = 100\n",
    "n_inputs = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x): return torch.clamp(input=x, min=0.)\n",
    "x = torch.randn(n_inputs)\n",
    "\n",
    "for i in range(n_layers):\n",
    "    a = xavier_init(n_inputs, n_inputs)\n",
    "    x = relu(a @ x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 6.148139943250872e-16\n",
      "Std: 9.401696196399494e-16\n"
     ]
    }
   ],
   "source": [
    "print('Mean:',x.mean().item())\n",
    "print('Std:',x.std().item()) # the std of layers' activations will cause almost completely vanishing gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU - [Kaiming](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) Weight Init - GOOD!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for asymmetric, non-linear activations\n",
    "def kaiming_init(m, h): return torch.randn(m,h) * math.sqrt(2./m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_layers = 100\n",
    "n_inputs = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x): return torch.clamp(input=x, min=0.)\n",
    "x = torch.randn(n_inputs)\n",
    "\n",
    "for i in range(n_layers):\n",
    "    a = kaiming_init(n_inputs, n_inputs)\n",
    "    x = relu(a @ x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.699047327041626\n",
      "Std: 0.9852362275123596\n"
     ]
    }
   ],
   "source": [
    "print('Mean:',x.mean().item())\n",
    "print('Std:',x.std().item()) # the std of layers’ activations around 1 will avoid gradients exploding or vanishing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Courtesy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [Weight Initialization in Neural Networks](https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
