{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import renom as rm\n",
    "from renom.cuda import set_cuda_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muhamuttaqien/xgboost/python-package/ReNom/renom/cuda/__init__.py:28: UserWarning: Couldn't find cuda modules.\n",
      "  warnings.warn(\"Couldn't find cuda modules.\")\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "set_cuda_active(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fully Convolutional Networks 8s\n",
    "class FCN_8s(rm.Model):\n",
    "    def __init__(self, nb_classes):\n",
    "        \"\"\"Class for FCN8. argumnents,\n",
    "        nb_classeses: number of classes\"\"\"\n",
    "        print(\"FCN_8s initialized!\")\n",
    "        \n",
    "        self.conv1_1 = rm.Conv2d(64, padding=1, filter=3)\n",
    "        self.conv1_2 = rm.Conv2d(64, padding=1, filter=3)\n",
    "        self.max_pool1 = rm.MaxPool2d(filter=2, stride=2)\n",
    "        \n",
    "        self.conv2_1 = rm.Conv2d(128, padding=1, filter=3)\n",
    "        self.conv2_2 = rm.Conv2d(128, padding=1, filter=3)\n",
    "        self.max_pool2 = rm.MaxPool2d(filter=2, stride=2)\n",
    "        \n",
    "        self.conv3_1 = rm.Conv2d(256, padding=1, filter=3)\n",
    "        self.conv3_2 = rm.Conv2d(256, padding=1, filter=3)\n",
    "        self.conv3_3 = rm.Conv2d(256, padding=1, filter=3)\n",
    "        self.max_pool3 = rm.MaxPool2d(filter=2, stride=2)\n",
    "        \n",
    "        self.conv4_1 = rm.Conv2d(512, padding=1, filter=3)\n",
    "        self.conv4_2 = rm.Conv2d(512, padding=1, filter=3)\n",
    "        self.conv4_3 = rm.Conv2d(512, padding=1, filter=3)\n",
    "        self.max_pool4 = rm.MaxPool2d(filter=2, stride=2)\n",
    "        \n",
    "        self.conv5_1 = rm.Conv2d(512, padding=1, filter=3)\n",
    "        self.conv5_2 = rm.Conv2d(512, padding=1, filter=3)\n",
    "        self.conv5_3 = rm.Conv2d(512, padding=1, filter=3)\n",
    "        self.max_pool5 = rm.MaxPool2d(filter=2, stride=2)\n",
    "        \n",
    "        self.fc6 = rm.Conv2d(4096, padding=3, filter=7)\n",
    "        self.fc7 = rm.Conv2d(4096, padding=0, filter=1)\n",
    "        \n",
    "        self.drop_out = rm.Dropout(0.5)\n",
    "        \n",
    "        self.score_fr = rm.Conv2d(nb_classes, filter=1)\n",
    "        self.upscore2 = rm.Deconv2d(nb_classes, padding=0, filter=2, stride=2)\n",
    "        self.upscore8 = rm.Deconv2d(nb_classes, padding=0, filter=8, stride=8)\n",
    "        \n",
    "        self.score_pool3 = rm.Conv2d(nb_classes, filter=1)\n",
    "        self.score_pool4 = rm.Conv2d(nb_classes, filter=1)\n",
    "        \n",
    "        self.upscore_pool4 = rm.Deconv2d(nb_classes, padding=0, filter=2, stride=2)\n",
    "        print(help(FCN_8s))\n",
    "\n",
    "    def forward(self, x):\n",
    "        t = x\n",
    "        t = rm.relu(self.conv1_1(t))\n",
    "        t = rm.relu(self.conv1_2(t))\n",
    "        self.c1 = t\n",
    "        t = self.max_pool1(t)\n",
    "        \n",
    "        t = rm.relu(self.conv2_1(t))\n",
    "        t = rm.relu(self.conv2_2(t))\n",
    "        self.c2 = t\n",
    "        t = self.max_pool2(t)\n",
    "        \n",
    "        t = rm.relu(self.conv3_1(t))\n",
    "        t = rm.relu(self.conv3_2(t))\n",
    "        t = rm.relu(self.conv3_3(t))\n",
    "        t = self.max_pool3(t)\n",
    "        self.c3 = t\n",
    "        pool3 = t\n",
    "        \n",
    "        t = rm.relu(self.conv4_1(t))\n",
    "        t = rm.relu(self.conv4_2(t))\n",
    "        t = rm.relu(self.conv4_3(t))\n",
    "        t = self.max_pool4(t)\n",
    "        self.c4 = t\n",
    "        pool4 = t\n",
    "        \n",
    "        t = rm.relu(self.conv5_1(t))\n",
    "        t = rm.relu(self.conv5_2(t))\n",
    "        t = rm.relu(self.conv5_3(t))\n",
    "        self.c5 = t\n",
    "        t = self.max_pool5(t)\n",
    "        \n",
    "        t = rm.relu(self.fc6(t))\n",
    "        t = self.drop_out(t)\n",
    "        fc6 = t\n",
    "        \n",
    "        t = rm.relu(self.fc7(t))\n",
    "        fc7 = t\n",
    "        \n",
    "        t = self.score_fr(t)\n",
    "        score_fr = t\n",
    "        \n",
    "        t = self.upscore2(t)\n",
    "        upscore2 = t\n",
    "        \n",
    "        t = self.score_pool4(pool4)\n",
    "        score_pool4 = t\n",
    "        \n",
    "        t = upscore2 + score_pool4\n",
    "        fuse_pool4 = t\n",
    "        \n",
    "        t = self.score_pool3(pool3)\n",
    "        score_pool3 = t\n",
    "        \n",
    "        t = self.upscore_pool4(fuse_pool4)\n",
    "        upscore_pool4 = t\n",
    "        t = upscore_pool4 + score_pool3\n",
    "        \n",
    "        t = self.upscore8(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epochs = 300\n",
    "opt = rm.Sgd(lr=0.03,momentum=0.8) # rm.Adam(lr=0.00001)\n",
    "lr = [0.03] * 10 + [0.02] * 10 + [0.01] * 10 + [0.008] * 30 + [0.006] * 240\n",
    "N = len(train_keys)\n",
    "val_N = len(val_keys)\n",
    "best_loss = np.inf\n",
    "\n",
    "all_accuracies = [0]*epochs\n",
    "all_train_losses = [0]*epochs\n",
    "all_validation_losses = [0]*epochs\n",
    "all_ious = [0]*epochs\n",
    "\n",
    "CLASS_WEIGHT = 8 # hyperparameter to give more weight to the imbalanced class\n",
    "AUG_PROB = 1.0\n",
    "PLOT_WHILE_TRAINING = False\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    counts = 0\n",
    "    total = 0\n",
    "    total_area = 0\n",
    "    bar = tqdm(range(N//batch_size))\n",
    "    loss = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    opt._lr = lr[epoch]\n",
    "    for j in range(N//batch_size):\n",
    "        with model_FCN.train():\n",
    "            x, y = genr.generate(True, AUG_PROB).__next__()\n",
    "            t = model_FCN(x)\n",
    "            \n",
    "            reg = 0\n",
    "            for layer in model_FCN.iter_models():\n",
    "                if hasattr(layer, \"params\") and hasattr(layer.params, \"w\"):\n",
    "                    reg += rm.sum(layer.params.w*layer.params.w)\n",
    "                    reg_loss = 0.0001*reg/(img_size[0] * img_size[1] * x.shape[0] * 2)\n",
    "            \n",
    "            n, c, _, _ = y.shape\n",
    "            weight_loss = -rm.log(rm.softmax(t) + 1e-8) * y\n",
    "            weight_loss += weight_loss * np.broadcast_to(np.expand_dims(np.argmax(y, axis=1) * CLASS_WEIGHT, axis=1), weight_loss.shape)\n",
    "            l = rm.sum(weight_loss) / (img_size[0] * img_size[1] * x.shape[0]) + reg_loss\n",
    "            \n",
    "        l.grad().update(opt)\n",
    "        bar.update(1)\n",
    "        loss += l.as_ndarray()\n",
    "        \n",
    "    for k in range(val_N//batch_size):\n",
    "        x, y = gen.generate(False).__next__()\n",
    "        t = model_FCN(x)\n",
    "        l = -rm.log(rm.softmax(t) + 1e-8) * y\n",
    "        l += l * np.broadcast_to(np.expand_dims(np.argmax(y, axis=1) * CLASS_WEIGHT, axis=1), l.shape)\n",
    "        l = rm.sum(l) / (img_size[0] * img_size[1] * batch_size)\n",
    "        results = rm.softmax(t)\n",
    "        results = results.as_ndarray()\n",
    "        tmp = 0\n",
    "        \n",
    "        target_index = np.where(np.argmax(y, axis=1).flatten()==1)[0]\n",
    "        \n",
    "        for index in np.where(np.argmax(results, axis=1).flatten()==1)[0]:\n",
    "            if index in target_index:\n",
    "                counts += 1\n",
    "                tmp += 1\n",
    "                \n",
    "        total += np.sum(np.argmax(y, axis=1)==1)\n",
    "        total_area += (np.sum(np.argmax(y, axis=1)==1) + np.sum(np.argmax(results, axis=1)==1) - tmp)\n",
    "        \n",
    "        val_loss += l.as_ndarray()\n",
    "        \n",
    "    # PLOT\n",
    "    if PLOT_WHILE_TRAINING:\n",
    "        fig=plt.figure(figsize=(8, 8))\n",
    "        pred_img = visualize(np.argmax(results[0], axis=0), False)\n",
    "        annot = visualize(np.argmax(y[0], axis=0), False)\n",
    "        fig.add_subplot(1, 4, 1)\n",
    "        plt.imshow(pred_img/255.)\n",
    "        fig.add_subplot(1, 4, 2)\n",
    "        plt.imshow(annot/255.)\n",
    "        fig.add_subplot(1, 4, 3)\n",
    "        plt.imshow(x[0][0], cmap='gray')\n",
    "        fig.add_subplot(1, 4, 4)\n",
    "        plt.imshow(x[0][10], cmap='gray')\n",
    "        plt.show\n",
    "        \n",
    "    iou = counts / total_area\n",
    "    accuracy = counts / total\n",
    "    all_accuracies[epoch] = accuracy\n",
    "    \n",
    "    train_loss = loss/(j+1) # tran loss\n",
    "    all_train_losses[epoch] = train_loss\n",
    "    all_validation_losses[epoch] = val_loss/(k+1)\n",
    "    all_ious[epoch] = iou\n",
    "    \n",
    "    if (val_loss/(k+1)) < best_loss or epoch%25 == 0:\n",
    "        print('Epoch %d, saving the model...' %epoch)\n",
    "        model_FCN.save('../03_results/weights/weight.Augmented_%.1f_best_Angga_FCN_CLASS_WEIGHT_rotate_zoom_%d_epoch%d.hdf5'%(AUG_PROB, CLASS_WEIGHT, epoch))\n",
    "        \n",
    "        best_loss = (val_loss/ (k+1))\n",
    "        bar.set_description(\"epoch {:03d} avg loss:{:6.4f}  val loss:{:6.4f} accuracy:{:6.4f} iou:{:6.4f} val loss is improved\".format(epoch, float((loss/(j+1))), float((val_loss/(k+1))), accuracy, iou))\n",
    "    else:\n",
    "        bar.set_description(\"epoch {:03d} avg loss:{:6.4f}  val loss:{:6.4f} accuracy:{:6.4f} iou:{:6.4f}\".format(epoch, float((loss/(j+1))), float((val_loss/(k+1))), accuracy, iou))\n",
    "        \n",
    "    bar.update(0)\n",
    "    bar.refresh()\n",
    "    bar.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
