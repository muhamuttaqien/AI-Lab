{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rainbow DQN, Deep Q Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import namedtuple, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda: device = torch.device('cuda')\n",
    "else: device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e4)\n",
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.99\n",
    "TAU = 1e-3 # for soft update of target parameters\n",
    "LR = 1e-3\n",
    "PRINT_EVERY = 100\n",
    "UPDATE_EVERY = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-02-06 13:03:09,872] Making new env: MountainCar-v0\n",
      "/Users/angga.muhammad/anaconda3/lib/python3.7/site-packages/gym/envs/registration.py:17: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "ENV_NAME = 'MountainCar-v0'\n",
    "env = gym.make(ENV_NAME).unwrapped; env.seed(90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Display:\n",
      "State space Box(2,)\n",
      "Action space Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "print('Environment Display:')\n",
    "env.reset() # reset environment to a new, random state\n",
    "env.render()\n",
    "\n",
    "print('State space {}'.format(env.observation_space))\n",
    "print('Action space {}'.format(env.action_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Noisy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_features, output_features, sigma_init=0.4, train_mode=True):\n",
    "        \n",
    "        super(NoisyLinear, self).__init__()\n",
    "        \n",
    "        self.input_features = input_features\n",
    "        self.output_features = output_features\n",
    "        self.sigma_init = sigma_init\n",
    "        self.train_mode = train_mode\n",
    "        \n",
    "        self.mu_weight = nn.Parameter(torch.FloatTensor(output_features, input_features))\n",
    "        self.sigma_weight = nn.Parameter(torch.FloatTensor(output_features, input_features))\n",
    "        self.register_buffer('epsilon_weight', torch.FloatTensor(output_features, input_features))\n",
    "        \n",
    "        self.mu_bias = nn.Parameter(torch.FloatTensor(output_features))\n",
    "        self.sigma_bias = nn.Parameter(torch.FloatTensor(output_features))\n",
    "        self.register_buffer('epsilon_bias', torch.FloatTensor(output_features))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        \n",
    "        mu_range = 1 / math.sqrt(self.mu_weight.size(1))\n",
    "        \n",
    "        self.mu_weight.data.uniform_(-mu_range, mu_range)\n",
    "        self.sigma_weight.data.fill_(self.sigma_init / math.sqrt(self.sigma_weight.size(1)))\n",
    "        \n",
    "        self.mu_bias.data.uniform_(-mu_range, mu_range)\n",
    "        self.sigma_bias.data.fill_(self.sigma_init / math.sqrt(self.sigma_bias.size(0)))\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        \n",
    "        input_size = self.input_features\n",
    "        epsilon_input = torch.randn(input_size)\n",
    "        epsilon_input = epsilon_input.sign().mul(epsilon_input.abs().sqrt())\n",
    "        \n",
    "        output_size = self.output_features\n",
    "        epsilon_output = torch.randn(output_size)\n",
    "        epsilon_output = epsilon_output.sign().mul(epsilon_output.abs().sqrt())\n",
    "        \n",
    "        self.epsilon_weight.copy_(epsilon_output.ger(epsilon_input))\n",
    "        self.epsilon_bias.copy_(epsilon_output)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        if self.train_mode:\n",
    "            weight = self.mu_weight + self.sigma_weight.mul(autograd.Variable(self.epsilon_weight))\n",
    "            bias = self.mu_bias + self.sigma_bias.mul(autograd.Variable(self.epsilon_bias))\n",
    "        else:\n",
    "            weight = self.mu_weight\n",
    "            bias = self.mu_bias\n",
    "            \n",
    "        return F.linear(x, weight, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build DQN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \"\"\"Define DQN architecture.\"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, atom_size, v_min, v_max, seed, fcl_units=64, fc2_units=64):\n",
    "        \"\"\"Initialize parameters and build model.\"\"\"\n",
    "        \n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.action_size = action_size\n",
    "        self.atom_size = atom_size\n",
    "        \n",
    "        self.v_min = v_min\n",
    "        self.v_max = v_max\n",
    "        \n",
    "        self.fc1_layer = nn.Linear(state_size, fcl_units)\n",
    "        self.fc2_layer = nn.Linear(fcl_units, fc2_units)\n",
    "        \n",
    "        # decompose state & action values\n",
    "        self.noisy1_state_layer = NoisyLinear(fc2_units, fc2_units)\n",
    "        self.noisy2_state_layer = NoisyLinear(fc2_units, atom_size)\n",
    "        \n",
    "        self.noisy1_advantage_layer = NoisyLinear(fc2_units, fc2_units)\n",
    "        self.noisy2_advantage_layer = NoisyLinear(fc2_units, atom_size*action_size)\n",
    "        \n",
    "    def reset_noise(self):\n",
    "        self.noisy1_state_layer.reset_noise(); self.noisy2_state_layer.reset_noise()\n",
    "        self.noisy1_advantage_layer.reset_noise(); self.noisy2_advantage_layer.reset_noise()\n",
    "        \n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state into action values.\"\"\"\n",
    "        \n",
    "        batch_size = state.size(0)\n",
    "        \n",
    "        state = F.relu(self.fc1_layer(state))\n",
    "        state = F.relu(self.fc2_layer(state))\n",
    "        \n",
    "        state_value = F.relu(self.noisy1_state_layer(state))\n",
    "        state_value = self.noisy2_state_layer(state_value)\n",
    "        \n",
    "        advantage_value = F.relu(self.noisy1_advantage_layer(state))\n",
    "        advantage_value = self.noisy2_advantage_layer(advantage_value)\n",
    "        \n",
    "        state_value = state_value.view(batch_size, 1, self.atom_size)\n",
    "        advantage_value = advantage_value.view(batch_size, self.action_size, self.atom_size)\n",
    "        \n",
    "        Qsa = state_value + advantage_value - advantage_value.mean(1, keepdim=True)\n",
    "        Qsa = F.softmax(Qsa.view(-1, self.atom_size)).view(-1, self.action_size, self.atom_size)\n",
    "        Qsa = Qsa * torch.linspace(self.v_min, self.v_max, self.atom_size)\n",
    "        \n",
    "        return Qsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Prioritized Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer(object):\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        \"\"\"Initialize a PrioritizedReplayMemory object.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "    \n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayMemory object.\"\"\"\n",
    "        \n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "        \n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to buffer.\"\"\"\n",
    "        \n",
    "        self.memory.append(self.experience(state, action, reward, next_state, done))\n",
    "        \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "        \n",
    "        states = torch.from_numpy(np.vstack([exp.state for exp in experiences if exp is not None])).float()\n",
    "        states = states.to(device)\n",
    "        \n",
    "        actions = torch.from_numpy(np.vstack([exp.action for exp in experiences if exp is not None])).long()\n",
    "        actions = actions.to(device)\n",
    "        \n",
    "        rewards = torch.from_numpy(np.vstack([exp.reward for exp in experiences if exp is not None])).float()\n",
    "        rewards = rewards.to(device)\n",
    "        \n",
    "        next_states = torch.from_numpy(np.vstack([exp.next_state for exp in experiences if exp is not None])).float()\n",
    "        next_states = next_states.to(device)\n",
    "        \n",
    "        dones = torch.from_numpy(np.vstack([exp.done for exp in experiences if exp is not None]).astype(np.uint8)).float()\n",
    "        dones = dones.to(device)\n",
    "        \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Rainbow DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rainbow_DQNAgent():\n",
    "    \"\"\"The agent interacting with and learning from the environment.\"\"\"\n",
    "    \n",
    "    def __init__(self, state_size, action_size, atom_size, v_min, v_max, seed):\n",
    "        \"\"\"Initialize an agent object.\"\"\"\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "        \n",
    "        # Q-Network\n",
    "        self.dqn_net = DQN(state_size, action_size, atom_size, v_min, v_max, seed).to(device)\n",
    "        self.target_net = DQN(state_size, action_size, atom_size, v_min, v_max, seed).to(device)\n",
    "        self.optimizer = optim.Adam(self.dqn_net.parameters(), lr=LR)\n",
    "        \n",
    "        # Replay Buffer\n",
    "        self.buffer = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "        self.time_step = 0\n",
    "        \n",
    "    def memorize(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Save experience in replay buffer.\"\"\"\n",
    "        \n",
    "        self.buffer.add(state, action, reward, next_state, done)\n",
    "    \n",
    "        self.time_step = (self.time_step + 1) % UPDATE_EVERY\n",
    "        if self.time_step == 0:\n",
    "            # if enough samples are available in memory, get random subset and learn\n",
    "            if len(self.buffer) > BATCH_SIZE:\n",
    "                experiences = self.buffer.sample()\n",
    "                self.learn(experiences, GAMMA)\n",
    "            \n",
    "    def act(self, state, eps=0.):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "        \n",
    "        state = autograd.Variable(torch.from_numpy(state).float().unsqueeze(0), volatile=True).to(device)\n",
    "        self.dqn_net.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.dqn_net(state)\n",
    "        self.dqn_net.train()\n",
    "        \n",
    "        return action_values.sum(2).max(1)[1].numpy()[0]\n",
    "    \n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update value parameters using given batch of experience tuples.\"\"\"\n",
    "    \n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "        \n",
    "        distribution, Z_delta, supports = self.project_distribution(next_states, rewards, dones)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # get index of maximum value for next state\n",
    "        Qsa_next = self.dqn_net(next_states).detach()\n",
    "        _, action_max = Qsa_next.max(1)\n",
    "\n",
    "        # get max predicted Q values (for next states) from target network\n",
    "        Q_target_next = self.target_net(next_states).detach().gather(1, action_max.unsqueeze(1)) * supports\n",
    "        \n",
    "        # compute Q target\n",
    "        Q_target = rewards + (gamma * Q_target_next * (1 - dones))\n",
    "        \n",
    "        # get expected Q values from dqn network\n",
    "        actions = actions.unsqueeze(1).expand(actions.size(0), actions.size(1), Q_target_next.size(2))\n",
    "        Q_expected = self.dqn_net(states).gather(1, actions)\n",
    "        Q_expected.data.clamp_(0.01, 0.99)\n",
    "        \n",
    "        # compute loss\n",
    "        loss = - (autograd.Variable(distribution) * Q_expected.log()).sum(1)\n",
    "        loss = loss.mean()\n",
    " \n",
    "        # minimize the loss\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # reset noise for both DQN and target networks\n",
    "        self.dqn_net.reset_noise()\n",
    "        self.target_net.reset_noise()\n",
    "        \n",
    "        # update target network\n",
    "        self.soft_update(self.dqn_net, self.target_net, TAU)\n",
    "        \n",
    "    def project_distribution(self, next_states, rewards, dones):\n",
    "        \n",
    "        batch_size = next_states.shape[0]\n",
    "        \n",
    "        Z_delta = float(self.target_net.v_max - self.target_net.v_min) / (self.target_net.atom_size - 1)\n",
    "        supports = torch.linspace(self.target_net.v_min, self.target_net.v_max, self.target_net.atom_size)\n",
    "\n",
    "        # get index of maximum value for next state\n",
    "        Qsa_next = self.dqn_net(next_states).detach()\n",
    "        _, action_max = Qsa_next.max(1)\n",
    "\n",
    "        # get max predicted Q values (for next states) from target network\n",
    "        Q_target_next = self.target_net(next_states).detach().gather(1, action_max.unsqueeze(1)) * supports\n",
    "        action = Q_target_next.sum(2).max(1)[1]\n",
    "        action = action.unsqueeze(1).unsqueeze(1).expand(Q_target_next.size(0), 1, Q_target_next.size(2))\n",
    "        Q_target_next = Q_target_next.gather(1, action).squeeze(1)\n",
    "        \n",
    "        rewards = rewards.expand_as(Q_target_next)\n",
    "        dones = dones.expand_as(Q_target_next)\n",
    "        supports = supports.expand_as(Q_target_next)\n",
    "        \n",
    "        Tz = rewards + (1 - dones) * 0.99 * supports\n",
    "        Tz = Tz.clamp(min=self.target_net.v_min, max=self.target_net.v_max)\n",
    "        b = (Tz - self.target_net.v_min) / Z_delta\n",
    "        l = b.floor().long()\n",
    "        u = b.ceil().long()\n",
    "        \n",
    "        offsets = torch.linspace(0, (batch_size - 1) * self.target_net.atom_size, batch_size).long()\\\n",
    "                      .unsqueeze(1).expand(batch_size, self.target_net.atom_size)\n",
    "            \n",
    "        distribution = torch.zeros(Q_target_next.size())\n",
    "        distribution.view(-1).index_add_(0, (l + offsets).view(-1), (Q_target_next * (u.float() - b)).view(-1))\n",
    "        distribution.view(-1).index_add_(0, (u + offsets).view(-1), (Q_target_next * (b - l.float())).view(-1))\n",
    "        \n",
    "        return distribution, Z_delta, supports\n",
    "        \n",
    "    def soft_update(self, dqn_net, target_net, tau):\n",
    "        \"\"\"Soft update target network parameters.\"\"\"\n",
    "        \n",
    "        for dqn_param, target_param in zip(dqn_net.parameters(), target_net.parameters()):\n",
    "            target_param.data.copy_(tau*dqn_param.data + (1.0-tau) * target_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent = Rainbow_DQNAgent(state_size=env.observation_space.shape[0], action_size=env.action_space.n, \n",
    "                         atom_size=51, v_min=-10, v_max=10, seed=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watch an untrained agent\n",
    "state = env.reset()\n",
    "for time_step in range(200):\n",
    "    \n",
    "    # select an action\n",
    "    action = agent.act(state)\n",
    "    env.render()\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    state = next_state\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train The Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(num_episodes, max_time=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Train DQN agent.\"\"\"\n",
    "    \n",
    "    scores = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "    eps = eps_start\n",
    "    \n",
    "    for i_episode in range(1, num_episodes+1):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        for time_step in range(max_time):\n",
    "            action = agent.act(state, eps)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            agent.memorize(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        scores_window.append(score)\n",
    "        scores.append(score)\n",
    "        eps = max(eps_end, eps_decay*eps)\n",
    "        \n",
    "        print(f'\\rEpisode: {i_episode}, Average Score: {np.mean(scores_window):.2f}', end='')\n",
    "        \n",
    "        if i_episode % PRINT_EVERY == 0:\n",
    "            print(f'\\rEpisode: {i_episode}, Average Score: {np.mean(scores_window):.2f}')\n",
    "        if np.mean(scores_window) >= -200.0:\n",
    "            print(f'\\nEnvironment solved in {i_episode-100:d} episodes! Average Score: {np.mean(scores_window):.2f}')\n",
    "            if not os.path.exists('./agents/'): os.makedirs('./agents/')\n",
    "            torch.save(agent.dqn_net.state_dict(), f'./agents/Rainbow_DQN_{ENV_NAME}.pth')\n",
    "            \n",
    "    print('Training completed.')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100, Average Score: -1000.00\n",
      "Episode: 200, Average Score: -1000.00\n",
      "Episode: 300, Average Score: -1000.00\n",
      "Episode: 400, Average Score: -1000.00\n",
      "Episode: 500, Average Score: -1000.00\n",
      "Episode: 600, Average Score: -991.430\n",
      "Episode: 700, Average Score: -940.71\n",
      "Episode: 800, Average Score: -1000.00\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "scores = train_agent(num_episodes=800, max_time=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate The Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(np.arange(len(scores)), scores, color='green')\n",
    "plt.xlabel('Num of episodes')\n",
    "plt.ylabel('Score')\n",
    "if not os.path.exists('./images/'): os.makedirs('./images/')\n",
    "plt.savefig('./images/plot_of_agent_evaluation.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¬ Watch The Smart Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights of smart agent\n",
    "# agent.dqn_net.load_state_dict(torch.load(f'./agents/Rainbow_DQN_{ENV_NAME}.pth'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_episodes = 20\n",
    "\n",
    "for i_episode in range(1, num_of_episodes+1):\n",
    "    \n",
    "    state = env.reset()\n",
    "    for time_step in range(200):\n",
    "        \n",
    "        # select an action\n",
    "        action = agent.act(state)\n",
    "        env.render()\n",
    "        \n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
