{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "data = open('data/corpus').read()\n",
    "labels, texts = [], []\n",
    "for i, line in enumerate(data.split(\"\\n\")):\n",
    "    content = line.split()\n",
    "    labels.append(content[0])\n",
    "    texts.append(content[1:])\n",
    "\n",
    "# create a dataframe using texts and lables\n",
    "trainDF = pandas.DataFrame()\n",
    "trainDF['text'] = texts\n",
    "trainDF['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDF = trainDF.astype('str') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      "text     10000 non-null object\n",
      "label    10000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 156.3+ KB\n"
     ]
    }
   ],
   "source": [
    "trainDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Stuning', 'even', 'for', 'the', 'non-gamer:'...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['The', 'best', 'soundtrack', 'ever', 'to', 'a...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Amazing!:', 'This', 'soundtrack', 'is', 'my'...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Excellent', 'Soundtrack:', 'I', 'truly', 'li...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Remember,', 'Pull', 'Your', 'Jaw', 'Off', 'T...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       label\n",
       "0  ['Stuning', 'even', 'for', 'the', 'non-gamer:'...  __label__2\n",
       "1  ['The', 'best', 'soundtrack', 'ever', 'to', 'a...  __label__2\n",
       "2  ['Amazing!:', 'This', 'soundtrack', 'is', 'my'...  __label__2\n",
       "3  ['Excellent', 'Soundtrack:', 'I', 'truly', 'li...  __label__2\n",
       "4  ['Remember,', 'Pull', 'Your', 'Jaw', 'Off', 'T...  __label__2"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'], random_state=1708)\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='\\\\w{1,}', tokenizer=None,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(trainDF['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count = count_vect.transform(train_x)\n",
    "xvalid_count = count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(trainDF['text'])\n",
    "xtrain_tfidf = tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf = tfidf_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(trainDF['text'])\n",
    "xtrain_tfidf_ngram = tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram = tfidf_vect_ngram.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(trainDF['text'])\n",
    "xtrain_tfidf_ngram_chars = tfidf_vect_ngram_chars.transform(train_x) \n",
    "xvalid_tfidf_ngram_chars = tfidf_vect_ngram_chars.transform(valid_x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/wiki-news-300d-1M.vec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-d20b378ef7e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load the pre-trained word-embedding vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membeddings_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/wiki-news-300d-1M.vec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0membeddings_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/wiki-news-300d-1M.vec'"
     ]
    }
   ],
   "source": [
    "# load the pre-trained word-embedding vectors \n",
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('data/wiki-news-300d-1M.vec')):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create a tokenizer \n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(trainDF['text'])\n",
    "word_index = token.word_index\n",
    "\n",
    "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)\n",
    "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=70)\n",
    "\n",
    "# create token-embedding mapping\n",
    "embedding_matrix = numpy.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Text / NLP based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDF['char_count'] = trainDF['text'].apply(len)\n",
    "trainDF['word_count'] = trainDF['text'].apply(lambda x: len(x.split()))\n",
    "trainDF['word_density'] = trainDF['char_count'] / (trainDF['word_count']+1)\n",
    "trainDF['punctuation_count'] = trainDF['text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation)))\n",
    "trainDF['title_word_count'] = trainDF['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "trainDF['upper_case_word_count'] = trainDF['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Stuning', 'even', 'for', 'the', 'non-gamer:'...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>667</td>\n",
       "      <td>80</td>\n",
       "      <td>8.234568</td>\n",
       "      <td>252</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['The', 'best', 'soundtrack', 'ever', 'to', 'a...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>801</td>\n",
       "      <td>97</td>\n",
       "      <td>8.173469</td>\n",
       "      <td>306</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Amazing!:', 'This', 'soundtrack', 'is', 'my'...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>1148</td>\n",
       "      <td>129</td>\n",
       "      <td>8.830769</td>\n",
       "      <td>428</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Excellent', 'Soundtrack:', 'I', 'truly', 'li...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>1098</td>\n",
       "      <td>118</td>\n",
       "      <td>9.226891</td>\n",
       "      <td>388</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Remember,', 'Pull', 'Your', 'Jaw', 'Off', 'T...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>743</td>\n",
       "      <td>87</td>\n",
       "      <td>8.443182</td>\n",
       "      <td>284</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       label  char_count  \\\n",
       "0  ['Stuning', 'even', 'for', 'the', 'non-gamer:'...  __label__2         667   \n",
       "1  ['The', 'best', 'soundtrack', 'ever', 'to', 'a...  __label__2         801   \n",
       "2  ['Amazing!:', 'This', 'soundtrack', 'is', 'my'...  __label__2        1148   \n",
       "3  ['Excellent', 'Soundtrack:', 'I', 'truly', 'li...  __label__2        1098   \n",
       "4  ['Remember,', 'Pull', 'Your', 'Jaw', 'Off', 'T...  __label__2         743   \n",
       "\n",
       "   word_count  word_density  punctuation_count  title_word_count  \\\n",
       "0          80      8.234568                252                10   \n",
       "1          97      8.173469                306                 7   \n",
       "2         129      8.830769                428                24   \n",
       "3         118      9.226891                388                52   \n",
       "4          87      8.443182                284                30   \n",
       "\n",
       "   upper_case_word_count  \n",
       "0                      3  \n",
       "1                      3  \n",
       "2                      4  \n",
       "3                      4  \n",
       "4                      0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# implement PoS (part of speech) tagging\n",
    "\n",
    "pos_family = {\n",
    "    'noun' : ['NN', 'NNS', 'NNP', 'NNPS'],\n",
    "    'pron' : ['PRP', 'PRPS$', 'WP', 'WP$'],\n",
    "    'verb' : ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'],\n",
    "    'adj' : ['JJ', 'JJR', 'JJS'],\n",
    "    'adv' : ['RB', 'RBR', 'RBS', 'WRB']\n",
    "}\n",
    "\n",
    "# function to check and get the PoS tag count of a words in a given sentences\n",
    "def check_pos_tag(x, flag):\n",
    "    count = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                count += 1\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDF['noun_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "trainDF['verb_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "trainDF['adj_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "trainDF['adv_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "trainDF['pron_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'pron'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Stuning', 'even', 'for', 'the', 'non-gamer:'...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>667</td>\n",
       "      <td>80</td>\n",
       "      <td>8.234568</td>\n",
       "      <td>252</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['The', 'best', 'soundtrack', 'ever', 'to', 'a...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>801</td>\n",
       "      <td>97</td>\n",
       "      <td>8.173469</td>\n",
       "      <td>306</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Amazing!:', 'This', 'soundtrack', 'is', 'my'...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>1148</td>\n",
       "      <td>129</td>\n",
       "      <td>8.830769</td>\n",
       "      <td>428</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Excellent', 'Soundtrack:', 'I', 'truly', 'li...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>1098</td>\n",
       "      <td>118</td>\n",
       "      <td>9.226891</td>\n",
       "      <td>388</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Remember,', 'Pull', 'Your', 'Jaw', 'Off', 'T...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>743</td>\n",
       "      <td>87</td>\n",
       "      <td>8.443182</td>\n",
       "      <td>284</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       label  char_count  \\\n",
       "0  ['Stuning', 'even', 'for', 'the', 'non-gamer:'...  __label__2         667   \n",
       "1  ['The', 'best', 'soundtrack', 'ever', 'to', 'a...  __label__2         801   \n",
       "2  ['Amazing!:', 'This', 'soundtrack', 'is', 'my'...  __label__2        1148   \n",
       "3  ['Excellent', 'Soundtrack:', 'I', 'truly', 'li...  __label__2        1098   \n",
       "4  ['Remember,', 'Pull', 'Your', 'Jaw', 'Off', 'T...  __label__2         743   \n",
       "\n",
       "   word_count  word_density  punctuation_count  title_word_count  \\\n",
       "0          80      8.234568                252                10   \n",
       "1          97      8.173469                306                 7   \n",
       "2         129      8.830769                428                24   \n",
       "3         118      9.226891                388                52   \n",
       "4          87      8.443182                284                30   \n",
       "\n",
       "   upper_case_word_count  noun_count  verb_count  adj_count  adv_count  \\\n",
       "0                      3          47           4          2          1   \n",
       "1                      3          66           9          3          2   \n",
       "2                      4          80           7          2          7   \n",
       "3                      4          65           6          8          0   \n",
       "4                      0          57           5          6          0   \n",
       "\n",
       "   pron_count  \n",
       "0           1  \n",
       "1           6  \n",
       "2           4  \n",
       "3           2  \n",
       "4           3  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Topic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train a LDA model\n",
    "lda_model = decomposition.LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=20)\n",
    "X_topics = lda_model.fit_transform(xtrain_count)\n",
    "topic_word = lda_model.components_\n",
    "vocab = count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# view the topic models\n",
    "n_top_words = 10\n",
    "topic_summaries = []\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = numpypy.array(vocab)[numpy.argsortopic_wordopic_dist)][:-(n_top_words+1):-1]\n",
    "    topic_summaries.append(' '.join(topic_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "        \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Naive Bayes (NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.8348\n",
      "NB, WordLevel TF-IDF:  0.8468\n",
      "NB, N-Gram Vectors:  0.844\n",
      "NB, CharLevel Vectors:  0.812\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Word Level TF-IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"NB, WordLevel TF-IDF Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF-IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"NB, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Character Level TF-IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"NB, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Linear Classifier (LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Count Vectors:  0.868\n",
      "LR, WordLevel TF-IDF:  0.8784\n",
      "LR, N-Gram Vectors:  0.846\n",
      "LR, CharLevel Vectors:  0.824\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"LR, Count Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Word Level TF-IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"LR, WordLevel TF-IDF Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF-IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"LR, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Character Level TF-IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"LR, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, Count Vectors:  0.6944\n",
      "SVM, WordLevel TF-IDF:  0.5132\n",
      "SVM, N-Gram Vectors:  0.5132\n",
      "SVM, CharLevel Vectors:  0.5132\n"
     ]
    }
   ],
   "source": [
    "# SVM on Count Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"SVM, Count Vectors: \", accuracy)\n",
    "\n",
    "# SVM on Word Level TF-IDF Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"SVM, WordLevel TF-IDF Vectors: \", accuracy)\n",
    "\n",
    "# SVM on Ngram Level TF-IDF Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"SVM, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# SVM on Character Level TF-IDF Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"SVM, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Bagging Model (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Count Vectors:  0.7476\n",
      "RF, WordLevel TF-IDF:  0.7672\n",
      "RF, N-Gram Vectors:  0.7592\n",
      "RF, CharLevel Vectors:  0.69\n"
     ]
    }
   ],
   "source": [
    "# RF on Count Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"RF, Count Vectors: \", accuracy)\n",
    "\n",
    "# RF on Word Level TF-IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"RF, WordLevel TF-IDF Vectors: \", accuracy)\n",
    "\n",
    "# RF on Ngram Level TF-IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"RF, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# RF on Character Level TF-IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"RF, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Boosting Model (XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB, Count Vectors:  0.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB, WordLevel TF-IDF:  0.7916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB, N-Gram Vectors:  0.7404\n",
      "XGB, CharLevel Vectors:  0.8108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Extreme Gradient Boosting on Count Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xvalid_count.tocsc())\n",
    "print(\"XGB, Count Vectors: \", accuracy)\n",
    "\n",
    "# Extereme Gradient Boosting on Word Level TF-IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xvalid_tfidf.tocsc())\n",
    "print(\"XGB, WordLevel TF-IDF Vectors: \", accuracy)\n",
    "\n",
    "# Extereme Gradient Boosting on Ngram Level TF-IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"XGB, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Extereme Gradient Boosting on Character Level TF-IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y, xvalid_tfidf_ngram_chars.tocsc())\n",
    "print(\"XGB, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Shallow Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model_architecture(input_size):\n",
    "    # create input layer \n",
    "    input_layer = layers.Input((input_size, ), sparse=True)\n",
    "    \n",
    "    # create hidden layer\n",
    "    hidden_layer = layers.Dense(100, activation=\"relu\")(input_layer)\n",
    "    \n",
    "    # create output layer\n",
    "    output_layer = layers.Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
    "\n",
    "    classifier = models.Model(inputs = input_layer, outputs = output_layer)\n",
    "    classifier.compile(optimizer = optimizers.Adam(), loss = 'binary_crossentropy', ep)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "7500/7500 [==============================] - 14s 2ms/step - loss: 0.3991\n",
      "SNN, Count Vectors:  0.5132\n",
      "Epoch 1/1\n",
      "7500/7500 [==============================] - 3s 441us/step - loss: 0.5055\n",
      "SNN, Word Level TF IDF Vectors 0.5132\n",
      "Epoch 1/1\n",
      "7500/7500 [==============================] - 4s 520us/step - loss: 0.5239\n",
      "SNN, Ngram Level TF IDF Vectors 0.5132\n",
      "Epoch 1/1\n",
      "7500/7500 [==============================] - 5s 645us/step - loss: 0.5784\n",
      "SNN, CharLevel Vectors:  0.5132\n"
     ]
    }
   ],
   "source": [
    "# Shallow Neural Network on Count Vectors\n",
    "snn_classifier = create_model_architecture(xtrain_count.shape[1])\n",
    "accuracy = train_model(snn_classifier, xtrain_count, train_y, xvalid_count, is_neural_net=True)\n",
    "print(\"SNN, Count Vectors: \", accuracy)\n",
    "\n",
    "# Shallow Neural Network on Word Level TF-IDF Vectors\n",
    "snn_classifier = create_model_architecture(xtrain_tfidf.shape[1])\n",
    "accuracy = train_model(snn_classifier, xtrain_tfidf, train_y, xvalid_tfidf, is_neural_net=True)\n",
    "print(\"SNN, Word Level TF IDF Vectors\",  accuracy)\n",
    "\n",
    "# Shallow Neural Network on Ngram Level TF-IDF Vectors\n",
    "snn_classifier = create_model_architecture(xtrain_tfidf_ngram.shape[1])\n",
    "accuracy = train_model(snn_classifier, xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram, is_neural_net=True)\n",
    "print(\"SNN, Ngram Level TF IDF Vectors\",  accuracy)\n",
    "\n",
    "# Shallow Neural Network on Character Level TF-IDF Vectors\n",
    "snn_classifier = create_model_architecture(xtrain_tfidf_ngram_chars.shape[1])\n",
    "accuracy = train_model(snn_classifier, xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars, is_neural_net=True)\n",
    "print(\"SNN, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cnn():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recurrent Neural Network – LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_rnn_lstm():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recurrent Neural Network – GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_rnn_gru():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_bidirectional_rnn():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recurrent Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_rcnn():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
