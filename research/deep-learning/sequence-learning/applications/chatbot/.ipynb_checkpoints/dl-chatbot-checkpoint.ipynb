{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative-Based Chatbot Using Sequence to Sequence Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import codecs\n",
    "import itertools\n",
    "import unicodedata\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim\n",
    "from torch.jit import script, trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_name = 'cornell_movie_dialogs'\n",
    "corpus = os.path.join('data', corpus_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_lines(file, n=10):\n",
    "    with open(file, 'rb') as data:\n",
    "        lines = data.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_lines(os.path.join(corpus, 'movie_lines.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_lines(file_name, fields):\n",
    "    \n",
    "    lines = {}\n",
    "    with open(file_name, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(' +++$+++ ')\n",
    "            \n",
    "            line_obj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                line_obj[field] = values[i]\n",
    "            \n",
    "            lines[line_obj['lineID']] = line_obj\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_conversations(file_name, lines, fields):\n",
    "    \n",
    "    conversations = []\n",
    "    with open(file_name, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            \n",
    "            conv_obj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                conv_obj[field] = values[i]\n",
    "                \n",
    "            utterance_id_pattern = re.compile('L[0-9]+')\n",
    "            line_ids = utterance_id_pattern.findall(conv_obj['utteranceIDs'])\n",
    "            \n",
    "            conv_obj['lines'] = []\n",
    "            for line_id in line_ids:\n",
    "                conv_obj['lines'].append(lines[line_id])\n",
    "                \n",
    "            conversations.append(conv_obj)\n",
    "    return conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_sentence_pairs(conversations):\n",
    "    \n",
    "    qa_pairs = []\n",
    "    for conversation in conversations:\n",
    "        for i in range(len(conversation['lines']) - 1):\n",
    "            input_line = conversation['lines'][i]['text'].strip()\n",
    "            target_line = conversation['lines'][i+1]['text'].strip()\n",
    "            \n",
    "            if input_line and target_line:\n",
    "                qa_pairs.append([input_line, target_line])\n",
    "                \n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file = os.path.join(corpus, 'formatted_movie_lines.txt')\n",
    "\n",
    "delimiter = '\\t'\n",
    "delimiter = str(codecs.decode(delimiter, 'unicode_escape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = {}\n",
    "conversations = []\n",
    "MOVIE_LINES_FIELDS = ['lineID', 'characterID', 'movieID', 'character', 'text']\n",
    "MOVIE_CONVERSATIONS_FIELDS = ['character1ID', 'character2ID', 'movieID', 'utteranceIDs']\n",
    "\n",
    "print('\\nProcessing corpus...')\n",
    "lines = load_lines(os.path.join(corpus, 'movie_lines.txt'), MOVIE_LINES_FIELDS)\n",
    "\n",
    "print('\\nLoading conversations...')\n",
    "conversations = load_conversations(os.path.join(corpus, 'movie_conversations.txt'),\n",
    "                                   lines, MOVIE_CONVERSATIONS_FIELDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('\\nWriting newly formatted file...')\n",
    "with open(data_file, 'w', encoding='utf-8') as output_file:\n",
    "    writer = csv.writer(output_file, delimiter=delimiter, lineterminator='\\n')\n",
    "    for pair in extract_sentence_pairs(conversations):\n",
    "        writer.writerow(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('\\nSample lines from file:')\n",
    "print_lines(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
