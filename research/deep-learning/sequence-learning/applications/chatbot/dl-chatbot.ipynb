{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative-Based Chatbot Using Sequence to Sequence Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import codecs\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim\n",
    "from torch.jit import script, trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import normalize_string, filter_pairs, time_since, moving_average, show_plot_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "MAX_LENGTH = 10\n",
    "MIN_COUNT = 3\n",
    "\n",
    "# model configs\n",
    "LR = 0.0001\n",
    "N_EPOCHS = 4000\n",
    "TEACHER_FORCING_RATIO = 1.0\n",
    "HIDDEN_SIZE = 500\n",
    "DROPOUT = 0.1\n",
    "CLIP = 50.0\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "ENCODER_N_LAYERS = 2\n",
    "DECODER_N_LAYERS = 2\n",
    "DECODER_LEARNING_RATIO = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda: device = torch.device('cuda')\n",
    "else: device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super(Vocabulary, self).__init__()\n",
    "        \n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = { PAD_token: 'PAD', SOS_token: 'SOS', EOS_token: 'EOS' }\n",
    "        self.num_words = 3 # count constant tokens PAD, SOS and EOS\n",
    "        \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "            \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "    # remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "\n",
    "        if self.trimmed: return\n",
    "\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "        for key, value in self.word2count.items():\n",
    "            if value >= min_count:\n",
    "                keep_words.append(key)\n",
    "\n",
    "        print('Keep Words: {}/{} = {:.4f}'.format(\n",
    "               len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)))\n",
    "\n",
    "        # reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = { PAD_token: 'PAD', SOS_token: 'SOS', EOS_token: 'EOS' }\n",
    "        self.num_words = 3  # count constant tokens PAD, SOS and EOS\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.add_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vocabulary(data_file, corpus_name):\n",
    "    print('Reading lines...')\n",
    "    \n",
    "    # read the file and split into lines\n",
    "    lines = open(data_file, encoding='utf-8').read().strip().split('\\n')\n",
    "    # split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(string) for string in l.split('\\t')] for l in lines]\n",
    "    vocabulary = Vocabulary(corpus_name)\n",
    "    \n",
    "    return vocabulary, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prepare_data(corpus, corpus_name, data_file, save_dir):\n",
    "    print('Starting training data preparation...')\n",
    "    vocabulary, pairs = read_vocabulary(data_file, corpus_name)\n",
    "    \n",
    "    print('Reading {!s} sentence pairs'.format(len(pairs)))\n",
    "    pairs = filter_pairs(pairs, MAX_LENGTH)\n",
    "    \n",
    "    print('Trimmed to {!s} sentence pairs'.format(len(pairs)))\n",
    "    print('Counting words...')\n",
    "    for pair in pairs:\n",
    "        vocabulary.add_sentence(pair[0])\n",
    "        vocabulary.add_sentence(pair[1])\n",
    "    print(f'Counted words: {vocabulary.num_words}')\n",
    "    \n",
    "    return vocabulary, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets grasp from here: www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\n",
    "corpus_name = 'cornell_movie_dialogs'\n",
    "corpus = os.path.join('datasets', corpus_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_lines(file, n=10):\n",
    "    with open(file, 'rb') as data:\n",
    "        lines = data.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\\n'\n",
      "b'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\\n'\n",
      "b'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\\n'\n",
      "b'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\\n'\n",
      "b\"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\\n\"\n",
      "b'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\\n'\n",
      "b\"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\\n\"\n",
      "b'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\\n'\n",
      "b'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?\\n'\n",
      "b'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\\n'\n"
     ]
    }
   ],
   "source": [
    "print_lines(os.path.join(corpus, 'movie_lines.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lines(file_name, fields):\n",
    "    \n",
    "    lines = {}\n",
    "    with open(file_name, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(' +++$+++ ')\n",
    "            \n",
    "            line_obj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                line_obj[field] = values[i]\n",
    "            \n",
    "            lines[line_obj['lineID']] = line_obj\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conversations(file_name, lines, fields):\n",
    "    \n",
    "    conversations = []\n",
    "    with open(file_name, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            \n",
    "            conv_obj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                conv_obj[field] = values[i]\n",
    "                \n",
    "            utterance_id_pattern = re.compile('L[0-9]+')\n",
    "            line_ids = utterance_id_pattern.findall(conv_obj['utteranceIDs'])\n",
    "            \n",
    "            conv_obj['lines'] = []\n",
    "            for line_id in line_ids:\n",
    "                conv_obj['lines'].append(lines[line_id])\n",
    "                \n",
    "            conversations.append(conv_obj)\n",
    "    return conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentence_pairs(conversations):\n",
    "    \n",
    "    qa_pairs = []\n",
    "    for conversation in conversations:\n",
    "        for i in range(len(conversation['lines']) - 1):\n",
    "            input_line = conversation['lines'][i]['text'].strip()\n",
    "            target_line = conversation['lines'][i+1]['text'].strip()\n",
    "            \n",
    "            if input_line and target_line:\n",
    "                qa_pairs.append([input_line, target_line])\n",
    "                \n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = os.path.join(corpus, 'formatted_movie_lines.txt')\n",
    "\n",
    "delimiter = '\\t'\n",
    "delimiter = str(codecs.decode(delimiter, 'unicode_escape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus...\n",
      "\n",
      "Loading conversations...\n",
      "\n",
      "Writing newly formatted file...\n",
      "\n",
      "Sample lines from file:\n",
      "b\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\tWell, I thought we'd start with pronunciation, if that's okay with you.\\n\"\n",
      "b\"Well, I thought we'd start with pronunciation, if that's okay with you.\\tNot the hacking and gagging and spitting part.  Please.\\n\"\n",
      "b\"Not the hacking and gagging and spitting part.  Please.\\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\n\"\n",
      "b\"You're asking me out.  That's so cute. What's your name again?\\tForget it.\\n\"\n",
      "b\"No, no, it's my fault -- we didn't have a proper introduction ---\\tCameron.\\n\"\n",
      "b\"Cameron.\\tThe thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\n\"\n",
      "b\"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\tSeems like she could get a date easy enough...\\n\"\n",
      "b'Why?\\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\n'\n",
      "b\"Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\tThat's a shame.\\n\"\n",
      "b'Gosh, if only we could find Kat a boyfriend...\\tLet me see what I can do.\\n'\n"
     ]
    }
   ],
   "source": [
    "lines = {}\n",
    "conversations = []\n",
    "MOVIE_LINES_FIELDS = ['lineID', 'characterID', 'movieID', 'character', 'text']\n",
    "MOVIE_CONVERSATIONS_FIELDS = ['character1ID', 'character2ID', 'movieID', 'utteranceIDs']\n",
    "\n",
    "print('\\nProcessing corpus...')\n",
    "lines = load_lines(os.path.join(corpus, 'movie_lines.txt'), MOVIE_LINES_FIELDS)\n",
    "\n",
    "print('\\nLoading conversations...')\n",
    "conversations = load_conversations(os.path.join(corpus, 'movie_conversations.txt'),\n",
    "                                   lines, MOVIE_CONVERSATIONS_FIELDS)\n",
    "\n",
    "print('\\nWriting newly formatted file...')\n",
    "with open(data_file, 'w', encoding='utf-8') as output_file:\n",
    "    writer = csv.writer(output_file, delimiter=delimiter, lineterminator='\\n')\n",
    "    for pair in extract_sentence_pairs(conversations):\n",
    "        writer.writerow(pair)\n",
    "        \n",
    "print('\\nSample lines from file:')\n",
    "print_lines(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training data preparation...\n",
      "Reading lines...\n",
      "Reading 221282 sentence pairs\n",
      "Trimmed to 64271 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 18008\n",
      "\n",
      "Pairs:\n",
      "['there .', 'where ?']\n",
      "['you have my word . as a gentleman', 'you re sweet .']\n",
      "['hi .', 'looks like things worked out tonight huh ?']\n",
      "['you know chastity ?', 'i believe we share an art instructor']\n",
      "['have fun tonight ?', 'tons']\n",
      "['well no . . .', 'then that s all you had to say .']\n",
      "['then that s all you had to say .', 'but']\n",
      "['but', 'you always been this selfish ?']\n",
      "['do you listen to this crap ?', 'what crap ?']\n",
      "['what good stuff ?', 'the real you .']\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join('datasets', 'save')\n",
    "vocabulary, pairs = load_prepare_data(corpus, corpus_name, data_file, save_dir)\n",
    "\n",
    "print('\\nPairs:')\n",
    "for pair in pairs[:10]: print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_rare_words(vocabulary, pairs, min_count):\n",
    "    \n",
    "    vocabulary.trim(min_count)\n",
    "    \n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        \n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        \n",
    "        # check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in vocabulary.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "           \n",
    "        # check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in vocabulary.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "                \n",
    "        # only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "            \n",
    "    print('Trimmed from {} pairs to {}, {:.4f} of total.'.format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep Words: 7823/18005 = 0.4345\n",
      "Trimmed from 64271 pairs to 53165, 0.8272 of total.\n",
      "\n",
      "Pairs:\n",
      "['there .', 'where ?']\n",
      "['you have my word . as a gentleman', 'you re sweet .']\n",
      "['hi .', 'looks like things worked out tonight huh ?']\n",
      "['have fun tonight ?', 'tons']\n",
      "['well no . . .', 'then that s all you had to say .']\n",
      "['then that s all you had to say .', 'but']\n",
      "['but', 'you always been this selfish ?']\n",
      "['do you listen to this crap ?', 'what crap ?']\n",
      "['what good stuff ?', 'the real you .']\n",
      "['wow', 'let s go .']\n"
     ]
    }
   ],
   "source": [
    "pairs = trim_rare_words(vocabulary, pairs, MIN_COUNT)\n",
    "\n",
    "print('\\nPairs:')\n",
    "for pair in pairs[:10]: print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Datasets for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_matrix(l, value=PAD_token):\n",
    "    matrix = []\n",
    "    for i, sequence in enumerate(l):\n",
    "        matrix.append([])\n",
    "        for token in sequence:\n",
    "            if token == PAD_token:\n",
    "                matrix[i].append(0)\n",
    "            else:\n",
    "                matrix[i].append(1)\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns padded input sequence tensor and lengths\n",
    "def input_var(l, vocabulary):\n",
    "    \n",
    "    indexes_batch = [indexes_from_sentence(vocabulary, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    pad_list = zero_padding(indexes_batch)\n",
    "    pad_var = torch.LongTensor(pad_list)\n",
    "    \n",
    "    return pad_var, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns padded target sequence tensor, padding mask and max target length\n",
    "def output_var(l, vocabulary):\n",
    "    \n",
    "    indexes_batch = [indexes_from_sentence(vocabulary, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    pad_list = zero_padding(indexes_batch)\n",
    "    mask = binary_matrix(pad_list)\n",
    "    mask = torch.BoolTensor(mask)\n",
    "    pad_var = torch.LongTensor(pad_list)\n",
    "    \n",
    "    return pad_var, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns all items for a given batch of pairs\n",
    "def batch_to_train_data(vocabulary, pair_batch):\n",
    "    \n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(' ')), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    \n",
    "    inp, lengths = input_var(input_batch, vocabulary)\n",
    "    output, mask, max_target_len = output_var(output_batch, vocabulary)\n",
    "    \n",
    "    return inp, lengths, output, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_BATCH_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indexes_from_sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-fe676c81753f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_to_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSMALL_BATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minput_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_target_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input Variable:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_variable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Lengths:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-524471ab2256>\u001b[0m in \u001b[0;36mbatch_to_train_data\u001b[0;34m(vocabulary, pair_batch)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moutput_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_target_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-a793b00c82a5>\u001b[0m in \u001b[0;36minput_var\u001b[0;34m(l, vocabulary)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minput_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mindexes_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexes_from_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpad_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzero_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-a793b00c82a5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minput_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mindexes_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexes_from_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpad_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzero_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'indexes_from_sentence' is not defined"
     ]
    }
   ],
   "source": [
    "batches = batch_to_train_data(vocabulary, [random.choice(pairs) for _ in range(SMALL_BATCH_SIZE)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"Input Variable:\", input_variable)\n",
    "print(\"Lengths:\", lengths)\n",
    "print(\"Target Variable:\", target_variable)\n",
    "print(\"Mask:\", mask)\n",
    "print(\"Max Target Len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build [Seq2seq](https://arxiv.org/pdf/1409.3215.pdf) Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_layer = embedding\n",
    "        \n",
    "        # initialize GRU: the input size and hidden size params are bot set to 'hidden_size'\n",
    "        # because our input size is a word embedding with number of features equals to 'hidden_size'\n",
    "        self.gru_layer = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                                dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "        \n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        \n",
    "        # convert word indexes to embeddings\n",
    "        embeds = self.embedding_layer(input_seq) # input_seq: (max_length, batch_size)\n",
    "        \n",
    "        # pack padded batch of sequences for RNN module\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embeds, input_lengths)\n",
    "        \n",
    "        # forward pass throught GRU layer\n",
    "        gru_out, hidden = self.gru_layer(packed, hidden) # hidden shape: (n_layers x num_directions, batch_size, hidden_size)\n",
    "        \n",
    "        # unpack the padding\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(gru_out) # outputs shape: (max_length, batch_size, hidden_size)\n",
    "        \n",
    "        # sum bidirectional GRU outputs\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
    "        \n",
    "        # return output and final hidden state\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build [Attention](https://arxiv.org/pdf/1706.03762.pdf) Decoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, method, hidden_size):\n",
    "        \n",
    "        super(GlobalAttention, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        \n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, 'is not an appropriate attention method.')\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attention_layer = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "            \n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "    \n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attention_layer(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "    \n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attention_layer(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "    \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # calculate the attention weights (energies) based on the given method\n",
    "        if self.method == 'general':\n",
    "            attention_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attention_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attention_energies = self.dot_score(hidden, encoder_outputs)\n",
    "            \n",
    "        # transpose max_length and batch_size dimensions\n",
    "        attention_energies = attention_energies.t()\n",
    "        \n",
    "        # return the softmax normalized probability scores (with added dimension)\n",
    "        return F.softmax(attention_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAttentionDecoder(nn.Module):\n",
    "    \n",
    "    # input_step shape: (1, batch_size)\n",
    "    # last_hidden shape: (n_layers x num_directions, batch_size, hidden_size)\n",
    "    # encoder_outputs shape: (max_length, batch_size, hidden_size)\n",
    "    def __init__(self, embedding, hidden_size, output_size, n_layers=1, dropout=0.1, attention_model='dot'):\n",
    "        \n",
    "        super(GlobalAttentionDecoder, self).__init__()\n",
    "        \n",
    "        self.attention_model = attention_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # define layers\n",
    "        self.embedding_layer = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru_layer = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat_layer = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fc_layer = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.attention_layer = GlobalAttention(attention_model, hidden_size)\n",
    "    \n",
    "    # output shape: (batch_size, vocabulary.num_words)\n",
    "    # hidden shape: (n_layers x num_directions, batch_size, hidden_size)\n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        \n",
    "        # run this one step (word) at a time\n",
    "        embeds = self.embedding_layer(input_step)\n",
    "        embeds = self.embedding_dropout(embeds)\n",
    "        \n",
    "        # forward through undirectional GRU\n",
    "        gru_out, hidden = self.gru_layer(embeds, last_hidden)\n",
    "        \n",
    "        # calculate attention weights from the current GRU output\n",
    "        attention_weights = self.attention_layer(gru_out, encoder_outputs)\n",
    "        \n",
    "        # multiply attention weights to encoder outputs to get new 'weighted sum' context vector\n",
    "        context_vector = attention_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        \n",
    "        # concatenate weighted context vector and GRU output\n",
    "        gru_out = gru_out.squeeze(0)\n",
    "        \n",
    "        context_vector = context_vector.squeeze(1)\n",
    "        concat_input = torch.cat((gru_out, context_vector), 1)\n",
    "        concat_output = torch.tanh(self.concat_layer(concat_input))\n",
    "        \n",
    "        # predict next word\n",
    "        output = self.fc_layer(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        \n",
    "        # return output and final hidden state\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Seq2seq Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING = nn.Embedding(vocabulary.num_words, HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (embedding_layer): Embedding(7826, 500)\n",
       "  (gru_layer): GRU(500, 500, num_layers=2, dropout=0.1, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(HIDDEN_SIZE, EMBEDDING, ENCODER_N_LAYERS, DROPOUT)\n",
    "encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GlobalAttentionDecoder(\n",
       "  (embedding_layer): Embedding(7826, 500)\n",
       "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (gru_layer): GRU(500, 500, num_layers=2, dropout=0.1)\n",
       "  (concat_layer): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (fc_layer): Linear(in_features=500, out_features=7826, bias=True)\n",
       "  (attention_layer): GlobalAttention()\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = GlobalAttentionDecoder(EMBEDDING, HIDDEN_SIZE, vocabulary.num_words, DECODER_N_LAYERS, DROPOUT, attention_model='dot')\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_nll_loss(input_seq, target_seq, mask):\n",
    "    \n",
    "    n_total = mask.sum()\n",
    "    cross_entropy = -torch.log(torch.gather(input_seq, 1, target_seq.view(-1, 1)).squeeze(1))\n",
    "    loss = cross_entropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    \n",
    "    return loss, n_total.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=LR)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=LR * DECODER_LEARNING_RATIO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Seq2seq Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick = time.time()\n",
    "losses_history = []\n",
    "total_loss_print = 0\n",
    "total_loss_plot = 0\n",
    "\n",
    "print_every = 5000\n",
    "plot_every = 100\n",
    "\n",
    "training_batches = [batch_to_train_data(vocabulary, [random.choice(pairs) for _ in range(BATCH_SIZE)])\n",
    "                    for _ in range(N_EPOCHS)]\n",
    "\n",
    "print('Training the network...')\n",
    "for epoch in range(1, N_EPOCHS+1):\n",
    "    \n",
    "    training_batch = training_batches[epoch - 1]\n",
    "    \n",
    "    # extract fields from batch\n",
    "    input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "    \n",
    "    # zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    # set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "    \n",
    "    # initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "    \n",
    "    # forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "    \n",
    "    # create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(BATCH_SIZE)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "    \n",
    "    # set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "    \n",
    "    # determine if we are using teacher forching this iteration\n",
    "    USE_TEACHER_FORCING = True if random.random() < TEACHER_FORCING_RATIO else False\n",
    "    \n",
    "    # forward batch of sequences through decoder one time step at a time\n",
    "    if USE_TEACHER_FORCING:\n",
    "        \n",
    "        for t in range(max_target_len):\n",
    "            \n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            # teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            \n",
    "            # calculate and accumulate loss\n",
    "            mask_loss, n_total = mask_nll_loss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * n_total)\n",
    "            n_totals += n_total\n",
    "    else:\n",
    "        \n",
    "        for t in range(max_target_len):\n",
    "            \n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            \n",
    "            # no teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(BATCH_SIZE)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            \n",
    "            # calculate and accumulate loss\n",
    "            mask_loss, n_total = mask_nll_loss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * n_total)\n",
    "            n_totals += n_total\n",
    "    \n",
    "    # clip gradients\n",
    "    nn.utils.clip_grad_norm_(encoder.parameters(), CLIP)\n",
    "    nn.utils.clip_grad_norm_(decoder.parameters(), CLIP)\n",
    "    \n",
    "    # perform backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    loss = sum(print_losses) / n_totals\n",
    "    total_loss_print += loss\n",
    "    total_loss_plot += loss\n",
    "    \n",
    "    if epoch % print_every == 0:\n",
    "        avg_loss_print = print_loss_total / print_every\n",
    "        total_loss_print = 0\n",
    "        print('%d | %d epochs, Average Loss: %.4f, Times Taken: %s' % (epoch, N_EPOCHS, avg_loss_print,\n",
    "                                                                        time_since(tick, epoch / N_EPOCHS)))\n",
    "    \n",
    "    if epoch & plot_every == 0:\n",
    "        avg_loss_plot = total_loss_plot / plot_every\n",
    "        losses_history.append(avg_loss_plot)\n",
    "        total_loss_plot = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plot_evaluation(losses_history, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate The Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
