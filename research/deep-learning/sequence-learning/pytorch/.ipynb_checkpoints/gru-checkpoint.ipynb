{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './datasets/hourly-energy-consumption/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>AEP_MW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-12-31 01:00:00</td>\n",
       "      <td>13478.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-12-31 02:00:00</td>\n",
       "      <td>12865.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-12-31 03:00:00</td>\n",
       "      <td>12577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-12-31 04:00:00</td>\n",
       "      <td>12517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-12-31 05:00:00</td>\n",
       "      <td>12670.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime   AEP_MW\n",
       "0  2004-12-31 01:00:00  13478.0\n",
       "1  2004-12-31 02:00:00  12865.0\n",
       "2  2004-12-31 03:00:00  12577.0\n",
       "3  2004-12-31 04:00:00  12517.0\n",
       "4  2004-12-31 05:00:00  12670.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AEP = pd.read_csv(data_dir + 'AEP_hourly.csv')\n",
    "df_AEP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>COMED_MW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-31 01:00:00</td>\n",
       "      <td>9970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-12-31 02:00:00</td>\n",
       "      <td>9428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-12-31 03:00:00</td>\n",
       "      <td>9059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-31 04:00:00</td>\n",
       "      <td>8817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-12-31 05:00:00</td>\n",
       "      <td>8743.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime  COMED_MW\n",
       "0  2011-12-31 01:00:00    9970.0\n",
       "1  2011-12-31 02:00:00    9428.0\n",
       "2  2011-12-31 03:00:00    9059.0\n",
       "3  2011-12-31 04:00:00    8817.0\n",
       "4  2011-12-31 05:00:00    8743.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_COMED = pd.read_csv(data_dir + 'COMED_hourly.csv')\n",
    "df_COMED.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>FE_MW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-31 01:00:00</td>\n",
       "      <td>6222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-12-31 02:00:00</td>\n",
       "      <td>5973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-12-31 03:00:00</td>\n",
       "      <td>5778.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-31 04:00:00</td>\n",
       "      <td>5707.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-12-31 05:00:00</td>\n",
       "      <td>5691.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime   FE_MW\n",
       "0  2011-12-31 01:00:00  6222.0\n",
       "1  2011-12-31 02:00:00  5973.0\n",
       "2  2011-12-31 03:00:00  5778.0\n",
       "3  2011-12-31 04:00:00  5707.0\n",
       "4  2011-12-31 05:00:00  5691.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FE = pd.read_csv(data_dir + 'FE_hourly.csv')\n",
    "df_FE.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the scaler objects will be stored in this dictionary \n",
    "# so that our output test data from the model can be re-scaled during evaluation\n",
    "scalers_label = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfdd9cb33a394ff2ab87e873e854f3af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_x = []\n",
    "test_x, test_y = {}, {}\n",
    "\n",
    "for file in tqdm_notebook(os.listdir(data_dir)):\n",
    "    \n",
    "    # skip the files we're not using\n",
    "    if file[-4:] != '.csv' or file == 'pjm_hourly_est.csv':\n",
    "        continue\n",
    "        \n",
    "    df_data = pd.read_csv('{}/{}'.format(data_dir, file), parse_dates=[0])\n",
    "    \n",
    "    # pre-process the time data into suitable input formats\n",
    "    df_data['hour'] = df_data.apply(lambda x: x['Datetime'].hour, axis=1)\n",
    "    df_data['dayofweek'] = df_data.apply(lambda x: x['Datetime'].dayofweek, axis=1)\n",
    "    df_data['month'] = df_data.apply(lambda x: x['Datetime'].month, axis=1)\n",
    "    df_data['dayofyear'] = df_data.apply(lambda x: x['Datetime'].dayofyear, axis=1)\n",
    "    df_data = df_data.sort_values('Datetime').drop('Datetime', axis=1)\n",
    "    \n",
    "    # scale the input data\n",
    "    sc = MinMaxScaler()\n",
    "    sc_label = MinMaxScaler()\n",
    "    \n",
    "    data = sc.fit_transform(df_data.values)\n",
    "    \n",
    "    # obtain the scale for the labels (usage data)\n",
    "    # so that output can be re-schaled to actual value during evaluation\n",
    "    sc_label.fit(df_data.iloc[:,0].values.reshape(-1,1))\n",
    "    scalers_label[file] = sc_label\n",
    "    \n",
    "    # define look-back period and split for inputs and labels\n",
    "    look_back = 90\n",
    "    inputs = np.zeros((len(data)-look_back, look_back, df_data.shape[1]))\n",
    "    labels = np.zeros(len(data)-look_back)\n",
    "    \n",
    "    for i in range(look_back, len(data)):\n",
    "        inputs[i-look_back] = data[i-look_back:i]\n",
    "        labels[i-look_back] = data[i,0]\n",
    "    inputs = inputs.reshape(-1, look_back, df_data.shape[1])\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    \n",
    "    # split data into train/ test portions and combine all data from different files into a single array\n",
    "    test_size = int(0.1*len(inputs))\n",
    "    if len(train_x) == 0:\n",
    "        train_x = inputs[:-test_size]\n",
    "        train_y = labels[:-test_size]\n",
    "    else:\n",
    "        train_x = np.concatenate((train_x, inputs[:-test_size]))\n",
    "        train_y = np.concatenate((train_y, labels[:-test_size]))\n",
    "    \n",
    "    test_x[file] = (inputs[-test_size:])\n",
    "    test_y[file] = (labels[-test_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data: 980185\n",
      "Number of test data: 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training data: \" + str(len(train_x)))\n",
    "print(\"Number of test data: \" + str(len(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda: device = torch.device('cuda')\n",
    "else: device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:torch.Size([16, 90, 5])\n",
      "Output shape:torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Input shape:' + str(sample_x.shape))\n",
    "print('Output shape:' + str(sample_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = next(iter(train_loader))[0].shape[2]\n",
    "output_size = 1\n",
    "hidden_dim=256\n",
    "n_layers = 2\n",
    "\n",
    "LR = 0.001\n",
    "N_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build GRU Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_dim, output_size, n_layers, drop_prob=0.2):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru_layer = nn.GRU(input_size, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_layer = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        \n",
    "        return hidden\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        gru_out, hidden = self.gru_layer(x, hidden)\n",
    "        output = self.fc_layer(self.relu(gru_out[:,-1]))\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize GRU Network with hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU(\n",
       "  (gru_layer): GRU(5, 256, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (relu): ReLU()\n",
       "  (fc_layer): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru = GRU(input_size, hidden_dim, output_size, n_layers)\n",
    "gru.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(gru.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GRU Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angga.muhammad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "/Users/angga.muhammad/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([16, 1])) that is different to the input size (torch.Size([16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1... Step: 200/61261... Train Loss: 0.029870...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-21c01a814759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print_every = 200\n",
    "counter = 0\n",
    "epoch_times = []\n",
    "\n",
    "gru.train()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    tik = time.clock()\n",
    "    hidden = gru.init_hidden(BATCH_SIZE)\n",
    "    train_loss = 0.\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        hidden = hidden.data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        gru_out, hidden = gru(inputs.float(), hidden)\n",
    "        loss = mse_loss(gru_out.squeeze(), labels.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        if counter%print_every == 0:\n",
    "            print('Epoch: {}...'.format(epoch+1),\n",
    "                  'Step: {}/{}...'.format(counter, len(train_loader)),\n",
    "                  'Train Loss: {:.6f}...'.format(train_loss/counter))\n",
    "    \n",
    "    tok = time.clock()\n",
    "    print('Epoch {}/{} Done, Total Loss: {}'.format(epoch, N_EPOCHS, train_loss/len(train_loader)))\n",
    "    print('Total Time Elapsed: {} seconds'.format(str(tok-tik)))\n",
    "    epoch_times.append(current_time-start_time)\n",
    "\n",
    "print('Total Training Time: {} seconds'.format(str(sum(epoch_times))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angga.muhammad/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "targets = []\n",
    "tik = time.clock()\n",
    "\n",
    "gru.eval()\n",
    "for i in test_x.keys():\n",
    "    inputs = torch.from_numpy(np.array(test_x[i]))\n",
    "    labels = torch.from_numpy(np.array(test_x[i]))\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "    hidden = gru.init_hidden(inputs.shape[0])\n",
    "    gru_out, hidden = gru(inputs.float(), hidden)\n",
    "    outputs.append(scalers_label[i].inverse_transform(gru_out.cpu().detach().numpy()).reshape(-1))\n",
    "    targets.append(scalers_label[i].inverse_transform(labels.numpy()).reshape(-1))\n",
    "\n",
    "tok = time.clock()\n",
    "print('Evaluation Time: {}'.format(str(tok-tik)))\n",
    "\n",
    "sMAPE = 0\n",
    "for i in range(len(outputs)):\n",
    "    sMAPE += np.mean(abs(outputs[i]-targets[i]) / (targets[i]+outputs[i]/2) / len(outputs))\n",
    "print('sMAPE: {}%'.format(sMAPE*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
