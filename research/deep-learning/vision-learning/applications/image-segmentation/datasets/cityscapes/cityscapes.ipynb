{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cityscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CityScapes(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Cityscapes dataset from https://www.cityscapes-dataset.com/\n",
    "    \"\"\"\n",
    "    \n",
    "    # training dataset root directories\n",
    "    train_dir = 'leftImg8bit_trainvaltest/leftImg8bit/train'\n",
    "    train_label_dir = 'gtFine_trainvaltest/gtFine/train'\n",
    "    \n",
    "    # validation dataset root directories\n",
    "    valid_dir = 'leftImg8bit_trainvaltest/leftImg8bit/val'\n",
    "    valid_label_dir = 'gtFine_trainvaltest/gtFine/val'\n",
    "    \n",
    "    # test dataset root directories\n",
    "    test_dir = 'leftImg8bit_trainvaltest/leftImg8bit/test'\n",
    "    test_label_dir = 'gtFine_trainvaltest/gtFine/test'\n",
    "    \n",
    "    # images extension\n",
    "    img_extension = '.png'\n",
    "    label_name_filter = 'labelIds'\n",
    "    \n",
    "    # the values associated with the 35 classes\n",
    "    full_classes = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
    "                    17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\n",
    "                    32, 33, -1)\n",
    "\n",
    "    # the values above are remapped to the following\n",
    "    new_classes = (0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 3, 4, 5, 0, 0, 0, 6, 0, 7,\n",
    "                   8, 9, 10, 11, 12, 13, 14, 15, 16, 0, 0, 17, 18, 19, 0)\n",
    "    \n",
    "    # default encoding for pixel value, class name and class color\n",
    "    from collections import OrderedDict\n",
    "    \n",
    "    color_encoding = OrderedDict([\n",
    "        ('road', (128, 64, 128)),  # RGB format\n",
    "        ('sidewalk', (244, 35, 232)),\n",
    "        ('building', (70, 70, 70)),\n",
    "        ('wall', (102, 102, 156)),\n",
    "        ('fence', (190, 153, 153)),\n",
    "        ('pole', (153, 153, 153)),\n",
    "        ('traffic_light', (250, 170, 30)),\n",
    "        ('traffic_sign', (220, 220, 0)),\n",
    "        ('vegetation', (107, 142, 35)),\n",
    "        ('terrain', (152, 251, 152)),\n",
    "        ('sky', (70, 130, 180)),\n",
    "        ('person', (220, 20, 60)),\n",
    "        ('rider', (255, 0, 0)),\n",
    "        ('car', (0, 0, 142)),\n",
    "        ('truck', (0, 0, 70)),\n",
    "        ('bus', (0, 60, 100)),\n",
    "        ('train', (0, 80, 100)),\n",
    "        ('motorcycle', (0, 0, 230)),\n",
    "        ('bicycle', (119, 11, 32)),\n",
    "        # ('unlabeled', (0, 0, 0))\n",
    "    ])\n",
    "    \n",
    "    def __init__(self, \n",
    "                 root_dir, \n",
    "                 mode='train', \n",
    "                 data_transform=None, \n",
    "                 label_transform=None):\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.mode = mode\n",
    "        self.data_transform = data_transform\n",
    "        self.label_transform = label_transform\n",
    "        \n",
    "        # get the training data and labels filepaths\n",
    "        if self.mode.lower() == 'train':\n",
    "            self.train_data = utils.get_files(os.path.join(root_dir, self.train_dir), \n",
    "                                                           extension_filter=self.img_extension)\n",
    "            \n",
    "            self.train_labels = utils.get_files(os.path.join(root_dir, self.train_label_dir), \n",
    "                                                             extension_filter=self.img_extension)\n",
    "            \n",
    "        # get the validation data and labels filepaths\n",
    "        elif self.mode.lower() == 'valid':\n",
    "            self.valid_data = utils.get_files(os.path.join(root_dir, self.valid_dir), \n",
    "                                                           extension_filter=self.img_extension)\n",
    "            \n",
    "            self.valid_labels = utils.get_files(os.path.join(root_dir, self.valid_label_dir), \n",
    "                                                             extension_filter=self.img_extension)\n",
    "            \n",
    "        # get the test data and labels filepaths\n",
    "        elif self.mode.lower() == 'test':\n",
    "            self.test_data = utils.get_files(os.path.join(root_dir, self.test_dir), \n",
    "                                                          extension_filter=self.img_extension)\n",
    "            \n",
    "            self.test_labels = utils.get_files(os.path.join(root_dir, self.test_label_dir), \n",
    "                                                            extension_filter=self.img_extension)\n",
    "        \n",
    "        else:\n",
    "            raise RuntimeError('Unexpected dataset mode. Supported modes are: train, valid and test')\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if self.mode.lower() == 'train':\n",
    "            data_path, label_path = self.train_data[index], self.train_labels[index]\n",
    "            \n",
    "        elif self.mode.lower() == 'valid':\n",
    "            data_path, label_path = self.valid_data[index], self.valid_labels[index]\n",
    "        \n",
    "        elif self.mode.lower() == 'test':\n",
    "            data_path, label_path = self.test_data[index], self.test_labels[index]\n",
    "        \n",
    "        else:\n",
    "            raise RuntimeError('Unexpected dataset mode. Supported modes are: train, valid and test')\n",
    "        \n",
    "        image, label = self.loader(data_path, label_path)\n",
    "        \n",
    "        # remap class labels\n",
    "        label = utils.remap(label, self.full_classes, self.new_classes)\n",
    "        \n",
    "        if self.data_transform is not None:\n",
    "            image = self.data_transform(image)\n",
    "            \n",
    "        if self.label_transform is not None:\n",
    "            label = self.label_transform(label)\n",
    "            \n",
    "        # perform one-hot-encoding\n",
    "        target = utils.one_hot_encode(label)\n",
    "        target = torch.FloatTensor(target)\n",
    "            \n",
    "        return image, label, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        if self.mode.lower() == 'train':\n",
    "            return len(self.train_data)\n",
    "        \n",
    "        elif self.mode.lower() == 'valid':\n",
    "            return len(self.valid_data)\n",
    "        \n",
    "        elif self.mode.lower() == 'test':\n",
    "            return len(self.test_data)\n",
    "        else:\n",
    "            raise RuntimeError('Unexpected dataset mode. Supported modes are: train, valid and test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = './data'\n",
    "HEIGHT, WIDTH = 360, 480\n",
    "BATCH_SIZE = 10\n",
    "WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([transforms.Resize((HEIGHT, WIDTH)), \n",
    "                                     transforms.ToTensor()])\n",
    "\n",
    "label_transform = transforms.Compose([transforms.Resize((HEIGHT, WIDTH), Image.NEAREST),\n",
    "                                      transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityscapes_set = CityScapes(DATASET_DIR, mode='train', \n",
    "                            data_transform=data_transform, label_transform=label_transform)\n",
    "\n",
    "class_encoding = cityscapes_set.color_encoding\n",
    "num_classes = len(class_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityscapes_loader = torch.utils.data.DataLoader(cityscapes_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, targets = iter(cityscapes_loader).next()\n",
    "print(\"Images size:\", images.size())\n",
    "print(\"Labels size:\", labels.size())\n",
    "print(\"Targets size:\", targets.size())\n",
    "print(\"Number of class:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(f'Data ({i})')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[i,0], cmap='gray')\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(labels[i,0])\n",
    "    plt.title(f'Label ({i})')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    num_classes, targets = utils.one_hot_encode_for_sanity_check(num_classes, labels)\n",
    "    targets = torch.tensor(targets)\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    c = random.randint(0, num_classes-1)\n",
    "    plt.imshow(targets[i, c])\n",
    "    plt.title(f'One-Hot-Label ({c})')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
