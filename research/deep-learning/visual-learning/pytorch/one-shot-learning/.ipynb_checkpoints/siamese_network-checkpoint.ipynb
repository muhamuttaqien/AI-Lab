{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese One Shot Learning Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_LEARN = True\n",
    "SAVE_FREQUENCY = 2\n",
    "BATCH_SIZE = 16\n",
    "LR = 0.001\n",
    "N_EPOCHS = 10\n",
    "WEIGHT_DECAY = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL_PATH = './weights/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_int(b):\n",
    "    return int(codecs.encode(b, 'hex'), 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "    assert get_int(data[:4]) == 2051\n",
    "    length = get_int(data[4:8])\n",
    "    num_rows = get_int(data[8:12])\n",
    "    num_cols = get_int(data[12:16])\n",
    "    \n",
    "    images = []\n",
    "    parsed = np.frombuffer(data, dtype=np.uint8, offset=16)\n",
    "    \n",
    "    return torch.from_numpy(parsed).view(length, num_rows, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_label_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "    assert get_int(data[:4]) == 2049\n",
    "    length = get_int(data[4:8])\n",
    "    parsed = np.frombuffer(data, dtype=np.uint8, offset=8)\n",
    "    \n",
    "    return torch.from_numpy(parsed).view(length).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Custom Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedMNISTPair(torch.utils.data.Dataset):\n",
    "    \"\"\" Dataset that on each iteration will provides two pairs of MNIST images randomly. \n",
    "        One pair is of the same number (positive sample) and \n",
    "        other one is of the two different numbers (negative sample).\n",
    "    \"\"\"\n",
    "    \n",
    "    urls = [\n",
    "        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
    "    ]\n",
    "    \n",
    "    raw_folder = 'raw'\n",
    "    processed_folder = 'processed'\n",
    "    training_file = 'training.pt'\n",
    "    test_file = 'test.pt'\n",
    "    \n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "        \n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train\n",
    "        \n",
    "        if download:\n",
    "            self.download()\n",
    "            \n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Dataset not found.' + ' You can use download=True to download it.')\n",
    "            \n",
    "        if self.train:\n",
    "            self.train_data, self.train_labels = torch.load(\n",
    "                os.path.join(self.root, self.processed_folder, self.training_file))\n",
    "            \n",
    "            train_data_class = []\n",
    "            train_labels_class = []\n",
    "            for i in range(10):\n",
    "                indices = torch.squeeze((self.train_labels == i).nonzero())\n",
    "                train_data_class.append(torch.index_select(self.train_data, 0, indices))\n",
    "                train_labels_class.append(torch.index_select(self.train_labels, 0, indices))\n",
    "\n",
    "            # generated balanced pairs\n",
    "            self.train_data = []\n",
    "            self.train_labels = []\n",
    "            lengths = [x.shape[0] for x in train_labels_class]\n",
    "            for i in range(10):\n",
    "                for j in range(500):\n",
    "                    random_class  = random.randint(0,8)\n",
    "                    if random_class >= i:\n",
    "                        random_class = random_class + 1\n",
    "                        \n",
    "                    random_dist = random.randint(0,100)\n",
    "                    \n",
    "                    self.train_data.append(torch.stack([train_data_class[i][j], train_data_class[i][j+random_dist], train_data_class[random_class][j]]))\n",
    "                    self.train_labels.append([1,0])\n",
    "                    \n",
    "            self.train_data = torch.stack(self.train_data)\n",
    "            self.train_labels = torch.tensor(self.train_labels)\n",
    "            \n",
    "        else:\n",
    "            self.test_data, self.test_labels = torch.load(\n",
    "                os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "            \n",
    "            test_data_class = []\n",
    "            test_labels_class = []\n",
    "            for i in range(10):\n",
    "                indices = torch.squeeze((self.test_labels == i).nonzero())\n",
    "                test_data_class.append(torch.index_select(self.test_data, 0, indices))\n",
    "                test_labels_class.append(torch.index_select(self.test_labels, 0, indices))\n",
    "                \n",
    "            # generated balanced pairs\n",
    "            self.test_data = []\n",
    "            self.test_labels = []\n",
    "            lengths = [x.shape[0] for x in test_labels_class]\n",
    "            for i in range(10):\n",
    "                for j in range(500):\n",
    "                    random_class  = random.randint(0,8)\n",
    "                    if random_class >= i:\n",
    "                        random_class = random_class + 1\n",
    "                        \n",
    "                    random_dist = random.randint(0,100)\n",
    "                    \n",
    "                    self.test_data.append(torch.stack([test_data_class[i][j], test_data_class[i][j+random_dist], test_data_class[random_class][j]]))\n",
    "                    self.test_labels.append([1,0])\n",
    "                    \n",
    "            self.test_data = torch.stack(self.test_data)\n",
    "            self.test_labels = torch.tensor(self.test_labels)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            images, targets = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            images, targets = self.test_data[index], self.test_labels[index]\n",
    "            \n",
    "        image_list = []\n",
    "        for i in range(len(images)):\n",
    "            image = Image.fromarray(images[i].numpy(), mode='L')\n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image)\n",
    "            image_list.append(image)\n",
    "            \n",
    "        if self.target_transform is not None:\n",
    "            targets = self.target_transform(targets)\n",
    "            \n",
    "        return image_list, targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "        \n",
    "    def _check_exists(self):\n",
    "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
    "         os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        tmp = 'train' if self.train is True else 'test'\n",
    "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        tmp = '    Transforms (if any): '\n",
    "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        tmp = '    Target Transforms (if any): '\n",
    "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        \n",
    "        return fmt_str\n",
    "        \n",
    "    def download(self):\n",
    "        \"\"\" Download the MNIST data if it doesn't exist in processed_folder already. \"\"\"\n",
    "        from six.moves import urllib\n",
    "        import gzip\n",
    "        \n",
    "        if self._check_exists():\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
    "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.EEXIST:\n",
    "                pass\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        for url in self.urls:\n",
    "            print('Downloading ' + url)\n",
    "            data = urllib.request.urlopen(url)\n",
    "            filename = url.rpartition('/')[2]\n",
    "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(data.read())\n",
    "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
    "                   gzip.GzipFile(file_path) as zip_f:\n",
    "                out_f.write(zip_f.read())\n",
    "            os.unlink(file_path)\n",
    "            \n",
    "        print('Processing...')\n",
    "        \n",
    "        training_set = (\n",
    "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
    "        )\n",
    "        test_set = (\n",
    "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
    "        )\n",
    "        \n",
    "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
    "            torch.save(training_set, f)\n",
    "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
    "            torch.save(test_set, f)\n",
    "\n",
    "        print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Siamese Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, 7)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 5)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 5)\n",
    "        self.linear1 = nn.Linear(2304, 512)\n",
    "        self.linear2 = nn.Linear(512, 2)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        fvectors = []\n",
    "        for i in range(2): # the layers in the two subnetworks share the same weights\n",
    "            x = data[i]\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.pool1(x)\n",
    "            \n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv3(x)\n",
    "            x = F.relu(x)\n",
    "            \n",
    "            x = x.view(x.shape[0], -1)\n",
    "            x = self.linear1(x)\n",
    "            fvectors.append(F.relu(x))\n",
    "            \n",
    "        distance = torch.abs(fvectors[1] - fvectors[0])\n",
    "        score = self.linear2(distance)\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_to_display = []\n",
    "def train(model, device, train_loader, epoch, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    print('# -----------------')\n",
    "    print('# TRAINING PROCESS')\n",
    "    print('# -----------------')\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        for i in range(len(data)):\n",
    "            data[i] = data[i].to(device)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        output_positive = model(data[:2])\n",
    "        output_negative = model(data[0:3:2])\n",
    "        \n",
    "        target = target.type(torch.LongTensor).to(device)\n",
    "        target_positive = torch.squeeze(target[:,0])\n",
    "        target_negative = torch.squeeze(target[:,1])\n",
    "        \n",
    "        loss_positive = F.cross_entropy(output_positive, target_positive)\n",
    "        loss_negative = F.cross_entropy(output_negative, target_negative)\n",
    "        \n",
    "        loss = loss_positive + loss_negative\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.6f}'.format(epoch,\n",
    "                                                                           batch_idx*BATCH_SIZE,\n",
    "                                                                           len(train_loader.dataset),\n",
    "                                                                           100. * batch_idx*BATCH_SIZE / len(train_loader.dataset),\n",
    "                                                                           loss.item()))\n",
    "        train_loss_to_display.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_to_display = []\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    print('# -----------------')\n",
    "    print('# TESTING PROCESS')\n",
    "    print('# -----------------')\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accurate_labels = 0\n",
    "        all_labels = 0\n",
    "        loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            for i in range(len(data)):\n",
    "                data[i] = data[i].to(device)\n",
    "                \n",
    "            output_positive = model(data[:2])\n",
    "            output_negative = model(data[0:3:2])\n",
    "            \n",
    "            target = target.type(torch.LongTensor).to(device)\n",
    "            target_positive = torch.squeeze(target[:,0])\n",
    "            target_negative = torch.squeeze(target[:,1])\n",
    "            \n",
    "            loss_positive = F.cross_entropy(output_positive, target_positive)\n",
    "            loss_negative = F.cross_entropy(output_negative, target_negative)\n",
    "            \n",
    "            loss = loss + loss_positive + loss_negative\n",
    "            \n",
    "            accurate_labels_positive = torch.sum(torch.argmax(output_positive, dim=1) == target_positive).cpu()\n",
    "            accurate_labels_negative = torch.sum(torch.argmax(output_negative, dim=1) == target_negative).cpu()\n",
    "            \n",
    "            accurate_labels = accurate_labels + accurate_labels_positive + accurate_labels_negative\n",
    "            all_labels = all_labels + len(target_positive) + len(target_negative)\n",
    "            \n",
    "        accuracy = 100. * accurate_labels / all_labels\n",
    "        print('Test Accuracy: {}/{} ({:.3f}%) Loss: {:.6f}'.format(accurate_labels, all_labels, accuracy, loss))\n",
    "        test_loss_to_display.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_shot():\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(data)):\n",
    "            data[i] = data[i].to(device)\n",
    "            \n",
    "        output = model(data)\n",
    "        return torch.squeeze(torch.argmax(output, dim=1)).cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.5,), (1.0,))])\n",
    "    \n",
    "    model = SiameseNet().to(device)\n",
    "    \n",
    "    if DO_LEARN:\n",
    "        train_loader = torch.utils.data.DataLoader(BalancedMNISTPair('./datasets', train=True, download=True, transform=transform), \n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(BalancedMNISTPair('./datasets', train=False, download=True, transform=transform),\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  shuffle=False)\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "        for epoch in range(N_EPOCHS):\n",
    "            train(model, device, train_loader, epoch, optimizer)\n",
    "            test(model, device, test_loader)\n",
    "            if epoch & SAVE_FREQUENCY == 0:\n",
    "                if not os.path.exists('./weights'): os.makedirs('./weights')\n",
    "                torch.save(model, 'siamese_{:03}.pt'.format(epoch))\n",
    "                \n",
    "    else:\n",
    "        prediction_loader = torch.utils.data.DataLoader(BalancedMNISTPair('./datasets', train=False, download=True, transform=transform),\n",
    "                                                        batch_size=1,\n",
    "                                                        shuffle=True)\n",
    "        model.load_state_dict(torch.load(LOAD_MODEL_PATH))\n",
    "        \n",
    "        data = []\n",
    "        data.extend(next(iter(prediction_loader))[0][:3:2])\n",
    "        \n",
    "        similarity_score = one_shot(model)\n",
    "        if similarity_score > 0:\n",
    "            print('These two images are of the same number.')\n",
    "        else:\n",
    "            print('These two images are not of the same number.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -----------------\n",
      "# TRAINING PROCESS\n",
      "# -----------------\n",
      "Train Epoch: 0 [0/5000 (0%)] Loss: 1.385130\n",
      "Train Epoch: 0 [160/5000 (3%)] Loss: 1.289311\n",
      "Train Epoch: 0 [320/5000 (6%)] Loss: 1.374107\n",
      "Train Epoch: 0 [480/5000 (10%)] Loss: 1.251105\n",
      "Train Epoch: 0 [640/5000 (13%)] Loss: 1.222174\n",
      "Train Epoch: 0 [800/5000 (16%)] Loss: 1.329783\n",
      "Train Epoch: 0 [960/5000 (19%)] Loss: 1.194321\n",
      "Train Epoch: 0 [1120/5000 (22%)] Loss: 0.986903\n",
      "Train Epoch: 0 [1280/5000 (26%)] Loss: 1.042635\n",
      "Train Epoch: 0 [1440/5000 (29%)] Loss: 1.108517\n",
      "Train Epoch: 0 [1600/5000 (32%)] Loss: 1.225872\n",
      "Train Epoch: 0 [1760/5000 (35%)] Loss: 1.107710\n",
      "Train Epoch: 0 [1920/5000 (38%)] Loss: 1.413166\n",
      "Train Epoch: 0 [2080/5000 (42%)] Loss: 1.035034\n",
      "Train Epoch: 0 [2240/5000 (45%)] Loss: 1.309956\n",
      "Train Epoch: 0 [2400/5000 (48%)] Loss: 0.951125\n",
      "Train Epoch: 0 [2560/5000 (51%)] Loss: 0.898804\n",
      "Train Epoch: 0 [2720/5000 (54%)] Loss: 0.868516\n",
      "Train Epoch: 0 [2880/5000 (58%)] Loss: 1.617306\n",
      "Train Epoch: 0 [3040/5000 (61%)] Loss: 0.668398\n",
      "Train Epoch: 0 [3200/5000 (64%)] Loss: 1.153276\n",
      "Train Epoch: 0 [3360/5000 (67%)] Loss: 0.634659\n",
      "Train Epoch: 0 [3520/5000 (70%)] Loss: 0.941331\n",
      "Train Epoch: 0 [3680/5000 (74%)] Loss: 0.771264\n",
      "Train Epoch: 0 [3840/5000 (77%)] Loss: 0.461731\n",
      "Train Epoch: 0 [4000/5000 (80%)] Loss: 1.054793\n",
      "Train Epoch: 0 [4160/5000 (83%)] Loss: 1.037884\n",
      "Train Epoch: 0 [4320/5000 (86%)] Loss: 0.813346\n",
      "Train Epoch: 0 [4480/5000 (90%)] Loss: 0.517560\n",
      "Train Epoch: 0 [4640/5000 (93%)] Loss: 0.565383\n",
      "Train Epoch: 0 [4800/5000 (96%)] Loss: 0.679116\n",
      "Train Epoch: 0 [4960/5000 (99%)] Loss: 0.398448\n",
      "# -----------------\n",
      "# TESTING PROCESS\n",
      "# -----------------\n",
      "Test Accuracy: 8496/10000 (84.000%) Loss: 228.786758\n",
      "# -----------------\n",
      "# TRAINING PROCESS\n",
      "# -----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angga.muhammad/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type SiameseNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/5000 (0%)] Loss: 0.886889\n",
      "Train Epoch: 1 [160/5000 (3%)] Loss: 0.490917\n",
      "Train Epoch: 1 [320/5000 (6%)] Loss: 0.843181\n",
      "Train Epoch: 1 [480/5000 (10%)] Loss: 0.330017\n",
      "Train Epoch: 1 [640/5000 (13%)] Loss: 0.499086\n",
      "Train Epoch: 1 [800/5000 (16%)] Loss: 0.437951\n",
      "Train Epoch: 1 [960/5000 (19%)] Loss: 0.567102\n",
      "Train Epoch: 1 [1120/5000 (22%)] Loss: 1.025748\n",
      "Train Epoch: 1 [1280/5000 (26%)] Loss: 0.264803\n",
      "Train Epoch: 1 [1440/5000 (29%)] Loss: 0.462520\n",
      "Train Epoch: 1 [1600/5000 (32%)] Loss: 0.309850\n",
      "Train Epoch: 1 [1760/5000 (35%)] Loss: 0.273429\n",
      "Train Epoch: 1 [1920/5000 (38%)] Loss: 0.595843\n",
      "Train Epoch: 1 [2080/5000 (42%)] Loss: 0.470056\n",
      "Train Epoch: 1 [2240/5000 (45%)] Loss: 0.725589\n",
      "Train Epoch: 1 [2400/5000 (48%)] Loss: 0.398860\n",
      "Train Epoch: 1 [2560/5000 (51%)] Loss: 0.663762\n",
      "Train Epoch: 1 [2720/5000 (54%)] Loss: 0.364029\n",
      "Train Epoch: 1 [2880/5000 (58%)] Loss: 0.359097\n",
      "Train Epoch: 1 [3040/5000 (61%)] Loss: 0.636338\n",
      "Train Epoch: 1 [3200/5000 (64%)] Loss: 0.691596\n",
      "Train Epoch: 1 [3360/5000 (67%)] Loss: 0.288177\n",
      "Train Epoch: 1 [3520/5000 (70%)] Loss: 0.579565\n",
      "Train Epoch: 1 [3680/5000 (74%)] Loss: 0.278131\n",
      "Train Epoch: 1 [3840/5000 (77%)] Loss: 0.293406\n",
      "Train Epoch: 1 [4000/5000 (80%)] Loss: 0.510821\n",
      "Train Epoch: 1 [4160/5000 (83%)] Loss: 0.112585\n",
      "Train Epoch: 1 [4320/5000 (86%)] Loss: 0.411281\n",
      "Train Epoch: 1 [4480/5000 (90%)] Loss: 0.461609\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c7bc734e5e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-eadc623344c8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWEIGHT_DECAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSAVE_FREQUENCY\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-b151bdc9515a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, epoch, optimizer)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_positive\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_negative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Train & Test Loss of Siamese Network\")\n",
    "plt.plot(train_loss_to_display, label=\"Train Loss\")\n",
    "plt.plot(test_loss_to_display, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "if not os.path.exists('./images/'): os.makedirs('./images/')\n",
    "plt.savefig('./images/final_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
